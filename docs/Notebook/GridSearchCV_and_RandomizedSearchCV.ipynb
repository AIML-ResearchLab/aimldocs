{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is GridSearchCV?\n",
        "\n",
        "- ```GridSearchCV``` performs an ```exhaustive search``` over all possible combinations of hyperparameters in a given grid.\n",
        "\n",
        "- It evaluates each combination using ```cross-validation``` and returns the best hyperparameters.\n",
        "\n",
        "üëâ Example: If you have\n",
        "\n",
        "- ```max_depth = [3, 5, 7]```\n",
        "\n",
        "- ```n_estimators = [50, 100]```\n",
        "\n",
        "GridSearch will test all ```3 √ó 2 = 6``` combinations.\n",
        "\n",
        "\n",
        "‚úÖ Pros:\n",
        "\n",
        "- Finds the absolute best hyperparameter combination (within the grid).\n",
        "\n",
        "- Simple to understand.\n",
        "\n",
        "‚ùå Cons:\n",
        "\n",
        "- Computationally expensive (especially with large grids).\n",
        "\n",
        "- Not scalable for high-dimensional hyperparameter spaces.\n",
        "\n",
        "\n",
        "# What is RandomizedSearchCV?\n",
        "\n",
        "- **RandomizedSearchCV** randomly samples hyperparameter combinations from a **given distribution**.\n",
        "\n",
        "- You specify number of iterations (```n_iter```) instead of testing all combinations.\n",
        "\n",
        "üëâ Example:\n",
        "\n",
        "Instead of testing all 6 combos, it may test only 3 random ones.\n",
        "\n",
        "\n",
        "‚úÖ Pros:\n",
        "\n",
        "- Much faster than GridSearch.\n",
        "\n",
        "- Works better with large search spaces.\n",
        "\n",
        "- Can still find near-optimal hyperparameters.\n",
        "\n",
        "‚ùå Cons:\n",
        "\n",
        "- Doesn‚Äôt guarantee the absolute best hyperparameters.\n",
        "\n",
        "- Results can vary depending on random seed.\n",
        "\n",
        "\n",
        "# üîπ 3. Key Differences\n",
        "\n",
        "| Aspect        | GridSearchCV             | RandomizedSearchCV |\n",
        "| ------------- | ------------------------ | ------------------ |\n",
        "| Search method | Exhaustive (all combos)  | Random sampling    |\n",
        "| Speed         | Slow (expensive)         | Faster             |\n",
        "| Best result   | Guaranteed (within grid) | Approximate        |\n",
        "| Use case      | Small search space       | Large search space |\n",
        "\n",
        "\n",
        "\n",
        "# üîπ 4. Real-Time Example\n",
        "\n",
        "Let‚Äôs take a **Random Forest Classifier** on the ```Titanic dataset```.\n",
        "\n"
      ],
      "metadata": {
        "id": "fuHwI4_6nf3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cyvyN2inWfF",
        "outputId": "ced65821-42a8-449f-89aa-26c11b62c247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (GridSearch): {'max_depth': 3, 'n_estimators': 100}\n",
            "Best score (GridSearch): 0.8241873396065014\n",
            "Best params (RandomizedSearch): {'max_depth': 5, 'n_estimators': 121}\n",
            "Best score (RandomizedSearch): 0.8206087824351298\n",
            "Test Accuracy: 0.7655502392344498\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
        "df = titanic.frame\n",
        "\n",
        "# Preprocess (drop missing & encode)\n",
        "df = df[['pclass', 'sex', 'age', 'fare', 'survived']].dropna()\n",
        "df['sex'] = df['sex'].map({'male':0, 'female':1})\n",
        "\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# --- GridSearchCV ---\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params (GridSearch):\", grid_search.best_params_)\n",
        "print(\"Best score (GridSearch):\", grid_search.best_score_)\n",
        "\n",
        "# --- RandomizedSearchCV ---\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': randint(3, 10)\n",
        "}\n",
        "random_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
        "                                   n_iter=5, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params (RandomizedSearch):\", random_search.best_params_)\n",
        "print(\"Best score (RandomizedSearch):\", random_search.best_score_)\n",
        "\n",
        "# Test set performance\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 5. Explanation in Real-Time\n",
        "\n",
        "- **GridSearchCV** will try **all combos (3√ó3=9 tests)** ‚Üí ensures best result but slower.\n",
        "\n",
        "- **RandomizedSearchCV** will try only **5 random combos (n_iter=5)** ‚Üí much faster, may still hit near-best parameters.\n",
        "\n",
        "- In practice, people often start with **RandomizedSearchCV** to narrow down ranges, then use **GridSearchCV** for fine-tuning.\n",
        "\n",
        "üëâ So in real-world use cases:\n",
        "\n",
        "- **Small models, small parameter space** ‚Üí Use **GridSearchCV**.\n",
        "\n",
        "- **Large models (RandomForest, XGBoost, Neural Nets)** ‚Üí Use **RandomizedSearchCV** for efficiency."
      ],
      "metadata": {
        "id": "hzoQYqxlsh04"
      }
    }
  ]
}