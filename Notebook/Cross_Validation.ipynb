{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ What is Cross-Validation?\n",
        "- Cross-validation is a technique to **evaluate how well a machine learning model generalizes** to unseen data.\n",
        "\n",
        "- Instead of training the model once and testing it on a single train/test split, cross-validation divides the dataset into multiple parts (called folds) and tests the model multiple times, each time on different unseen data.\n",
        "\n",
        "# üîπ Why do we need it?\n",
        "\n",
        "- Prevents **overfitting** (model memorizing training data).\n",
        "\n",
        "- Gives a **better estimate** of model performance.\n",
        "\n",
        "- Ensures the model works well on **different subsets** of data.\n",
        "\n",
        "# üîπ Types of Cross-Validation\n",
        "\n",
        "1. **Hold-out method** ‚Üí One-time train/test split. (Simple but not robust).\n",
        "\n",
        "2. **K-Fold Cross-Validation** ‚Üí Most common. Dataset is split into k equal parts (folds). Each fold gets a turn as test data, rest as training.\n",
        "\n",
        "3. **Stratified K-Fold** ‚Üí Ensures class balance in each fold (important in classification).\n",
        "\n",
        "4. **Leave-One-Out Cross-Validation (LOOCV)** ‚Üí Extreme case of K-fold where k = number of samples.\n",
        "\n",
        "\n",
        "# üîπ Analogy (Match Example ‚öΩüèè)\n",
        "\n",
        "Think of **building a cricket team strategy:**\n",
        "\n",
        "- You have **11 players** (your dataset).\n",
        "\n",
        "- To test your strategy, you **don‚Äôt always play the same 11 vs the same opposition**.\n",
        "\n",
        "- Instead, you rotate:\n",
        "  \n",
        "   - In Round 1: 10 play, 1 rests (that 1 tests if the strategy works).\n",
        "\n",
        "   - In Round 2: Another player rests, 10 play.\n",
        "\n",
        "   - Repeat until everyone has had a chance to be tested.\n",
        "\n",
        "üëâ This way, you ensure the strategy (your ML model) **works well no matter which player (data) is in or out**.\n",
        "\n",
        "\n",
        "This is exactly **K-Fold Cross Validation**.\n",
        "\n",
        "\n",
        "# üîπ Example in Python (Iris Dataset with K-Fold CV)"
      ],
      "metadata": {
        "id": "RDN8C0ONCNrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERxnq0QYCCBz",
        "outputId": "8b443870-471a-4da4-829a-c695ddedefd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [1.         0.96666667 0.93333333 0.93333333 0.93333333]\n",
            "Average accuracy: 0.9533333333333335\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Define model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Define 5-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate model using cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=kf)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average accuracy:\", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëâ Interpretation:\n",
        "\n",
        "The model performs well across all folds (not just on one lucky split).\n",
        "\n",
        "# üîπ Summary\n",
        "\n",
        "- **Cross-validation** = multiple training/testing cycles.\n",
        "\n",
        "- **K-Fold** = most used, rotates test/train sets.\n",
        "\n",
        "- **Analogy** = rotating cricket/football players to test strategies.\n",
        "\n",
        "- **Code** = cross_val_score makes it easy in scikit-learn."
      ],
      "metadata": {
        "id": "mcCmVjczFg3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let‚Äôs go step by step and manually implement K-Fold Cross Validation so you see exactly what happens under the hood.\n",
        "\n",
        "\n",
        "# üîπ Manual K-Fold Example (Iris Dataset)\n",
        "\n",
        "We‚Äôll take the Iris dataset, split it into 5 folds, and then **train and test** the model fold by fold."
      ],
      "metadata": {
        "id": "BpFS2xHGOt2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Define model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Define 5-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split data\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    scores.append(acc)\n",
        "\n",
        "    print(f\"Fold {fold}: Train size={len(train_index)}, Test size={len(test_index)}, Accuracy={acc:.3f}\")\n",
        "    fold += 1\n",
        "\n",
        "print(\"\\nAll fold accuracies:\", scores)\n",
        "print(\"Average accuracy:\", np.mean(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNkMB66UPP89",
        "outputId": "777837a9-4f00-4b6e-c166-d543ef9f3d55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: Train size=120, Test size=30, Accuracy=1.000\n",
            "Fold 2: Train size=120, Test size=30, Accuracy=0.967\n",
            "Fold 3: Train size=120, Test size=30, Accuracy=0.933\n",
            "Fold 4: Train size=120, Test size=30, Accuracy=0.933\n",
            "Fold 5: Train size=120, Test size=30, Accuracy=0.933\n",
            "\n",
            "All fold accuracies: [1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333]\n",
            "Average accuracy: 0.9533333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ How it Works (Match Analogy ‚öΩüèè)\n",
        "\n",
        "Think of **5 cricket matches** where you rotate which players sit out:\n",
        "\n",
        "- **Match 1:** 30 players sit out (test set), 120 play (train set).\n",
        "\n",
        "- **Match 2:** Another 30 sit out, different 120 play.\n",
        "\n",
        "- Repeat until every player (data point) has been tested at least once.\n",
        "\n",
        "üëâ Finally, you average the performance across matches = **true measure of strategy (model performance)**.\n",
        "\n"
      ],
      "metadata": {
        "id": "J0fjrurPPnTG"
      }
    }
  ]
}