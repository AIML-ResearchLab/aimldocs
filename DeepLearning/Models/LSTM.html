<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Ganesh kinkar Giri" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>LSTM (Long Short-Term Memory) - AIML documents</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "LSTM (Long Short-Term Memory)";
        var mkdocs_page_input_path = "DeepLearning/Models/LSTM.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../index.html" class="icon icon-home"> AIML documents
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../index.html">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">AIML</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" >Programing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Programing/python.html">PYTHON</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Statistic</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Descriptive Statistics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" >Measures of Central Tendency</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mean.html">Mean</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Median.html">Median</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mode.html">Mode</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Measures of Position (Relative Standing)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Percentiles.html">Percentiles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Quartiles.html">Quartiles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Deciles.html">Deciles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Z-Score.html">Z-Score</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Shape of the Distribution</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Skewness.html">Skewness</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Kurtosis.html">Kurtosis</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Visualization Tools</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/Histogram.html">Histogram</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/BarChart.html">Bar Chart</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/PieChart.html">Pie Chart</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/BoxPlot.html">Box Plot</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/LinePlot.html">Line Plot</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/DotPlot.html">Dot Plot</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Measures of Dispersion (Variability)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Range.html">Range</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Variance.html">Variance</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/StandardDeviation.html">Standard Deviation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/InterquartileRange.html">Interquartile Range(IQR)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/CofficientVariation.html">Cofficient of Variation</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Inferential Statistics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" >Population and Sample</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/Population.html">Population</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/Sample.html">Sample</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/SamplingMethods.html">Sampling Methods</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Estimation</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/PointEstimation.html">Point Estimation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/IntervalEstimation.html">Interval Estimation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/MarginError.html">Margin of Error</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Regression and Correlation Analysis</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LinearRegression.html">Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LogisticRegression.html">Logistic Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/MultipleRegression.html">Multiple Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/CorrelationCoefficients.html">Correlation Coefficients</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Hypothesis Testing</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/NullHypothesis.html">Null Hypothesis (H₀)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/AlternativeHypothesis.html">Alternative Hypothesis (H₁)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TestStatistic.html">Test Statistic</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/pvalue.html">p-value</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/SignificanceLevel.html">Significance Level (α)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIError.html">Type I Error (α)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIIError.html">Type II Error (β)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/PoweroftheTest.html">Power of the Test</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Parametric Tests</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/t-test.html">t-test</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/z-test.html">z-test</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/ANOVA.html">ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/F-test.html">F-test</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Non-Parametric Tests</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Mann-WhitneyU.html">Mann-Whitney U</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Kruskal-Wallis.html">Kruskal-Wallis</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Wilcoxon.html">Wilcoxon</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Chi-square.html">Chi-square</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Resampling Methods</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Resampling-Methods/Bootstrapping.html">Bootstrapping</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Resampling-Methods/Jackknife.html">Jackknife</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Analysis of Variance (ANOVA)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/One-way-ANOVA.html">One-way ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/Two-way-ANOVA.html">Two-way ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/Post-hoc-Tests.html">Post-hoc Tests</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Probability Theory</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/ProbabilityDistributions.html">Probability Distributions</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/CentralLimitTheorem.html">Central Limit Theorem</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/BayesianInference.html">Bayesian Inference</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Time Series</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Trend.html">Trend</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Seasonality.html">Seasonality</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Cyclic.html">Cyclic</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Noise.html">Irregular/Noise</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Stationarity.html">Stationarity</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Non-stationary.html">Non-stationary</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Autocorrelation.html">Autocorrelation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Lag.html">Lag</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/MovingAverages.html">Moving Averages</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Holt-Winters.html">Holt-Winters Method</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Additive.html">Additive</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Multiplicative.html">Multiplicative</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AR.html">AR (Auto Regression)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/ARIMA.html">ARIMA</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Arimax.html">Arimax</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Sarimax.html">Sarimax</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Smoothing.html">Smoothing</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AutomatedForecasting.html">Automated Forecasting</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AutomatedTimeSeries.html">Automated Time Series</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Multivariate.html">Uni, Bi and Multivariate</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/metrics.html">Metrics Evaluation</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/timeseries.html">Time Series Old</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/statistic-details.html">Statistic Details</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Data manipulation and analysis</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-manipulation-and-analysis/data-manipulation-analysis.html">PANDAS</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Data Processing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/sql.html">Basic SQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/sql-datascience.html">Using SQL for Data Science</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/unstructured-data.html">Unstructured Data</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/exploratory-data-analysis.html">Exploratory Data Analysis(EDA)</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../Data-processing/building-ml-models-on-text-data.md">Building ML Models on Text Data</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Databases</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/PostgreSQL.html">PostgreSQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/MySQL.html">MySQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/MongoDB.html">MongoDB</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Machine Learning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../MachineLearning/Overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Supervised Learning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/Overview.html">Overview</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/Regression.html">Regression</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/Classification.html">Classification</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/CrossValidation.html">Cross Validation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/HyperparameterTuning.html">Hyperparameter Tuning</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/TuningDecisionThreshold.html">Tuning decision threshold</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Regression Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/SimpleLinearRegression.html">Simple Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/MultipleLinearRegression.html">Multiple Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/PolynomialRegression.html">Polynomial Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/RidgeLassoRegression.html">Ridge & Lasso Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/SupportVectorRegression.html">Support Vector Regression (SVR)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/DecisionTreeRegression.html">Decision Tree Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/RegressionModels/RandomForestRegression.html">Random Forest Regression</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Linear Classification Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/LinearClassificationModels/LogisticRegression.html">Logistic Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/LinearClassificationModels/SupportVectorMachines.html">Support Vector Machines</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/LinearClassificationModels/SinglelayerPerceptron.html">Single-layer Perceptron</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/LinearClassificationModels/StochasticGradientDescent.html">Stochastic Gradient Descent (SGD)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Non-linear Classification Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/DecisionTreeClassification.html">Decision Tree Classification</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/KNearestNeighbours.html">K-Nearest Neighbours</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/NaiveBayes.html">Naive Bayes</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/RandomForests.html">Random Forests</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/AdaBoost.html">AdaBoost</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/BaggingClassifier.html">Bagging Classifier</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/Ensemblelearningclassifiers.html">Ensemble learning classifiers</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/KernelSVM.html">Kernel SVM</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Unsupervised Learning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/UnsupervisedLearning/overview.html">Overview</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/UnsupervisedLearning/Clustering.html">Clustering</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/UnsupervisedLearning/Pca.html">Principal Component Analysis(PCA)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Reinforcement Learning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../MachineLearning/ReinforcementLearning/ReinforcementLearning.html">Overview</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Linear Algebra</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../LinearAlgebra/Overview.html">Overview</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Deep Learning</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../Overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Vanishing.html">Vanishing and Exploding Gradients Problems</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Components of Neural Networks</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../Components/LayersNeuralNetworks.html">Layers in Neural Networks</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/WeightsBiases.html">Weights and Biases</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/ForwardPropagation.html">Forward Propagation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/ActivationFunctions.html">Activation Functions</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/LossFunctions.html">Loss Functions</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/Backpropagation.html">Backpropagation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../Components/LearningRate.html">Learning Rate</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Optimization Algorithm</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/GradientDescent.html">Gradient Descent</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/SGD.html">Stochastic Gradient Descent (SGD)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/Adam.html">Adam (Adaptive Moment Estimation)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/BatchNormalization.html">Batch Normalization</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/Mini-batch-GD.html">Mini-batch Gradient Descent</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/Momentum-based-GO.html">Momentum-based Gradient Optimizer</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/AdagradOptimizer.html">Adagrad Optimizer</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../OptimizationAlgorithm/RMSPropOptimizer.html">RMSProp Optimizer</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" >Models</a>
    <ul class="current">
                <li class="toctree-l3"><a class="reference internal" href="FNN.html">Feedforward Neural Network (FNN)</a>
                </li>
                <li class="toctree-l3 current"><a class="reference internal current" >Recurrent Neural Network (RNN)</a>
    <ul class="current">
                <li class="toctree-l4"><a class="reference internal" href="RNN.html">Recurrent Neural Network (RNN)</a>
                </li>
                <li class="toctree-l4 current"><a class="reference internal current" href="#">LSTM (Long Short-Term Memory)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="GRU.html">GRU (Gated Recurrent Unit)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="CNN.html">Convolutional Neural Network (CNN)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="RBFN.html">Radial Basis Function Network (RBFN)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="ComputerVision.html">Computer Vision</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="GANs.html">Generative Adversarial Networks (GANs)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="Transformer.html">Transformer Networks</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="Autoencoders.html">Autoencoders</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="SOM.html">Self-Organizing Maps (SOM)</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Natural Language Processing(NLP)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../NLP/overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../NLP/nlpdetails.html">NLP Details</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Retrieval-Augmented Generation(RAG)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../RAG/rag.html">RAG</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >AI agents</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../AIagents/aiagents.html">AI agents</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Agentic AI</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/general.html">general</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/crewai.html">crewai</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/LangGraph.html">LangGraph</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/AutoGen.html">AutoGen</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/aws.html">AWS</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/azure.html">AZURE</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Agent Development Kit</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/adk.html">ADK</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/Agents.html">Agents</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/Tools.html">Tools</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/a2a.html">Tools</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >MCPModel Context Protocol (MCP)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../MCP/mcp.html">MCP</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Models Details information</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Models/Ollama.html">Ollama</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Note Book</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Notebook/allnotebook.html">All Notebook</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">AIML documents</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html" class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">AIML</li>
          <li class="breadcrumb-item">Deep Learning</li>
          <li class="breadcrumb-item">Models</li>
          <li class="breadcrumb-item">Recurrent Neural Network (RNN)</li>
      <li class="breadcrumb-item active">LSTM (Long Short-Term Memory)</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 style="color:red;">✅ LSTM - Long Short Term Memory</h2>

<h3 style="color:blue;">📌 What is LSTM - Long Short Term Memory?</h3>

<p>Long Short-Term Memory (LSTM) is an enhanced version of the Recurrent Neural Network (RNN)
designed by Hochreiter and Schmidhuber. LSTMs can capture long-term dependencies in sequential data making them ideal for tasks like language translation, speech recognition and time series forecasting.</p>
<p>Unlike traditional RNNs which use a single hidden state passed through time LSTMs introduce a memory cell that holds information over extended periods addressing the challenge of learning long-term dependencies.</p>
<p><img alt="alt text" src="../images/LSTM1.png" /></p>
<p><img alt="alt text" src="../images/LSTM2.png" /></p>
<p><img alt="alt text" src="../images/LSTM3.png" /></p>
<p><strong>Problem with Long-Term Dependencies in RNN</strong></p>
<p>Recurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps.</p>
<h3 style="color:blue;">📌 Understanding LSTM Networks</h3>

<p><img alt="alt text" src="../images/LSTMRNN1.png" /></p>
<p><img alt="alt text" src="../images/LSTMRNN2.png" /></p>
<p>Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN,capable of learning long-term dependencies.</p>
<p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p>
<p>All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.</p>
<p><img alt="alt text" src="../images/LSTM4.png" /></p>
<p>The repeating module in a standard RNN contains a single layer.</p>
<p>LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p>
<p><img alt="alt text" src="../images/LSTM5.png" /></p>
<p><img alt="alt text" src="../images/LSTM6.png" /></p>
<h2 id="the-core-idea-behind-lstms">The Core Idea Behind LSTMs<a class="headerlink" href="#the-core-idea-behind-lstms" title="Permanent link">#</a></h2>
<p>The key to LSTMs is the cell state, the horizontal line running through the top of the diagram.
The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.</p>
<h2 id="memory-cell">Memory Cell<a class="headerlink" href="#memory-cell" title="Permanent link">#</a></h2>
<ol>
<li>
<p><strong>You can Add information</strong></p>
</li>
<li>
<p><strong>You can Remove Information</strong></p>
</li>
</ol>
<p><img alt="alt text" src="../images/LSTM7.png" /></p>
<p>The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.</p>
<p>Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.</p>
<p><img alt="alt text" src="../images/LSTM8.png" /></p>
<p>The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”</p>
<p>An LSTM has three of these gates, to protect and control the cell state.</p>
<p><strong>Step-by-Step LSTM Walk Through</strong></p>
<p>The first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “forget gate layer.” It looks at ht−1  and xt, and outputs a number between 0  and 1 for each number in the cell state Ct−1.</p>
<p>A 1 represents “completely keep this” while a 0 represents “completely get rid of this.”</p>
<p>Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p>
<p><img alt="alt text" src="../images/LSTM9.png" /></p>
<p>The next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “input gate layer” decides which values we’ll update. Next, a tanh layer creates a vector of new candidate values, C̃ t
, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.</p>
<p>In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.</p>
<p><img alt="alt text" src="../images/LSTM10.png" /></p>
<p>It’s now time to update the old cell state, Ct−1 , into the new cell state Ct . The previous steps already decided what to do, we just need to actually do it.</p>
<p>We multiply the old state by ft , forgetting the things we decided to forget earlier. Then we add it∗C̃ t. This is the new candidate values, scaled by how much we decided to update each state value.</p>
<p>In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.</p>
<p><img alt="alt text" src="../images/LSTM11.png" /></p>
<p>Finally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanh
 (to push the values to be between −1
 and 1
) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.</p>
<p>For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.</p>
<p><img alt="alt text" src="../images/LSTM12.png" /></p>
<h2 id="variants-on-long-short-term-memory">Variants on Long Short Term Memory<a class="headerlink" href="#variants-on-long-short-term-memory" title="Permanent link">#</a></h2>
<p>What I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.</p>
<p>One popular LSTM variant, introduced by Gers &amp; Schmidhuber (2000), is adding “peephole connections.” This means that we let the gate layers look at the cell state.</p>
<p><img alt="alt text" src="../images/LSTM13.png" /></p>
<p>The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.</p>
<p>Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.</p>
<p><img alt="alt text" src="../images/LSTM14.png" /></p>
<p>A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014). It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.</p>
<p><img alt="alt text" src="../images/LSTM15.png" /></p>
<p>These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by Yao, et al. (2015). There’s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by Koutnik, et al. (2014).</p>
<p>Which of these variants is best? Do the differences matter? Greff, et al. (2015) do a nice comparison of popular variants, finding that they’re all about the same. Jozefowicz, et al. (2015) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.</p>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">#</a></h2>
<p>Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!</p>
<p>Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.</p>
<p>LSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, et al. (2015) do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…</p>
<p>Attention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, et al. (2015) seem extremely promising. Work using RNNs in generative models – such as Gregor, et al. (2015), Chung, et al. (2015), or Bayer &amp; Osendorfer (2015) – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!</p>
<h1 id="extra-understanding">Extra Understanding<a class="headerlink" href="#extra-understanding" title="Permanent link">#</a></h1>
<p>Long Short terl Memory</p>
<ol>
<li>
<p><strong>Memory Cell</strong></p>
</li>
<li>
<p><strong>Forget Cell</strong></p>
</li>
<li>
<p><strong>Input Cell</strong></p>
</li>
</ol>
<h2 id="relu">Relu<a class="headerlink" href="#relu" title="Permanent link">#</a></h2>
<p>Can actually cause dead neurons duraing back propagation.</p>
<ul>
<li><code>My name is Ganesh and I want to eat Pizza</code></li>
</ul>
<p>When I am trying to use the <strong>RNN</strong>, what RNN will do?</p>
<p><code>Each and every word it will try to convert in to vectors to make sure it consider that each and every word is important.</code></p>
<p>Suppose if something we have missed, suppose let say Pizza dependent on some word like it. This case you know that "eat" is just before the "Pizza" so it is being able to capture the context by with the help of RNN and also it will be able to capture the context. But over here you can see another word "I" I is definitly related to "Ganesh" I is basically giving the context of "Ganesh". This is only one word distance. But think about "I" and "My" can also be related. There should be some kind of context and Important context. Here you can see the distance is quite long.</p>
<p>What memory do? (Sometime you need to remember something, sometimes you need to forget something )</p>
<h1 id="lstm-context-switching-example">LSTM Context Switching Example<a class="headerlink" href="#lstm-context-switching-example" title="Permanent link">#</a></h1>
<h2 id="example">Example<a class="headerlink" href="#example" title="Permanent link">#</a></h2>
<ol>
<li><strong>Ganesh likes AIML</strong> → This is one context.  </li>
<li><strong>Ram likes DevSecOps</strong> → This is another context.  </li>
</ol>
<p>From <strong>context 1</strong> to <strong>context 2</strong>, a switch happens because the topic (or subject) changes — we are now talking about a different person.</p>
<p>Let’s say in the previous step (cell), we passed the information:</p>
<blockquote>
<p><strong>"Ganesh likes AIML"</strong></p>
</blockquote>
<p>In the next step, the context changes.<br />
When this happens, if we want our neural network to predict future words, it should only be based on the <strong>new context</strong>.<br />
It should <strong>not</strong> remember the previous context at this moment.</p>
<p>So, the <strong>old context</strong> (<code>Ganesh likes AIML</code>) will be <strong>forgotten</strong>, and the <strong>new context</strong> will be added.</p>
<hr />
<h2 id="forget-gate-behavior">Forget Gate Behavior<a class="headerlink" href="#forget-gate-behavior" title="Permanent link">#</a></h2>
<p>Most of the information in such a context-switching scenario will be close to <strong>[0]</strong> because the forget gate will filter it out.</p>
<ul>
<li>The forget gate uses a <strong>sigmoid</strong> activation function that outputs values between <strong>[0, 1]</strong>.</li>
<li>If the previous information is <strong>similar</strong> to the new context → values will be close to <strong>1</strong> (retain it).</li>
<li>If it is <strong>different</strong> → values will be close to <strong>0</strong> (forget it).</li>
</ul>
<p>When values are near <strong>0</strong>, the memory cell is instructed to <strong>forget</strong> the old information.<br />
This is done through <strong>pointwise multiplication</strong> in the forward pass.</p>
<hr />
<h2 id="adding-new-information">Adding New Information<a class="headerlink" href="#adding-new-information" title="Permanent link">#</a></h2>
<p>We now want to store the <strong>new word</strong> <code>"friend"</code> in the memory cell.</p>
<ol>
<li><strong>Sigmoid gate</strong> decides <strong>how much</strong> of the new information should be stored (values in <code>[0, 1]</code>).</li>
<li>The same input passes through a <strong>tanh</strong> activation function, producing values in the range <code>[-1, 1]</code>.</li>
<li>Outputs from <strong>sigmoid</strong> and <strong>tanh</strong> are <strong>combined element-wise</strong>.</li>
<li>The result is <strong>added to the memory cell</strong>, updating it with only the important parts of the new context.</li>
</ol>
<hr />
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">#</a></h2>
<ul>
<li><strong>Pointwise operation</strong> ensures that <strong>only important new information</strong> passes through and merges with the memory cell.</li>
<li><strong>Old, irrelevant context</strong> is discarded when the forget gate outputs values close to <code>0</code>.</li>
</ul>
<h2 id="referance-link">Referance Link:<a class="headerlink" href="#referance-link" title="Permanent link">#</a></h2>
<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></p>
<h2 style="color:red;">✅ Bidirectional LSTM</h2>

<h1 id="bidirectional-lstm-bilstm-explanation">Bidirectional LSTM (BiLSTM) Explanation<a class="headerlink" href="#bidirectional-lstm-bilstm-explanation" title="Permanent link">#</a></h1>
<h2 id="1-what-is-a-bidirectional-lstm">1. What is a Bidirectional LSTM?<a class="headerlink" href="#1-what-is-a-bidirectional-lstm" title="Permanent link">#</a></h2>
<p>A <strong>Bidirectional LSTM (BiLSTM)</strong> is an extension of the traditional LSTM (Long Short-Term Memory) network.<br />
Instead of processing the sequence in <strong>only one direction</strong> (forward in time), BiLSTM processes the sequence in <strong>both directions</strong>:</p>
<ul>
<li><strong>Forward LSTM</strong> → Reads the sequence from start to end.</li>
<li><strong>Backward LSTM</strong> → Reads the sequence from end to start.</li>
</ul>
<p>The outputs from both directions are then <strong>combined</strong> (either concatenated, summed, or averaged) to make the final prediction.</p>
<hr />
<h2 id="2-why-use-bidirectional-lstm">2. Why use Bidirectional LSTM?<a class="headerlink" href="#2-why-use-bidirectional-lstm" title="Permanent link">#</a></h2>
<p>Some tasks require understanding <strong>both past and future context</strong> in a sequence.</p>
<ul>
<li>Standard LSTM: Has access only to <strong>past information</strong>.</li>
<li>BiLSTM: Has access to <strong>both past and future information</strong> at each time step.</li>
</ul>
<p>This is especially useful in:
- Natural Language Processing (NLP)
- Speech Recognition
- Handwriting Recognition
- Named Entity Recognition (NER)
- Sentiment Analysis</p>
<hr />
<h2 id="3-real-life-example">3. Real-Life Example<a class="headerlink" href="#3-real-life-example" title="Permanent link">#</a></h2>
<h3 id="problem">Problem:<a class="headerlink" href="#problem" title="Permanent link">#</a></h3>
<p>We want to predict the <strong>sentiment</strong> (Positive/Negative) of a sentence.</p>
<p>Sentence:  </p>
<blockquote>
<p><code>"The movie was not bad"</code></p>
</blockquote>
<h3 id="why-bilstm-helps">Why BiLSTM helps:<a class="headerlink" href="#why-bilstm-helps" title="Permanent link">#</a></h3>
<ul>
<li>If we read <strong>only forward</strong>, we might think "The movie was not..." is <strong>negative</strong>.</li>
<li>But when reading <strong>backward</strong> as well, we see the word <strong>"bad"</strong> preceded by <strong>"not"</strong>, which changes the meaning to <strong>positive</strong>.</li>
<li>A BiLSTM can use both forward and backward context to correctly understand that the sentiment is <strong>Positive</strong>.</li>
</ul>
<hr />
<h2 id="4-how-it-works-step-by-step">4. How it works step-by-step:<a class="headerlink" href="#4-how-it-works-step-by-step" title="Permanent link">#</a></h2>
<ol>
<li><strong>Input sentence</strong> is tokenized into a sequence of words:</li>
</ol>
<p>["The", "movie", "was", "not", "bad"]</p>
<ol>
<li><strong>Forward LSTM</strong> processes:</li>
</ol>
<p>The → movie → was → not → bad</p>
<ol>
<li>At each word position, <strong>both forward and backward hidden states</strong> are concatenated:</li>
</ol>
<p>Hidden_state_t = [Forward_hidden_t ; Backward_hidden_t]</p>
<ol>
<li>Final combined representation is passed to a classifier (e.g., Softmax for sentiment prediction).</li>
</ol>
<hr />
<h2 id="5-diagram">5. Diagram<a class="headerlink" href="#5-diagram" title="Permanent link">#</a></h2>
<p>Input: The movie was not bad
Forward → h1 → h2 → h3 → h4 → h5
Backward ← h1'← h2'← h3'← h4'← h5'
| | | | |
Output: [h1;h1'] [h2;h2'] ... [h5;h5']</p>
<hr />
<h2 id="6-advantages">6. Advantages<a class="headerlink" href="#6-advantages" title="Permanent link">#</a></h2>
<ul>
<li>Uses <strong>full context</strong> of the sequence (past + future).</li>
<li>Improves performance in many NLP tasks where meaning depends on both sides of the word.</li>
</ul>
<hr />
<h2 id="7-limitations">7. Limitations<a class="headerlink" href="#7-limitations" title="Permanent link">#</a></h2>
<ul>
<li><strong>Cannot be used for real-time predictions</strong> where future data is not yet available.</li>
<li><strong>More computational cost</strong> compared to a single LSTM.</li>
</ul>
<hr />
<h2 id="8-summary-table">8. Summary Table<a class="headerlink" href="#8-summary-table" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>LSTM</th>
<th>BiLSTM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Direction</td>
<td>Forward only</td>
<td>Forward + Backward</td>
</tr>
<tr>
<td>Context</td>
<td>Past only</td>
<td>Past + Future</td>
</tr>
<tr>
<td>Computation Time</td>
<td>Lower</td>
<td>Higher</td>
</tr>
<tr>
<td>Use in Real-time</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Accuracy in NLP</td>
<td>Good</td>
<td>Often Better</td>
</tr>
</tbody>
</table>
<p><img alt="alt text" src="../images/BDLSTM3.png" /></p>
<p><img alt="alt text" src="../images/BDLSTM1.png" /></p>
<p><img alt="alt text" src="../images/BDLSTM2.png" /></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="RNN.html" class="btn btn-neutral float-left" title="Recurrent Neural Network (RNN)"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="GRU.html" class="btn btn-neutral float-right" title="GRU (Gated Recurrent Unit)">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="RNN.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="GRU.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
