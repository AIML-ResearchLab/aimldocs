
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AIML">
      
      
        <meta name="author" content="Ganesh kinkar Giri">
      
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>Langgraph - AIML documents</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../css/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#langgraph" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="AIML documents" class="md-header__button md-logo" aria-label="AIML documents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AIML documents
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Langgraph
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AIML documents" class="md-nav__button md-logo" aria-label="AIML documents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    AIML documents
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    AIML
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    AIML
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Programing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Programing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Programing/python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PYTHON
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Statistic
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Statistic
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1" id="__nav_2_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Descriptive Statistics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Descriptive Statistics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1_1" id="__nav_2_2_1_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Measures of Central Tendency
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Measures of Central Tendency
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mean/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mean
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Median/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Median
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mode/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mode
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1_2" id="__nav_2_2_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Measures of Position (Relative Standing)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Measures of Position (Relative Standing)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Percentiles/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Percentiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Quartiles/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quartiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Deciles/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deciles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Z-Score/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Z-Score
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1_3" id="__nav_2_2_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Shape of the Distribution
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Shape of the Distribution
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Skewness/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Skewness
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Kurtosis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Kurtosis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1_4" id="__nav_2_2_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Visualization Tools
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Visualization Tools
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/Histogram/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Histogram
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/BarChart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Bar Chart
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/PieChart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pie Chart
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/BoxPlot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Box Plot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/LinePlot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Line Plot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Visualization-Tools/DotPlot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dot Plot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1_5" id="__nav_2_2_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Measures of Dispersion (Variability)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Measures of Dispersion (Variability)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Range/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Range
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Variance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Variance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/StandardDeviation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Standard Deviation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/InterquartileRange/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Interquartile Range(IQR)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/CofficientVariation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cofficient of Variation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2" id="__nav_2_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Inferential Statistics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Inferential Statistics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_1" id="__nav_2_2_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Population and Sample
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Population and Sample
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Population-and-Sample/Population/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Population
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Population-and-Sample/Sample/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sample
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Population-and-Sample/SamplingMethods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sampling Methods
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_2" id="__nav_2_2_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Estimation
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Estimation
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Estimation/PointEstimation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Point Estimation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Estimation/IntervalEstimation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Interval Estimation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Estimation/MarginError/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Margin of Error
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_3" id="__nav_2_2_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Regression and Correlation Analysis
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Regression and Correlation Analysis
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LinearRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linear Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LogisticRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Logistic Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/MultipleRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multiple Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/CorrelationCoefficients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Correlation Coefficients
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_4" id="__nav_2_2_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Hypothesis Testing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Hypothesis Testing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/NullHypothesis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Null Hypothesis (H₀)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/AlternativeHypothesis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Alternative Hypothesis (H₁)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/TestStatistic/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Test Statistic
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/pvalue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    p-value
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/SignificanceLevel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Significance Level (α)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIError/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Type I Error (α)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIIError/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Type II Error (β)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Hypothesis-Testing/PoweroftheTest/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Power of the Test
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_5" id="__nav_2_2_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Parametric Tests
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Parametric Tests
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Parametric-Tests/t-test/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    t-test
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Parametric-Tests/z-test/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    z-test
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Parametric-Tests/ANOVA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ANOVA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Parametric-Tests/F-test/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    F-test
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_6" id="__nav_2_2_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Non-Parametric Tests
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Non-Parametric Tests
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Non-Parametric-Tests/Mann-WhitneyU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mann-Whitney U
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Non-Parametric-Tests/Kruskal-Wallis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Kruskal-Wallis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Non-Parametric-Tests/Wilcoxon/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Wilcoxon
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Non-Parametric-Tests/Chi-square/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chi-square
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_7" id="__nav_2_2_2_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Resampling Methods
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Resampling Methods
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Resampling-Methods/Bootstrapping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Bootstrapping
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Resampling-Methods/Jackknife/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Jackknife
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_8" id="__nav_2_2_2_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Analysis of Variance (ANOVA)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Analysis of Variance (ANOVA)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/ANOVA/One-way-ANOVA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    One-way ANOVA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/ANOVA/Two-way-ANOVA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Two-way ANOVA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/ANOVA/Post-hoc-Tests/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Post-hoc Tests
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2_9" id="__nav_2_2_2_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Probability Theory
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_2_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Probability Theory
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Probability-Theory/ProbabilityDistributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Probability Distributions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Probability-Theory/CentralLimitTheorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Central Limit Theorem
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/InferentialStatistics/Probability-Theory/BayesianInference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Bayesian Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_2_3" id="__nav_2_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Time Series
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Time Series
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Trend/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Trend
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Seasonality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Seasonality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Cyclic/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cyclic
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Noise/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Irregular/Noise
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Stationarity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stationarity
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Non-stationary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Non-stationary
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Autocorrelation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Autocorrelation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Lag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Lag
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/MovingAverages/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Moving Averages
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Holt-Winters/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Holt-Winters Method
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Additive/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Additive
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Multiplicative/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multiplicative
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/AR/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AR (Auto Regression)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/ARIMA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ARIMA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Arimax/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Arimax
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Sarimax/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sarimax
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Smoothing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Smoothing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/AutomatedForecasting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Automated Forecasting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/AutomatedTimeSeries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Automated Time Series
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/TimeSeries/Multivariate/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Uni, Bi and Multivariate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/metrics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Metrics Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/timeseries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Time Series Old
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Statistic/statistic-details/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Statistic Details
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data manipulation and analysis
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data manipulation and analysis
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-manipulation-and-analysis/data-manipulation-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PANDAS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Processing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Processing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-processing/sql/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Basic SQL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-processing/sql-datascience/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Using SQL for Data Science
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-processing/unstructured-data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Unstructured Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-processing/exploratory-data-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Exploratory Data Analysis(EDA)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data-processing/building-ml-models-on-text-data.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Building ML Models on Text Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Databases
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Databases
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Databases/PostgreSQL/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PostgreSQL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Databases/MySQL/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MySQL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Databases/MongoDB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MongoDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Machine Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Machine Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_2" >
        
          
          <label class="md-nav__link" for="__nav_2_6_2" id="__nav_2_6_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Supervised Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Supervised Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/Regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/Classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/CrossValidation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cross Validation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/HyperparameterTuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hyperparameter Tuning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/TuningDecisionThreshold/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tuning decision threshold
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_6_2_7" id="__nav_2_6_2_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Regression Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_6_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_2_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Regression Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/SimpleLinearRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Simple Linear Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/MultipleLinearRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multiple Linear Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/PolynomialRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Polynomial Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/RidgeLassoRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ridge & Lasso Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/SupportVectorRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Support Vector Regression (SVR)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/DecisionTreeRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Decision Tree Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/RegressionModels/RandomForestRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Random Forest Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_6_2_8" id="__nav_2_6_2_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Linear Classification Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_6_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_2_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Linear Classification Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/LinearClassificationModels/LogisticRegression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Logistic Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/LinearClassificationModels/SupportVectorMachines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Support Vector Machines
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/LinearClassificationModels/SinglelayerPerceptron/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Single-layer Perceptron
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/LinearClassificationModels/StochasticGradientDescent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stochastic Gradient Descent (SGD)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_6_2_9" id="__nav_2_6_2_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Non-linear Classification Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_6_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_2_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Non-linear Classification Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/DecisionTreeClassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Decision Tree Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/KNearestNeighbours/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    K-Nearest Neighbours
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/NaiveBayes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Naive Bayes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/RandomForests/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Random Forests
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/AdaBoost/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AdaBoost
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/BaggingClassifier/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Bagging Classifier
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/Ensemblelearningclassifiers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ensemble learning classifiers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/SupervisedLearning/NonlinearClassificationModels/KernelSVM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Kernel SVM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_3" >
        
          
          <label class="md-nav__link" for="__nav_2_6_3" id="__nav_2_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Unsupervised Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Unsupervised Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/UnsupervisedLearning/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/UnsupervisedLearning/Clustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Clustering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/UnsupervisedLearning/Pca/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Principal Component Analysis(PCA)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6_4" >
        
          
          <label class="md-nav__link" for="__nav_2_6_4" id="__nav_2_6_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Reinforcement Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reinforcement Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MachineLearning/ReinforcementLearning/ReinforcementLearning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Linear Algebra
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Linear Algebra
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../LinearAlgebra/Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Deep Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Deep Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Vanishing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vanishing and Exploding Gradients Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8_3" >
        
          
          <label class="md-nav__link" for="__nav_2_8_3" id="__nav_2_8_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Components of Neural Networks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_8_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Components of Neural Networks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/LayersNeuralNetworks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Layers in Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/WeightsBiases/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Weights and Biases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/ForwardPropagation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Forward Propagation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/ActivationFunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Activation Functions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/LossFunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Loss Functions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/Backpropagation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Backpropagation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Components/LearningRate/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Learning Rate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8_4" >
        
          
          <label class="md-nav__link" for="__nav_2_8_4" id="__nav_2_8_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Optimization Algorithm
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_8_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Optimization Algorithm
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/GradientDescent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Gradient Descent
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/SGD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stochastic Gradient Descent (SGD)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/Adam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adam (Adaptive Moment Estimation)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/BatchNormalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Batch Normalization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/Mini-batch-GD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mini-batch Gradient Descent
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/Momentum-based-GO/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Momentum-based Gradient Optimizer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/AdagradOptimizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adagrad Optimizer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/OptimizationAlgorithm/RMSPropOptimizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RMSProp Optimizer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8_5" >
        
          
          <label class="md-nav__link" for="__nav_2_8_5" id="__nav_2_8_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_8_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/FNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Feedforward Neural Network (FNN)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8_5_2" >
        
          
          <label class="md-nav__link" for="__nav_2_8_5_2" id="__nav_2_8_5_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Recurrent Neural Network (RNN)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_8_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8_5_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Recurrent Neural Network (RNN)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/RNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recurrent Neural Network (RNN)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/LSTM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LSTM (Long Short-Term Memory)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/GRU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GRU (Gated Recurrent Unit)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/CNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Convolutional Neural Network (CNN)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/RBFN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Radial Basis Function Network (RBFN)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/ComputerVision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Computer Vision
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/GANs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Generative Adversarial Networks (GANs)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/Transformer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformer Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/Autoencoders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Autoencoders
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DeepLearning/Models/SOM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Self-Organizing Maps (SOM)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_9" id="__nav_2_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Natural Language Processing(NLP)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Natural Language Processing(NLP)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/nlpdetails/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NLP Details
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_10" >
        
          
          <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Computer Vision
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Computer Vision
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_10_2" >
        
          
          <label class="md-nav__link" for="__nav_2_10_2" id="__nav_2_10_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Traditional CV (Before deep learning)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Traditional CV (Before deep learning)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Edge-detection.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Edge detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Feature-extraction.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Feature extraction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Image-filtering.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image filtering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Template-matching.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Template matching
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Optical-flow.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Optical flow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Histogram-analysis.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Histogram analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Rule-based-vision-systems.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Rule-based vision systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_10_3" >
        
          
          <label class="md-nav__link" for="__nav_2_10_3" id="__nav_2_10_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Modern CV (Deep learning–based)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modern CV (Deep learning–based)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/CNNs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CNNs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/ViT.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vision Transformers (ViT)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/YOLO.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    YOLO
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Faster-R-CNN.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Faster R-CNN
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Mask-R-CNN.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mask R-CNN
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Diffusion-models.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Diffusion models (for vision generation)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_10_4" >
        
          
          <label class="md-nav__link" for="__nav_2_10_4" id="__nav_2_10_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Common Computer Vision tasks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Common Computer Vision tasks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Image-classification.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Object-detection.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Object detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Face-recognition.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Face recognition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/OCR.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OCR (text from images)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Medical-imaging-analysis.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Medical imaging analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Autonomous-driving-vision.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Autonomous driving vision
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Video-analytics.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Video analytics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer-Vision/Industrial-inspection.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Industrial inspection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../OpenCV/OpenCV/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OpenCV
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_11" >
        
          
          <label class="md-nav__link" for="__nav_2_11" id="__nav_2_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Retrieval-Augmented Generation(RAG)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    Retrieval-Augmented Generation(RAG)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../RAG/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_12" >
        
          
          <label class="md-nav__link" for="__nav_2_12" id="__nav_2_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    AI agents
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    AI agents
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AIagents/aiagents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_13" >
        
          
          <label class="md-nav__link" for="__nav_2_13" id="__nav_2_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Agentic AI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_13">
            <span class="md-nav__icon md-icon"></span>
            
  
    Agentic AI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Framework
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/design-patterns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Design Patterns
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/general/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    general
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/crewai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    crewai
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_13_6" >
        
          
          <label class="md-nav__link" for="__nav_2_13_6" id="__nav_2_13_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    LangGraph
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_13_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    LangGraph
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/LangGraph/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/LangGraphDetails/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LangGraph Graph API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/Subgraphs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Subgraphs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/Interrupts.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Interrupts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/time-travel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Time travel
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/LangGraph-runtime/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LangGraph runtime
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/Durable-execution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Durable execution
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/Install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Install
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/graph-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Graph API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/functional-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Functional API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/local-server/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Run local server
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/workflows/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Workflows
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/persistence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Persistence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/streaming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Streaming
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/interrupts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Interrupts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/graph/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Graph
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/node/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Node
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/LangGraph/edge/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Edge
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/AutoGen/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AutoGen
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/aws/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AWS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_13_9" >
        
          
          <label class="md-nav__link" for="__nav_2_13_9" id="__nav_2_13_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    AZURE
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_13_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    AZURE
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/AZURE/azure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/AZURE/azure-openai-foundry-modelsure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Azure OpenAI Foundry models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_13_10" >
        
          
          <label class="md-nav__link" for="__nav_2_13_10" id="__nav_2_13_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Agent Development Kit
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_13_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Agent Development Kit
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/GCP/adk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ADK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/GCP/Agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/GCP/Tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AgenticAI/GCP/a2a/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_14" >
        
          
          <label class="md-nav__link" for="__nav_2_14" id="__nav_2_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Agent to Agent(A2A)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_14">
            <span class="md-nav__icon md-icon"></span>
            
  
    Agent to Agent(A2A)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../A2A/a2a/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    A2A
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_15" >
        
          
          <label class="md-nav__link" for="__nav_2_15" id="__nav_2_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Temporal
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_15">
            <span class="md-nav__icon md-icon"></span>
            
  
    Temporal
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Temporal/temporal-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Temporal/setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Temporal/core-application/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Core application
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Temporal/Temporal-client/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Temporal Client
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_16" >
        
          
          <label class="md-nav__link" for="__nav_2_16" id="__nav_2_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    MCPModel Context Protocol(MCP)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_16">
            <span class="md-nav__icon md-icon"></span>
            
  
    MCPModel Context Protocol(MCP)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MCP/mcp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MCP
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_17" >
        
          
          <label class="md-nav__link" for="__nav_2_17" id="__nav_2_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Vector Databases
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_17">
            <span class="md-nav__icon md-icon"></span>
            
  
    Vector Databases
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../VectorDatabases/PgVector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PgVector
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../VectorDatabases/OpenSearch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OpenSearch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_18" >
        
          
          <label class="md-nav__link" for="__nav_2_18" id="__nav_2_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Graph Databases
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_18">
            <span class="md-nav__icon md-icon"></span>
            
  
    Graph Databases
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../GraphDatabases/neo4j-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    neo4j setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../GraphDatabases/neo4j-cypher/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    neo4j Cypher
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_19" >
        
          
          <label class="md-nav__link" for="__nav_2_19" id="__nav_2_19_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Models Details information
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_19">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models Details information
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Models/Ollama/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ollama
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_20" >
        
          
          <label class="md-nav__link" for="__nav_2_20" id="__nav_2_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Note Book
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_20">
            <span class="md-nav__icon md-icon"></span>
            
  
    Note Book
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Notebook/allnotebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    All Notebook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_21" >
        
          
          <label class="md-nav__link" for="__nav_2_21" id="__nav_2_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Pypi Library
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_21">
            <span class="md-nav__icon md-icon"></span>
            
  
    Pypi Library
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Pypi/Pypi-lib-details/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pypi Library Details
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


              
              <article class="md-content__inner md-typeset">
                
                  



<p><img alt="langgraph" src="../image/langgraph.png" /></p>
<h1 id="langgraph">LangGraph<a class="headerlink" href="#langgraph" title="Permanent link">#</a></h1>
<p>LangGraph is a low-level orchestration framework for building controllable agents.
While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.</p>
<h1 id="install-the-library">Install the Library<a class="headerlink" href="#install-the-library" title="Permanent link">#</a></h1>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip install -U langgraph
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>pip install -U langchain-anthropic
</span></code></pre></div>
<h1 id="simple-example-below-of-how-to-create-a-react-agent">Simple example below of how to create a ReAct agent.<a class="headerlink" href="#simple-example-below-of-how-to-create-a-react-agent" title="Permanent link">#</a></h1>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a># This code depends on pip install langchain[anthropic]
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>from langgraph.prebuilt import create_react_agent
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>import os
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>from dotenv import load_dotenv
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a># Load environment variables
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>load_dotenv()
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a># Retrieve API tokens from .env
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>ANTHROPIC_API_KEY = os.getenv(&quot;ANTHROPIC_API_KEY&quot;)
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>def search(query: str):
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    &quot;&quot;&quot;Call to surf the web.&quot;&quot;&quot;
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    if &quot;sf&quot; in query.lower() or &quot;san francisco&quot; in query.lower():
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>        return &quot;It&#39;s 60 degrees and foggy.&quot;
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    return &quot;It&#39;s 90 degrees and sunny.&quot;
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>agent = create_react_agent(&quot;anthropic:claude-3-7-sonnet-latest&quot;, tools=[search])
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>agent.invoke(
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    {&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is the weather in sf&quot;}]}
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>)
</span></code></pre></div>
<h1 id="why-use-langgraph">Why use LangGraph?<a class="headerlink" href="#why-use-langgraph" title="Permanent link">#</a></h1>
<p>LangGraph is useful for building <strong>robust, modular, and scalable AI agents</strong>.It extends LangChain with graph-based execution, making it ideal for <strong>multi-agent workflows, streaming, and fine-grained control</strong>.</p>
<p>Developers choose LangGraph for:</p>
<ol>
<li>
<p><strong>Reliability and controllability:</strong> </p>
<ul>
<li>Ensures <strong>structured execution</strong> of agent tasks.</li>
<li>Supports <strong>moderation checks</strong>, human approvals, and context persistence for long-running workflows.</li>
</ul>
</li>
<li>
<p><strong>Low-level and extensible:</strong> </p>
<ul>
<li>Provides <strong>full control</strong> over agent behavior using <strong>custom nodes and state management</strong>.</li>
<li>Ideal for <strong>multi-agent collaboration</strong>, where each agent has a defined role.</li>
</ul>
</li>
<li>
<p><strong>First-Class Streaming Support:</strong></p>
<ul>
<li>Supports <strong>token-by-token streaming</strong>, making it great for <strong>real-time insights</strong> into agent decisions.</li>
<li>Allows <strong>intermediate step streaming</strong>, improving <strong>observability and debugging</strong>.</li>
</ul>
</li>
</ol>
<h1 id="where-is-langgraph-useful">Where is LangGraph Useful?<a class="headerlink" href="#where-is-langgraph-useful" title="Permanent link">#</a></h1>
<ul>
<li><strong>Multi-Agent Systems:</strong> When you need <strong>multiple specialized agents</strong> working together.</li>
<li><strong>Long-Running Workflows:</strong> If your agents need <strong>context persistence</strong> over time.</li>
<li><strong>Interactive Applications:</strong> When <strong>streaming responses</strong> improve user experience.</li>
</ul>
<p>LangGraph can be useful for designing complex AI pipelines where different agents handle different tasks while <strong>maintaining control and visibility</strong>. </p>
<p>LangGraph is already <strong>trusted in production</strong> by major companies for AI-powered automation, making it a solid choice for building <strong>scalable, reliable, and controllable AI agents</strong>.</p>
<h1 id="real-world-use-cases-of-langgraph">Real-World Use Cases of LangGraph<a class="headerlink" href="#real-world-use-cases-of-langgraph" title="Permanent link">#</a></h1>
<ul>
<li><strong>Klarna → Customer Support Bot</strong><ul>
<li>Handles <strong>85 million</strong> active users.</li>
<li>Manages customer inquiries with <strong>multi-step workflows and automation</strong>.</li>
</ul>
</li>
<li><strong>Elastic → Security AI Assistant</strong><ul>
<li>Helps with <strong>threat detection and security analysis</strong>.</li>
<li>Uses <strong>multi-agent collaboration</strong> for investigating security alerts.</li>
</ul>
</li>
<li><strong>Uber → Automated Unit Test Generation</strong><ul>
<li>Generates and refines <strong>unit tests for developers</strong>.</li>
<li>Uses LangGraph for <strong>agent-based coding assistants</strong>.</li>
</ul>
</li>
<li><strong>Replit → AI-Powered Code Generation</strong><ul>
<li>Assists developers in <strong>writing, debugging, and optimizing code</strong>.</li>
<li>Uses LangGraph’s <strong>streaming and multi-agent capabilities</strong>.</li>
</ul>
</li>
</ul>
<h1 id="langgraphs-ecosystem-integrations">LangGraph’s Ecosystem &amp; Integrations<a class="headerlink" href="#langgraphs-ecosystem-integrations" title="Permanent link">#</a></h1>
<p>LangGraph works <strong>standalone</strong> but integrates seamlessly with <strong>LangChain tools</strong>, making it easier to build, evaluate, and deploy AI agents.</p>
<h1 id="key-integrations-for-better-llm-application-development">Key Integrations for Better LLM Application Development<a class="headerlink" href="#key-integrations-for-better-llm-application-development" title="Permanent link">#</a></h1>
<ul>
<li>
<p><strong>LangSmith (Agent Evaluation &amp; Debugging)</strong></p>
<ul>
<li>Debugs <strong>poor-performing LLM runs</strong> and optimizes workflows.</li>
<li>Evaluates <strong>agent trajectories</strong> to improve decision-making.</li>
<li>Provides <strong>observability</strong> in production.</li>
</ul>
</li>
<li>
<p><strong>LangGraph Platform (Scaling &amp; Deployment)</strong></p>
<ul>
<li>Deploys <strong>long-running, stateful AI agents</strong> at scale.</li>
<li>Allows <strong>agent discovery, reuse, and configuration</strong> across teams.</li>
<li>Features <strong>LangGraph Studio</strong> for <strong>visual prototyping</strong> and fast iteration.</li>
</ul>
</li>
</ul>
<h1 id="to-integrate-langgraph-langsmith-into-your-ai-projects">To integrate LangGraph + LangSmith into your AI projects<a class="headerlink" href="#to-integrate-langgraph-langsmith-into-your-ai-projects" title="Permanent link">#</a></h1>
<p><strong>Set Up LangGraph with LangSmith for Debugging &amp; Observability</strong>
- <strong>Install Dependencies</strong>
    - First, install LangGraph, LangSmith, and LangChain:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>        pip install langgraph langsmith langchain
</span></code></pre></div>
<ul>
<li>
<p><strong>Set Up LangSmith API Key</strong>
    Sign up for LangSmith at smith.langchain.com and get your API key.
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>        https://smith.langchain.com/
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>        LANGCHAIN_API_KEY=&quot;your_actual_api_key&quot;
</span></code></pre></div>
Then, set it in your environment:</p>
</li>
<li>
<p><strong>Enable Debugging for Agents</strong></p>
</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>        # This code depends on pip install langchain[anthropic]
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>        from langgraph.prebuilt import create_react_agent
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>        import os
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>        from dotenv import load_dotenv
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        from langchain_openai import ChatOpenAI
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>        from langsmith import traceable
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>        # Load environment variables
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>        load_dotenv()
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        LANGCHAIN_API_KEY = os.getenv(&quot;LANGCHAIN_API_KEY&quot;)
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        OPENAI_API_KEY = os.getenv(&quot;OPENAI_API_KEY&quot;)
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &quot;true&quot;
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>        os.environ[&quot;LANGCHAIN_PROJECT&quot;] = &quot;default&quot;
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>        # Define the function
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>        @traceable
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>        def search(query: str):
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>            &quot;&quot;&quot;Call to surf the web.&quot;&quot;&quot;
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>            if &quot;sf&quot; in query.lower() or &quot;san francisco&quot; in query.lower():
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>                return &quot;It&#39;s 60 degrees and foggy.&quot;
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>            return &quot;It&#39;s 90 degrees and sunny.&quot;
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>        # Use OpenAI&#39;s GPT model
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>        llm = ChatOpenAI(model=&quot;gpt-4-turbo&quot;)
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>        # Create the agent
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>        agent = create_react_agent(llm, tools=[search])
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>        # Invoke the agent
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>        response = agent.invoke({&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the weather in SF?&quot;}]})
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a>
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a>        print(response)
</span></code></pre></div>
<ul>
<li>Now, all agent runs will be logged in LangSmith for debugging.</li>
</ul>
<p><strong>Visualizing &amp; Debugging Agent Trajectories in LangSmith</strong></p>
<p>Once the agent is running, go to LangSmith UI and check:</p>
<ul>
<li>Logs of each agent action (inputs, outputs, reasoning).</li>
<li>Failure points in decision-making.</li>
<li>Performance metrics to optimize.</li>
</ul>
<p><img alt="langsmith" src="../image/langsmith.png" /></p>
<p><img alt="langsmith" src="../image/langsmith-1.png" /></p>
<p><strong>Scaling with LangGraph Platform (Long-Running Agents &amp; Deployment)</strong></p>
<ul>
<li>To make your AI <strong>stateful and scalable</strong>, use <strong>LangGraph Platform:</strong></li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>pip install langgraph[platform]
</span></code></pre></div>
<ul>
<li>Deploy <strong>long-running agents</strong> with <strong>stateful memory</strong>.</li>
<li>Use <strong>LangGraph Studio</strong> for <strong>drag-and-drop workflow design</strong>.</li>
<li>Share &amp; configure agents <strong>across teams</strong>.</li>
</ul>
<h1 id="graph-api-basics">Graph API Basics<a class="headerlink" href="#graph-api-basics" title="Permanent link">#</a></h1>
<h2 id="how-to-update-graph-state-from-nodes">How to update graph state from nodes<a class="headerlink" href="#how-to-update-graph-state-from-nodes" title="Permanent link">#</a></h2>
<p><strong>Define state</strong>
State in <strong>LangGraph</strong> can be a <strong>TypedDict</strong>, <strong>Pydantic</strong> model, or dataclass. </p>
<p><strong>State:</strong>
The first thing you do when you define a graph is define the State of the graph. The State consists of the schema of the graph as well as reducer functions which specify how to apply updates to the state.
The schema of the State will be the input schema to all Nodes and Edges in the graph, and can be either a TypedDict or a Pydantic model. All Nodes will emit updates to the State which are then applied using the specified reducer function.</p>
<p><strong>Schema:</strong>
The main documented way to specify the schema of a graph is by using TypedDict. However, we also support using a Pydantic BaseModel as your graph state to add default values and additional data validation.</p>
<h2 id="how-to-use-pydantic-model-as-graph-state">How to use Pydantic model as graph state<a class="headerlink" href="#how-to-use-pydantic-model-as-graph-state" title="Permanent link">#</a></h2>
<p><strong>First we need to install the packages required</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>%%capture --no-stderr
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>%pip install --quiet -U langgraph
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>import getpass
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>import os
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>def _set_env(var: str):
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    if not os.environ.get(var):
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>_set_env(&quot;OPENAI_API_KEY&quot;)
</span></code></pre></div>
<h2 id="input-validation">Input Validation<a class="headerlink" href="#input-validation" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>from typing_extensions import TypedDict
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>from pydantic import BaseModel
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a># The overall state of the graph (this is the public state shared across nodes)
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>class OverallState(BaseModel):
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    a: str
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>def node(state: OverallState):
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>    return {&quot;a&quot;: &quot;goodbye&quot;}
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a># Build the state graph
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>builder = StateGraph(OverallState)
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>builder.add_node(node)  # node_1 is the first node
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>builder.add_edge(START, &quot;node&quot;)  # Start the graph with node_1
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>builder.add_edge(&quot;node&quot;, END)  # End the graph after node_1
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>graph = builder.compile()
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>
</span><span id="__span-8-23"><a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a># Test the graph with a valid input
</span><span id="__span-8-24"><a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a>graph.invoke({&quot;a&quot;: &quot;hello&quot;})
</span></code></pre></div>
<p><strong>Output:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>{&#39;a&#39;: &#39;goodbye&#39;}
</span></code></pre></div>
<p><strong>Invoke the graph with an invalid input</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>try:
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>    graph.invoke({&quot;a&quot;: 123})  # Should be a string
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>except Exception as e:
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>    print(&quot;An exception was raised because `a` is an integer rather than a string.&quot;)
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>    print(e)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>An exception was raised because `a` is an integer rather than a string.
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>1 validation error for OverallState
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>a
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>  Input should be a valid string [type=string_type, input_value=123, input_type=int]
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    For further information visit https://errors.pydantic.dev/2.9/v/string_type
</span></code></pre></div>
<h2 id="multiple-nodes">Multiple Nodes<a class="headerlink" href="#multiple-nodes" title="Permanent link">#</a></h2>
<p>Run-time validation will also work in a multi-node graph. In the example below bad_node updates a to an integer.</p>
<p>Because run-time validation occurs on inputs, the validation error will occur when ok_node is called (not when bad_node returns an update to the state which is inconsistent with the schema).</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>from typing_extensions import TypedDict
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>from pydantic import BaseModel
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a># The overall state of the graph (this is the public state shared across nodes)
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>class OverallState(BaseModel):
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>    a: str
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>def bad_node(state: OverallState):
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>    return {
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>        &quot;a&quot;: 123  # Invalid
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>    }
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>def ok_node(state: OverallState):
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>    return {&quot;a&quot;: &quot;goodbye&quot;}
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a># Build the state graph
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>builder = StateGraph(OverallState)
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>builder.add_node(bad_node)
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>builder.add_node(ok_node)
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>builder.add_edge(START, &quot;bad_node&quot;)
</span><span id="__span-12-27"><a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>builder.add_edge(&quot;bad_node&quot;, &quot;ok_node&quot;)
</span><span id="__span-12-28"><a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>builder.add_edge(&quot;ok_node&quot;, END)
</span><span id="__span-12-29"><a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>graph = builder.compile()
</span><span id="__span-12-30"><a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a>
</span><span id="__span-12-31"><a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a># Test the graph with a valid input
</span><span id="__span-12-32"><a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>try:
</span><span id="__span-12-33"><a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>    graph.invoke({&quot;a&quot;: &quot;hello&quot;})
</span><span id="__span-12-34"><a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>except Exception as e:
</span><span id="__span-12-35"><a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>    print(&quot;An exception was raised because bad_node sets `a` to an integer.&quot;)
</span><span id="__span-12-36"><a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>    print(e)
</span></code></pre></div>
<p><strong>Output:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>An exception was raised because bad_node sets `a` to an integer.
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>1 validation error for OverallState
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>a
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>  Input should be a valid string [type=string_type, input_value=123, input_type=int]
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>    For further information visit https://errors.pydantic.dev/2.9/v/string_type
</span></code></pre></div>
<h2 id="advanced-pydantic-model-usage">Advanced Pydantic Model Usage<a class="headerlink" href="#advanced-pydantic-model-usage" title="Permanent link">#</a></h2>
<p>This section covers more advanced topics when using Pydantic models with LangGraph.</p>
<p><strong>Serialization Behavior</strong></p>
<p>When using Pydantic models as state schemas, it's important to understand how serialization works, especially when: - Passing Pydantic objects as inputs - Receiving outputs from the graph - Working with nested Pydantic models</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>from pydantic import BaseModel
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>class NestedModel(BaseModel):
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>    value: str
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>class ComplexState(BaseModel):
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>    text: str
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>    count: int
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>    nested: NestedModel
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>def process_node(state: ComplexState):
</span><span id="__span-14-16"><a id="__codelineno-14-16" name="__codelineno-14-16" href="#__codelineno-14-16"></a>    # Node receives a validated Pydantic object
</span><span id="__span-14-17"><a id="__codelineno-14-17" name="__codelineno-14-17" href="#__codelineno-14-17"></a>    print(f&quot;Input state type: {type(state)}&quot;)
</span><span id="__span-14-18"><a id="__codelineno-14-18" name="__codelineno-14-18" href="#__codelineno-14-18"></a>    print(f&quot;Nested type: {type(state.nested)}&quot;)
</span><span id="__span-14-19"><a id="__codelineno-14-19" name="__codelineno-14-19" href="#__codelineno-14-19"></a>
</span><span id="__span-14-20"><a id="__codelineno-14-20" name="__codelineno-14-20" href="#__codelineno-14-20"></a>    # Return a dictionary update
</span><span id="__span-14-21"><a id="__codelineno-14-21" name="__codelineno-14-21" href="#__codelineno-14-21"></a>    return {&quot;text&quot;: state.text + &quot; processed&quot;, &quot;count&quot;: state.count + 1}
</span><span id="__span-14-22"><a id="__codelineno-14-22" name="__codelineno-14-22" href="#__codelineno-14-22"></a>
</span><span id="__span-14-23"><a id="__codelineno-14-23" name="__codelineno-14-23" href="#__codelineno-14-23"></a>
</span><span id="__span-14-24"><a id="__codelineno-14-24" name="__codelineno-14-24" href="#__codelineno-14-24"></a># Build the graph
</span><span id="__span-14-25"><a id="__codelineno-14-25" name="__codelineno-14-25" href="#__codelineno-14-25"></a>builder = StateGraph(ComplexState)
</span><span id="__span-14-26"><a id="__codelineno-14-26" name="__codelineno-14-26" href="#__codelineno-14-26"></a>builder.add_node(&quot;process&quot;, process_node)
</span><span id="__span-14-27"><a id="__codelineno-14-27" name="__codelineno-14-27" href="#__codelineno-14-27"></a>builder.add_edge(START, &quot;process&quot;)
</span><span id="__span-14-28"><a id="__codelineno-14-28" name="__codelineno-14-28" href="#__codelineno-14-28"></a>builder.add_edge(&quot;process&quot;, END)
</span><span id="__span-14-29"><a id="__codelineno-14-29" name="__codelineno-14-29" href="#__codelineno-14-29"></a>graph = builder.compile()
</span><span id="__span-14-30"><a id="__codelineno-14-30" name="__codelineno-14-30" href="#__codelineno-14-30"></a>
</span><span id="__span-14-31"><a id="__codelineno-14-31" name="__codelineno-14-31" href="#__codelineno-14-31"></a># Create a Pydantic instance for input
</span><span id="__span-14-32"><a id="__codelineno-14-32" name="__codelineno-14-32" href="#__codelineno-14-32"></a>input_state = ComplexState(text=&quot;hello&quot;, count=0, nested=NestedModel(value=&quot;test&quot;))
</span><span id="__span-14-33"><a id="__codelineno-14-33" name="__codelineno-14-33" href="#__codelineno-14-33"></a>print(f&quot;Input object type: {type(input_state)}&quot;)
</span><span id="__span-14-34"><a id="__codelineno-14-34" name="__codelineno-14-34" href="#__codelineno-14-34"></a>
</span><span id="__span-14-35"><a id="__codelineno-14-35" name="__codelineno-14-35" href="#__codelineno-14-35"></a># Invoke graph with a Pydantic instance
</span><span id="__span-14-36"><a id="__codelineno-14-36" name="__codelineno-14-36" href="#__codelineno-14-36"></a>result = graph.invoke(input_state)
</span><span id="__span-14-37"><a id="__codelineno-14-37" name="__codelineno-14-37" href="#__codelineno-14-37"></a>print(f&quot;Output type: {type(result)}&quot;)
</span><span id="__span-14-38"><a id="__codelineno-14-38" name="__codelineno-14-38" href="#__codelineno-14-38"></a>print(f&quot;Output content: {result}&quot;)
</span><span id="__span-14-39"><a id="__codelineno-14-39" name="__codelineno-14-39" href="#__codelineno-14-39"></a>
</span><span id="__span-14-40"><a id="__codelineno-14-40" name="__codelineno-14-40" href="#__codelineno-14-40"></a># Convert back to Pydantic model if needed
</span><span id="__span-14-41"><a id="__codelineno-14-41" name="__codelineno-14-41" href="#__codelineno-14-41"></a>output_model = ComplexState(**result)
</span><span id="__span-14-42"><a id="__codelineno-14-42" name="__codelineno-14-42" href="#__codelineno-14-42"></a>print(f&quot;Converted back to Pydantic: {type(output_model)}&quot;)
</span></code></pre></div>
<p><strong>Runtime Type Coercion</strong>
Pydantic performs runtime type coercion for certain data types. This can be helpful but also lead to unexpected behavior if you're not aware of it.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>from pydantic import BaseModel
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>class CoercionExample(BaseModel):
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>    # Pydantic will coerce string numbers to integers
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>    number: int
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>    # Pydantic will parse string booleans to bool
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>    flag: bool
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>def inspect_node(state: CoercionExample):
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>    print(f&quot;number: {state.number} (type: {type(state.number)})&quot;)
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>    print(f&quot;flag: {state.flag} (type: {type(state.flag)})&quot;)
</span><span id="__span-15-15"><a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>    return {}
</span><span id="__span-15-16"><a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>
</span><span id="__span-15-17"><a id="__codelineno-15-17" name="__codelineno-15-17" href="#__codelineno-15-17"></a>
</span><span id="__span-15-18"><a id="__codelineno-15-18" name="__codelineno-15-18" href="#__codelineno-15-18"></a>builder = StateGraph(CoercionExample)
</span><span id="__span-15-19"><a id="__codelineno-15-19" name="__codelineno-15-19" href="#__codelineno-15-19"></a>builder.add_node(&quot;inspect&quot;, inspect_node)
</span><span id="__span-15-20"><a id="__codelineno-15-20" name="__codelineno-15-20" href="#__codelineno-15-20"></a>builder.add_edge(START, &quot;inspect&quot;)
</span><span id="__span-15-21"><a id="__codelineno-15-21" name="__codelineno-15-21" href="#__codelineno-15-21"></a>builder.add_edge(&quot;inspect&quot;, END)
</span><span id="__span-15-22"><a id="__codelineno-15-22" name="__codelineno-15-22" href="#__codelineno-15-22"></a>graph = builder.compile()
</span><span id="__span-15-23"><a id="__codelineno-15-23" name="__codelineno-15-23" href="#__codelineno-15-23"></a>
</span><span id="__span-15-24"><a id="__codelineno-15-24" name="__codelineno-15-24" href="#__codelineno-15-24"></a># Demonstrate coercion with string inputs that will be converted
</span><span id="__span-15-25"><a id="__codelineno-15-25" name="__codelineno-15-25" href="#__codelineno-15-25"></a>result = graph.invoke({&quot;number&quot;: &quot;42&quot;, &quot;flag&quot;: &quot;true&quot;})
</span><span id="__span-15-26"><a id="__codelineno-15-26" name="__codelineno-15-26" href="#__codelineno-15-26"></a>
</span><span id="__span-15-27"><a id="__codelineno-15-27" name="__codelineno-15-27" href="#__codelineno-15-27"></a># This would fail with a validation error
</span><span id="__span-15-28"><a id="__codelineno-15-28" name="__codelineno-15-28" href="#__codelineno-15-28"></a>try:
</span><span id="__span-15-29"><a id="__codelineno-15-29" name="__codelineno-15-29" href="#__codelineno-15-29"></a>    graph.invoke({&quot;number&quot;: &quot;not-a-number&quot;, &quot;flag&quot;: &quot;true&quot;})
</span><span id="__span-15-30"><a id="__codelineno-15-30" name="__codelineno-15-30" href="#__codelineno-15-30"></a>except Exception as e:
</span><span id="__span-15-31"><a id="__codelineno-15-31" name="__codelineno-15-31" href="#__codelineno-15-31"></a>    print(f&quot;\nExpected validation error: {e}&quot;)
</span></code></pre></div>
<p><strong>Working with Message Models</strong>
When working with LangChain message types in your state schema, there are important considerations for serialization. You should use AnyMessage (rather than BaseMessage) for proper serialization/deserialization when using message objects over the wire:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>from pydantic import BaseModel
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>from langchain_core.messages import HumanMessage, AIMessage, AnyMessage
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>from typing import List
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>class ChatState(BaseModel):
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>    messages: List[AnyMessage]
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a>    context: str
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a>
</span><span id="__span-16-11"><a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>
</span><span id="__span-16-12"><a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a>def add_message(state: ChatState):
</span><span id="__span-16-13"><a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a>    return {&quot;messages&quot;: state.messages + [AIMessage(content=&quot;Hello there!&quot;)]}
</span><span id="__span-16-14"><a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>
</span><span id="__span-16-15"><a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>
</span><span id="__span-16-16"><a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a>builder = StateGraph(ChatState)
</span><span id="__span-16-17"><a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>builder.add_node(&quot;add_message&quot;, add_message)
</span><span id="__span-16-18"><a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>builder.add_edge(START, &quot;add_message&quot;)
</span><span id="__span-16-19"><a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a>builder.add_edge(&quot;add_message&quot;, END)
</span><span id="__span-16-20"><a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a>graph = builder.compile()
</span><span id="__span-16-21"><a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>
</span><span id="__span-16-22"><a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a># Create input with a message
</span><span id="__span-16-23"><a id="__codelineno-16-23" name="__codelineno-16-23" href="#__codelineno-16-23"></a>initial_state = ChatState(
</span><span id="__span-16-24"><a id="__codelineno-16-24" name="__codelineno-16-24" href="#__codelineno-16-24"></a>    messages=[HumanMessage(content=&quot;Hi&quot;)], context=&quot;Customer support chat&quot;
</span><span id="__span-16-25"><a id="__codelineno-16-25" name="__codelineno-16-25" href="#__codelineno-16-25"></a>)
</span><span id="__span-16-26"><a id="__codelineno-16-26" name="__codelineno-16-26" href="#__codelineno-16-26"></a>
</span><span id="__span-16-27"><a id="__codelineno-16-27" name="__codelineno-16-27" href="#__codelineno-16-27"></a>result = graph.invoke(initial_state)
</span><span id="__span-16-28"><a id="__codelineno-16-28" name="__codelineno-16-28" href="#__codelineno-16-28"></a>print(f&quot;Output: {result}&quot;)
</span><span id="__span-16-29"><a id="__codelineno-16-29" name="__codelineno-16-29" href="#__codelineno-16-29"></a>
</span><span id="__span-16-30"><a id="__codelineno-16-30" name="__codelineno-16-30" href="#__codelineno-16-30"></a># Convert back to Pydantic model to see message types
</span><span id="__span-16-31"><a id="__codelineno-16-31" name="__codelineno-16-31" href="#__codelineno-16-31"></a>output_model = ChatState(**result)
</span><span id="__span-16-32"><a id="__codelineno-16-32" name="__codelineno-16-32" href="#__codelineno-16-32"></a>for i, msg in enumerate(output_model.messages):
</span><span id="__span-16-33"><a id="__codelineno-16-33" name="__codelineno-16-33" href="#__codelineno-16-33"></a>    print(f&quot;Message {i}: {type(msg).__name__} - {msg.content}&quot;)
</span></code></pre></div>
<h2 id="graphs">Graphs<a class="headerlink" href="#graphs" title="Permanent link">#</a></h2>
<p>At its core, LangGraph models agent workflows as graphs. You define the behavior of your agents using three key components:</p>
<ol>
<li>
<p><strong>State:</strong> A shared data structure that represents the current snapshot of your application. It can be any Python type, but is typically a TypedDict or Pydantic BaseModel.</p>
</li>
<li>
<p><strong>Nodes:</strong> Python functions that encode the logic of your agents. They receive the current State as input, perform some computation or side-effect, and return an updated State.</p>
</li>
<li>
<p><strong>Edges:</strong> Python functions that determine which Node to execute next based on the current State. They can be conditional branches or fixed transitions.</p>
</li>
</ol>
<p>By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State.</p>
<p>To emphasize: Nodes and Edges are nothing more than Python functions - they can contain an LLM or just good ol' Python code.</p>
<p><strong>In short:</strong> <strong>nodes</strong> do the work. <strong>edges</strong> tell what to do next.</p>
<p>LangGraph's underlying graph algorithm uses message passing to define a general program. When a Node completes its operation, it sends messages along one or more edges to other node(s).</p>
<p>These recipient nodes then execute their functions, pass the resulting messages to the next set of nodes, and the process continues.</p>
<p>A super-step can be considered a single iteration over the graph nodes. Nodes that run in parallel are part of the same super-step, while nodes that run sequentially belong to separate super-steps. At the start of graph execution, all nodes begin in an inactive state. A node becomes active when it receives a new message (state) on any of its incoming edges (or "channels"). The active node then runs its function and responds with updates. At the end of each super-step, nodes with no incoming messages vote to halt by marking themselves as inactive. The graph execution terminates when all nodes are inactive and no messages are in transit.</p>
<p><strong>StateGraph:</strong>
The StateGraph class is the main graph class to use. This is parameterized by a user defined State object.</p>
<p><strong>Compiling your graph:</strong>
To build your graph, you first define the <strong>state</strong>, you then add <strong>nodes</strong> and <strong>edges</strong>, and then you compile it. What exactly is compiling your graph and why is it needed?</p>
<p>Compiling is a pretty simple step. It provides a few basic checks on the structure of your graph (no orphaned nodes, etc). It is also where you can specify runtime args like <strong>checkpointers</strong> and <strong>breakpoints</strong>. You compile your graph by just calling the <strong>.compile</strong> method:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>graph = graph_builder.compile(...)
</span></code></pre></div>
<p><strong>Note:</strong> You MUST compile your graph before you can use it.</p>
<p><strong>Multiple schemas</strong>
Typically, all graph nodes communicate with a single schema. This means that they will read and write to the same state channels. But, there are cases where we want more control over this:</p>
<ul>
<li>Internal nodes can pass information that is not required in the graph's input / output.</li>
<li>We may also want to use different input / output schemas for the graph. The output might, for example, only contain a single relevant output key.</li>
</ul>
<p>It is possible to have nodes write to private state channels inside the graph for internal node communication. We can simply define a private schema, <strong>PrivateState</strong>.</p>
<p><strong>Let's look at an example:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>class InputState(TypedDict):
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>    user_input: str
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>class OutputState(TypedDict):
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>    graph_output: str
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>class OverallState(TypedDict):
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a>    foo: str
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>    user_input: str
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a>    graph_output: str
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a>class PrivateState(TypedDict):
</span><span id="__span-18-13"><a id="__codelineno-18-13" name="__codelineno-18-13" href="#__codelineno-18-13"></a>    bar: str
</span><span id="__span-18-14"><a id="__codelineno-18-14" name="__codelineno-18-14" href="#__codelineno-18-14"></a>
</span><span id="__span-18-15"><a id="__codelineno-18-15" name="__codelineno-18-15" href="#__codelineno-18-15"></a>def node_1(state: InputState) -&gt; OverallState:
</span><span id="__span-18-16"><a id="__codelineno-18-16" name="__codelineno-18-16" href="#__codelineno-18-16"></a>    # Write to OverallState
</span><span id="__span-18-17"><a id="__codelineno-18-17" name="__codelineno-18-17" href="#__codelineno-18-17"></a>    return {&quot;foo&quot;: state[&quot;user_input&quot;] + &quot; name&quot;}
</span><span id="__span-18-18"><a id="__codelineno-18-18" name="__codelineno-18-18" href="#__codelineno-18-18"></a>
</span><span id="__span-18-19"><a id="__codelineno-18-19" name="__codelineno-18-19" href="#__codelineno-18-19"></a>def node_2(state: OverallState) -&gt; PrivateState:
</span><span id="__span-18-20"><a id="__codelineno-18-20" name="__codelineno-18-20" href="#__codelineno-18-20"></a>    # Read from OverallState, write to PrivateState
</span><span id="__span-18-21"><a id="__codelineno-18-21" name="__codelineno-18-21" href="#__codelineno-18-21"></a>    return {&quot;bar&quot;: state[&quot;foo&quot;] + &quot; is&quot;}
</span><span id="__span-18-22"><a id="__codelineno-18-22" name="__codelineno-18-22" href="#__codelineno-18-22"></a>
</span><span id="__span-18-23"><a id="__codelineno-18-23" name="__codelineno-18-23" href="#__codelineno-18-23"></a>def node_3(state: PrivateState) -&gt; OutputState:
</span><span id="__span-18-24"><a id="__codelineno-18-24" name="__codelineno-18-24" href="#__codelineno-18-24"></a>    # Read from PrivateState, write to OutputState
</span><span id="__span-18-25"><a id="__codelineno-18-25" name="__codelineno-18-25" href="#__codelineno-18-25"></a>    return {&quot;graph_output&quot;: state[&quot;bar&quot;] + &quot; Lance&quot;}
</span><span id="__span-18-26"><a id="__codelineno-18-26" name="__codelineno-18-26" href="#__codelineno-18-26"></a>
</span><span id="__span-18-27"><a id="__codelineno-18-27" name="__codelineno-18-27" href="#__codelineno-18-27"></a>builder = StateGraph(OverallState,input=InputState,output=OutputState)
</span><span id="__span-18-28"><a id="__codelineno-18-28" name="__codelineno-18-28" href="#__codelineno-18-28"></a>builder.add_node(&quot;node_1&quot;, node_1)
</span><span id="__span-18-29"><a id="__codelineno-18-29" name="__codelineno-18-29" href="#__codelineno-18-29"></a>builder.add_node(&quot;node_2&quot;, node_2)
</span><span id="__span-18-30"><a id="__codelineno-18-30" name="__codelineno-18-30" href="#__codelineno-18-30"></a>builder.add_node(&quot;node_3&quot;, node_3)
</span><span id="__span-18-31"><a id="__codelineno-18-31" name="__codelineno-18-31" href="#__codelineno-18-31"></a>builder.add_edge(START, &quot;node_1&quot;)
</span><span id="__span-18-32"><a id="__codelineno-18-32" name="__codelineno-18-32" href="#__codelineno-18-32"></a>builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)
</span><span id="__span-18-33"><a id="__codelineno-18-33" name="__codelineno-18-33" href="#__codelineno-18-33"></a>builder.add_edge(&quot;node_2&quot;, &quot;node_3&quot;)
</span><span id="__span-18-34"><a id="__codelineno-18-34" name="__codelineno-18-34" href="#__codelineno-18-34"></a>builder.add_edge(&quot;node_3&quot;, END)
</span><span id="__span-18-35"><a id="__codelineno-18-35" name="__codelineno-18-35" href="#__codelineno-18-35"></a>
</span><span id="__span-18-36"><a id="__codelineno-18-36" name="__codelineno-18-36" href="#__codelineno-18-36"></a>graph = builder.compile()
</span><span id="__span-18-37"><a id="__codelineno-18-37" name="__codelineno-18-37" href="#__codelineno-18-37"></a>graph.invoke({&quot;user_input&quot;:&quot;My&quot;})
</span><span id="__span-18-38"><a id="__codelineno-18-38" name="__codelineno-18-38" href="#__codelineno-18-38"></a>{&#39;graph_output&#39;: &#39;My name is Lance&#39;}
</span></code></pre></div>
<p>There are two subtle and important points to note here:</p>
<ol>
<li>
<p>We pass state: InputState as the input schema to node_1. But, we write out to foo, a channel in OverallState. How can we write out to a state channel that is not included in the input schema? This is because a node can write to any state channel in the graph state. The graph state is the union of of the state channels defined at initialization, which includes OverallState and the filters InputState and OutputState.</p>
</li>
<li>
<p>We initialize the graph with StateGraph(OverallState,input=InputState,output=OutputState). So, how can we write to PrivateState in node_2? How does the graph gain access to this schema if it was not passed in the StateGraph initialization? We can do this because nodes can also declare additional state channels as long as the state schema definition exists. In this case, the PrivateState schema is defined, so we can add bar as a new state channel in the graph and write to it.</p>
</li>
</ol>
<h2 id="reducers">Reducers<a class="headerlink" href="#reducers" title="Permanent link">#</a></h2>
<p>Reducers are key to understanding how updates from nodes are applied to the State. Each key in the State has its own independent reducer function. If no reducer function is explicitly specified then it is assumed that all updates to that key should override it. There are a few different types of reducers, starting with the default type of reducer:</p>
<p><strong>Default Reducer</strong></p>
<p>These two examples show how to use the default reducer:</p>
<p><strong>Example A:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>from typing_extensions import TypedDict
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>class State(TypedDict):
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>    foo: int
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>    bar: list[str]
</span></code></pre></div>
<p>In this example, no reducer functions are specified for any key. Let's assume the input to the graph is {"foo": 1, "bar": ["hi"]}. Let's then assume the first Node returns {"foo": 2}. This is treated as an update to the state. Notice that the Node does not need to return the whole State schema - just an update. After applying this update, the State would then be {"foo": 2, "bar": ["hi"]}. If the second node returns {"bar": ["bye"]} then the State would then be {"foo": 2, "bar": ["bye"]}</p>
<p><strong>Example B:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>from typing import Annotated
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>from typing_extensions import TypedDict
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>from operator import add
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>class State(TypedDict):
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>    foo: int
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a>    bar: Annotated[list[str], add]
</span></code></pre></div>
<p>In this example, we've used the Annotated type to specify a reducer function (operator.add) for the second key (bar). Note that the first key remains unchanged. Let's assume the input to the graph is {"foo": 1, "bar": ["hi"]}. Let's then assume the first Node returns {"foo": 2}. This is treated as an update to the state. Notice that the Node does not need to return the whole State schema - just an update. After applying this update, the State would then be {"foo": 2, "bar": ["hi"]}. If the second node returns {"bar": ["bye"]} then the State would then be {"foo": 2, "bar": ["hi", "bye"]}. Notice here that the bar key is updated by adding the two lists together.</p>
<h2 id="working-with-messages-in-graph-state">Working with Messages in Graph State<a class="headerlink" href="#working-with-messages-in-graph-state" title="Permanent link">#</a></h2>
<p><strong>Why use messages?</strong></p>
<p>Most modern LLM providers have a chat model interface that accepts a list of messages as input. LangChain's ChatModel in particular accepts a list of Message objects as inputs. These messages come in a variety of forms such as HumanMessage (user input) or AIMessage (LLM response). To read more about what message objects are, please refer to this conceptual guide.</p>
<p><strong>Using Messages in your Graph</strong>
In many cases, it is helpful to store prior conversation history as a list of messages in your graph state. To do so, we can add a key (channel) to the graph state that stores a list of Message objects and annotate it with a reducer function (see messages key in the example below). The reducer function is vital to telling the graph how to update the list of Message objects in the state with each state update (for example, when a node sends an update). If you don't specify a reducer, every state update will overwrite the list of messages with the most recently provided value. If you wanted to simply append messages to the existing list, you could use operator.add as a reducer.</p>
<p>However, you might also want to manually update messages in your graph state (e.g. human-in-the-loop). If you were to use operator.add, the manual state updates you send to the graph would be appended to the existing list of messages, instead of updating existing messages. To avoid that, you need a reducer that can keep track of message IDs and overwrite existing messages, if updated. To achieve this, you can use the prebuilt add_messages function. For brand new messages, it will simply append to existing list, but it will also handle the updates for existing messages correctly.</p>
<p><strong>Serialization</strong>
In addition to keeping track of message IDs, the add_messages function will also try to deserialize messages into LangChain Message objects whenever a state update is received on the messages channel. See more information on LangChain serialization/deserialization here. This allows sending graph inputs / state updates in the following format:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a># this is supported
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>{&quot;messages&quot;: [HumanMessage(content=&quot;message&quot;)]}
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a># and this is also supported
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>{&quot;messages&quot;: [{&quot;type&quot;: &quot;human&quot;, &quot;content&quot;: &quot;message&quot;}]}
</span></code></pre></div>
<p>Since the state updates are always deserialized into LangChain Messages when using add_messages, you should use dot notation to access message attributes, like state["messages"][-1].content. Below is an example of a graph that uses add_messages as it's reducer function.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>from langchain_core.messages import AnyMessage
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>from langgraph.graph.message import add_messages
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>from typing import Annotated
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>from typing_extensions import TypedDict
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>class GraphState(TypedDict):
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>    messages: Annotated[list[AnyMessage], add_messages]
</span></code></pre></div>
<p><strong>MessagesState</strong></p>
<p>Since having a list of messages in your state is so common, there exists a prebuilt state called MessagesState which makes it easy to use messages. MessagesState is defined with a single messages key which is a list of AnyMessage objects and uses the add_messages reducer. Typically, there is more state to track than just messages, so we see people subclass this state and add more fields, like:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>from langgraph.graph import MessagesState
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>class State(MessagesState):
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>    documents: list[str]
</span></code></pre></div>
<h2 id="nodes">Nodes<a class="headerlink" href="#nodes" title="Permanent link">#</a></h2>
<p>In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a "config", containing optional configurable parameters (such as a thread_id).</p>
<p>Similar to NetworkX, you add these nodes to a graph using the add_node method:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>from langchain_core.runnables import RunnableConfig
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>from langgraph.graph import StateGraph
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>builder = StateGraph(dict)
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>def my_node(state: dict, config: RunnableConfig):
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>    print(&quot;In node: &quot;, config[&quot;configurable&quot;][&quot;user_id&quot;])
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>    return {&quot;results&quot;: f&quot;Hello, {state[&#39;input&#39;]}!&quot;}
</span><span id="__span-24-10"><a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>
</span><span id="__span-24-11"><a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>
</span><span id="__span-24-12"><a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a># The second argument is optional
</span><span id="__span-24-13"><a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>def my_other_node(state: dict):
</span><span id="__span-24-14"><a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a>    return state
</span><span id="__span-24-15"><a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a>
</span><span id="__span-24-16"><a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>
</span><span id="__span-24-17"><a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a>builder.add_node(&quot;my_node&quot;, my_node)
</span><span id="__span-24-18"><a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>builder.add_node(&quot;other_node&quot;, my_other_node)
</span><span id="__span-24-19"><a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a>...
</span></code></pre></div>
<p>Behind the scenes, functions are converted to RunnableLambdas, which add batch and async support to your function, along with native tracing and debugging.</p>
<p>If you add a node to a graph without specifying a name, it will be given a default name equivalent to the function name.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>builder.add_node(my_node)
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a># You can then create edges to/from this node by referencing it as `&quot;my_node&quot;`
</span></code></pre></div>
<h2 id="start-node">START Node<a class="headerlink" href="#start-node" title="Permanent link">#</a></h2>
<p>The START Node is a special node that represents the node that sends user input to the graph. The main purpose for referencing this node is to determine which nodes should be called first.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>from langgraph.graph import START
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>graph.add_edge(START, &quot;node_a&quot;)
</span></code></pre></div>
<h2 id="end-node">END Node<a class="headerlink" href="#end-node" title="Permanent link">#</a></h2>
<p>The END Node is a special node that represents a terminal node. This node is referenced when you want to denote which edges have no actions after they are done.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>from langgraph.graph import END
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>graph.add_edge(&quot;node_a&quot;, END)
</span></code></pre></div>
<h2 id="edges">Edges<a class="headerlink" href="#edges" title="Permanent link">#</a></h2>
<p>Edges define how the logic is routed and how the graph decides to stop. This is a big part of how your agents work and how different nodes communicate with each other. There are a few key types of edges:</p>
<ul>
<li><strong>Normal Edges:</strong> Go directly from one node to the next.</li>
<li><strong>Conditional Edges:</strong> Call a function to determine which node(s) to go to next.</li>
<li><strong>Entry Point:</strong> Which node to call first when user input arrives.</li>
<li><strong>Conditional Entry Point:</strong> Call a function to determine which node(s) to call first when user input arrives.</li>
</ul>
<p>A node can have MULTIPLE outgoing edges. If a node has multiple out-going edges, all of those destination nodes will be executed in parallel as a part of the next superstep.</p>
<p><strong>Normal Edges:</strong>
If you always want to go from node A to node B, you can use the add_edge method directly.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>graph.add_edge(&quot;node_a&quot;, &quot;node_b&quot;)
</span></code></pre></div>
<p><strong>Conditional Edges:</strong>
If you want to optionally route to 1 or more edges (or optionally terminate), you can use the add_conditional_edges method. This method accepts the name of a node and a "routing function" to call after that node is executed:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>graph.add_conditional_edges(&quot;node_a&quot;, routing_function)
</span></code></pre></div>
<p>Similar to nodes, the routing_function accepts the current state of the graph and returns a value.</p>
<p>By default, the return value routing_function is used as the name of the node (or list of nodes) to send the state to next. All those nodes will be run in parallel as a part of the next superstep.</p>
<p>You can optionally provide a dictionary that maps the routing_function's output to the name of the next node.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>graph.add_conditional_edges(&quot;node_a&quot;, routing_function, {True: &quot;node_b&quot;, False: &quot;node_c&quot;})
</span></code></pre></div>
<p><strong>Note:</strong> Use Command instead of conditional edges if you want to combine state updates and routing in a single function.</p>
<p><strong>Command</strong>
It can be useful to combine control flow (edges) and state updates (nodes). For example, you might want to BOTH perform state updates AND decide which node to go to next in the SAME node. LangGraph provides a way to do so by returning a Command object from node functions:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>def my_node(state: State) -&gt; Command[Literal[&quot;my_other_node&quot;]]:
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a>    return Command(
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>        # state update
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>        update={&quot;foo&quot;: &quot;bar&quot;},
</span><span id="__span-31-5"><a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a>        # control flow
</span><span id="__span-31-6"><a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a>        goto=&quot;my_other_node&quot;
</span><span id="__span-31-7"><a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a>    )
</span></code></pre></div>
<p>With Command you can also achieve dynamic control flow behavior (identical to conditional edges):</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>def my_node(state: State) -&gt; Command[Literal[&quot;my_other_node&quot;]]:
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>    if state[&quot;foo&quot;] == &quot;bar&quot;:
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>        return Command(update={&quot;foo&quot;: &quot;baz&quot;}, goto=&quot;my_other_node&quot;)
</span></code></pre></div>
<p><strong>Important</strong>
When returning Command in your node functions, you must add return type annotations with the list of node names the node is routing to, e.g. Command[Literal["my_other_node"]]. This is necessary for the graph rendering and tells LangGraph that my_node can navigate to my_other_node.</p>
<h2 id="when-should-i-use-command-instead-of-conditional-edges">When should I use Command instead of conditional edges?<a class="headerlink" href="#when-should-i-use-command-instead-of-conditional-edges" title="Permanent link">#</a></h2>
<p>Use Command when you need to both update the graph state and route to a different node. For example, when implementing multi-agent handoffs where it's important to route to a different agent and pass some information to that agent.</p>
<p>Use conditional edges to route between nodes conditionally without updating the state.</p>
<h2 id="navigating-to-a-node-in-a-parent-graph">Navigating to a node in a parent graph<a class="headerlink" href="#navigating-to-a-node-in-a-parent-graph" title="Permanent link">#</a></h2>
<p>If you are using subgraphs, you might want to navigate from a node within a subgraph to a different subgraph (i.e. a different node in the parent graph). To do so, you can specify graph=Command.PARENT in Command:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>def my_node(state: State) -&gt; Command[Literal[&quot;other_subgraph&quot;]]:
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>    return Command(
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a>        update={&quot;foo&quot;: &quot;bar&quot;},
</span><span id="__span-33-4"><a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a>        goto=&quot;other_subgraph&quot;,  # where `other_subgraph` is a node in the parent graph
</span><span id="__span-33-5"><a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a>        graph=Command.PARENT
</span><span id="__span-33-6"><a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a>    )
</span></code></pre></div>
<p><strong>Note:</strong> Setting graph to Command.PARENT will navigate to the closest parent graph.</p>
<p><strong>State updates with Command.PARENT</strong>
When you send updates from a subgraph node to a parent graph node for a key that's shared by both parent and subgraph state schemas, you must define a reducer for the key you're updating in the parent graph state. See this example.</p>
<h2 id="using-inside-tools">Using inside tools<a class="headerlink" href="#using-inside-tools" title="Permanent link">#</a></h2>
<p>A common use case is updating graph state from inside a tool. For example, in a customer support application you might want to look up customer information based on their account number or ID in the beginning of the conversation. To update the graph state from the tool, you can return Command(update={"my_custom_key": "foo", "messages": [...]}) from the tool:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>@tool
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a>def lookup_user_info(tool_call_id: Annotated[str, InjectedToolCallId], config: RunnableConfig):
</span><span id="__span-34-3"><a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a>    &quot;&quot;&quot;Use this to look up user information to better assist them with their questions.&quot;&quot;&quot;
</span><span id="__span-34-4"><a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a>    user_info = get_user_info(config.get(&quot;configurable&quot;, {}).get(&quot;user_id&quot;))
</span><span id="__span-34-5"><a id="__codelineno-34-5" name="__codelineno-34-5" href="#__codelineno-34-5"></a>    return Command(
</span><span id="__span-34-6"><a id="__codelineno-34-6" name="__codelineno-34-6" href="#__codelineno-34-6"></a>        update={
</span><span id="__span-34-7"><a id="__codelineno-34-7" name="__codelineno-34-7" href="#__codelineno-34-7"></a>            # update the state keys
</span><span id="__span-34-8"><a id="__codelineno-34-8" name="__codelineno-34-8" href="#__codelineno-34-8"></a>            &quot;user_info&quot;: user_info,
</span><span id="__span-34-9"><a id="__codelineno-34-9" name="__codelineno-34-9" href="#__codelineno-34-9"></a>            # update the message history
</span><span id="__span-34-10"><a id="__codelineno-34-10" name="__codelineno-34-10" href="#__codelineno-34-10"></a>            &quot;messages&quot;: [ToolMessage(&quot;Successfully looked up user information&quot;, tool_call_id=tool_call_id)]
</span><span id="__span-34-11"><a id="__codelineno-34-11" name="__codelineno-34-11" href="#__codelineno-34-11"></a>        }
</span><span id="__span-34-12"><a id="__codelineno-34-12" name="__codelineno-34-12" href="#__codelineno-34-12"></a>    )
</span></code></pre></div>
<h2 id="human-in-the-loop">Human-in-the-loop<a class="headerlink" href="#human-in-the-loop" title="Permanent link">#</a></h2>
<p>Command is an important part of human-in-the-loop workflows: when using interrupt() to collect user input, Command is then used to supply the input and resume execution via Command(resume="User input"). Check out this conceptual guide for more information.</p>
<h2 id="persistence">Persistence<a class="headerlink" href="#persistence" title="Permanent link">#</a></h2>
<p>LangGraph provides built-in persistence for your agent's state using checkpointers. Checkpointers save snapshots of the graph state at every superstep, allowing resumption at any time. This enables features like human-in-the-loop interactions, memory management, and fault-tolerance. You can even directly manipulate a graph's state after its execution using the appropriate get and update methods. For more details, see the persistence conceptual guide.</p>
<h2 id="threads">Threads<a class="headerlink" href="#threads" title="Permanent link">#</a></h2>
<p>Threads in LangGraph represent individual sessions or conversations between your graph and a user. When using checkpointing, turns in a single conversation (and even steps within a single graph execution) are organized by a unique thread ID.</p>
<h2 id="storage">Storage<a class="headerlink" href="#storage" title="Permanent link">#</a></h2>
<p>LangGraph provides built-in document storage through the BaseStore interface. Unlike checkpointers, which save state by thread ID, stores use custom namespaces for organizing data. This enables cross-thread persistence, allowing agents to maintain long-term memories, learn from past interactions, and accumulate knowledge over time. Common use cases include storing user profiles, building knowledge bases, and managing global preferences across all threads.</p>
<h2 id="graph-migrations">Graph Migrations<a class="headerlink" href="#graph-migrations" title="Permanent link">#</a></h2>
<p>LangGraph can easily handle migrations of graph definitions (nodes, edges, and state) even when using a checkpointer to track state.</p>
<ul>
<li>For threads at the end of the graph (i.e. not interrupted) you can change the entire topology of the graph (i.e. all nodes and edges, remove, add, rename, etc)</li>
<li>For threads currently interrupted, we support all topology changes other than renaming / removing nodes (as that thread could now be about to enter a node that no longer exists) -- if this is a blocker please reach out and we can prioritize a solution.</li>
<li>For modifying state, we have full backwards and forwards compatibility for adding and removing keys</li>
<li>State keys that are renamed lose their saved state in existing threads</li>
<li>State keys whose types change in incompatible ways could currently cause issues in threads with state from before the change -- if this is a blocker please reach out and we can prioritize a solution.</li>
</ul>
<h2 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Permanent link">#</a></h2>
<p>When creating a graph, you can also mark that certain parts of the graph are configurable. This is commonly done to enable easily switching between models or system prompts. This allows you to create a single "cognitive architecture" (the graph) but have multiple different instance of it.</p>
<p>You can optionally specify a config_schema when creating a graph.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>class ConfigSchema(TypedDict):
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>    llm: str
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>graph = StateGraph(State, config_schema=ConfigSchema)
</span></code></pre></div>
<p>You can then pass this configuration into the graph using the configurable config field.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>config = {&quot;configurable&quot;: {&quot;llm&quot;: &quot;anthropic&quot;}}
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>graph.invoke(inputs, config=config)
</span></code></pre></div>
<p>You can then access and use this configuration inside a node:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a>def node_a(state, config):
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a>    llm_type = config.get(&quot;configurable&quot;, {}).get(&quot;llm&quot;, &quot;openai&quot;)
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a>    llm = get_llm(llm_type)
</span><span id="__span-37-4"><a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a>    ...
</span></code></pre></div>
<h2 id="recursion-limit">Recursion Limit<a class="headerlink" href="#recursion-limit" title="Permanent link">#</a></h2>
<p>The recursion limit sets the maximum number of super-steps the graph can execute during a single execution. Once the limit is reached, LangGraph will raise GraphRecursionError. By default this value is set to 25 steps. The recursion limit can be set on any graph at runtime, and is passed to .invoke/.stream via the config dictionary. Importantly, recursion_limit is a standalone config key and should not be passed inside the configurable key as all other user-defined configuration. See the example below:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>graph.invoke(inputs, config={&quot;recursion_limit&quot;: 5, &quot;configurable&quot;:{&quot;llm&quot;: &quot;anthropic&quot;}})
</span></code></pre></div>
<h2 id="interrupt">interrupt<a class="headerlink" href="#interrupt" title="Permanent link">#</a></h2>
<p>Use the interrupt function to pause the graph at specific points to collect user input. The interrupt function surfaces interrupt information to the client, allowing the developer to collect user input, validate the graph state, or make decisions before resuming execution.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a>from langgraph.types import interrupt
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>def human_approval_node(state: State):
</span><span id="__span-39-4"><a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a>    ...
</span><span id="__span-39-5"><a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a>    answer = interrupt(
</span><span id="__span-39-6"><a id="__codelineno-39-6" name="__codelineno-39-6" href="#__codelineno-39-6"></a>        # This value will be sent to the client.
</span><span id="__span-39-7"><a id="__codelineno-39-7" name="__codelineno-39-7" href="#__codelineno-39-7"></a>        # It can be any JSON serializable value.
</span><span id="__span-39-8"><a id="__codelineno-39-8" name="__codelineno-39-8" href="#__codelineno-39-8"></a>        {&quot;question&quot;: &quot;is it ok to continue?&quot;},
</span><span id="__span-39-9"><a id="__codelineno-39-9" name="__codelineno-39-9" href="#__codelineno-39-9"></a>    )
</span><span id="__span-39-10"><a id="__codelineno-39-10" name="__codelineno-39-10" href="#__codelineno-39-10"></a>    ...
</span></code></pre></div>
<p>Resuming the graph is done by passing a Command object to the graph with the resume key set to the value returned by the interrupt function.</p>
<h2 id="breakpoints">Breakpoints<a class="headerlink" href="#breakpoints" title="Permanent link">#</a></h2>
<p>Breakpoints pause graph execution at specific points and enable stepping through execution step by step. Breakpoints are powered by LangGraph's persistence layer, which saves the state after each graph step. Breakpoints can also be used to enable human-in-the-loop workflows, though we recommend using the interrupt function for this purpose.</p>
<p>Read more about breakpoints in the Breakpoints conceptual guide.</p>
<h2 id="subgraphs">Subgraphs<a class="headerlink" href="#subgraphs" title="Permanent link">#</a></h2>
<p>A subgraph is a graph that is used as a node in another graph. This is nothing more than the age-old concept of encapsulation, applied to LangGraph. Some reasons for using subgraphs are:</p>
<ul>
<li>building multi-agent systems</li>
<li>when you want to reuse a set of nodes in multiple graphs, which maybe share some state, you can define them once in a subgraph and then use them in multiple parent graphs</li>
<li>when you want different teams to work on different parts of the graph independently, you can define each part as a subgraph, and as long as the subgraph interface (the input and output schemas) is respected, the parent graph can be built without knowing any details of the subgraph</li>
</ul>
<p>There are two ways to add subgraphs to a parent graph:</p>
<ul>
<li>add a node with the compiled subgraph: this is useful when the parent graph and the subgraph share state keys and you don't need to transform state on the way in or out</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>builder.add_node(&quot;subgraph&quot;, subgraph_builder.compile())
</span></code></pre></div>
<ul>
<li>add a node with a function that invokes the subgraph: this is useful when the parent graph and the subgraph have different state schemas and you need to transform state before or after calling the subgraph</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a>subgraph = subgraph_builder.compile()
</span><span id="__span-41-2"><a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a>
</span><span id="__span-41-3"><a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a>def call_subgraph(state: State):
</span><span id="__span-41-4"><a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a>    return subgraph.invoke({&quot;subgraph_key&quot;: state[&quot;parent_key&quot;]})
</span><span id="__span-41-5"><a id="__codelineno-41-5" name="__codelineno-41-5" href="#__codelineno-41-5"></a>
</span><span id="__span-41-6"><a id="__codelineno-41-6" name="__codelineno-41-6" href="#__codelineno-41-6"></a>builder.add_node(&quot;subgraph&quot;, call_subgraph)
</span></code></pre></div>
<h2 id="as-a-compiled-graph">As a compiled graph<a class="headerlink" href="#as-a-compiled-graph" title="Permanent link">#</a></h2>
<p>The simplest way to create subgraph nodes is by using a compiled subgraph directly. When doing so, it is important that the parent graph and the subgraph state schemas share at least one key which they can use to communicate. If your graph and subgraph do not share any keys, you should write a function invoking the subgraph instead.</p>
<p><strong>Note:</strong> If you pass extra keys to the subgraph node (i.e., in addition to the shared keys), they will be ignored by the subgraph node. Similarly, if you return extra keys from the subgraph, they will be ignored by the parent graph.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a>from langgraph.graph import StateGraph
</span><span id="__span-42-2"><a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a>from typing import TypedDict
</span><span id="__span-42-3"><a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a>
</span><span id="__span-42-4"><a id="__codelineno-42-4" name="__codelineno-42-4" href="#__codelineno-42-4"></a>class State(TypedDict):
</span><span id="__span-42-5"><a id="__codelineno-42-5" name="__codelineno-42-5" href="#__codelineno-42-5"></a>    foo: str
</span><span id="__span-42-6"><a id="__codelineno-42-6" name="__codelineno-42-6" href="#__codelineno-42-6"></a>
</span><span id="__span-42-7"><a id="__codelineno-42-7" name="__codelineno-42-7" href="#__codelineno-42-7"></a>class SubgraphState(TypedDict):
</span><span id="__span-42-8"><a id="__codelineno-42-8" name="__codelineno-42-8" href="#__codelineno-42-8"></a>    foo: str  # note that this key is shared with the parent graph state
</span><span id="__span-42-9"><a id="__codelineno-42-9" name="__codelineno-42-9" href="#__codelineno-42-9"></a>    bar: str
</span><span id="__span-42-10"><a id="__codelineno-42-10" name="__codelineno-42-10" href="#__codelineno-42-10"></a>
</span><span id="__span-42-11"><a id="__codelineno-42-11" name="__codelineno-42-11" href="#__codelineno-42-11"></a># Define subgraph
</span><span id="__span-42-12"><a id="__codelineno-42-12" name="__codelineno-42-12" href="#__codelineno-42-12"></a>def subgraph_node(state: SubgraphState):
</span><span id="__span-42-13"><a id="__codelineno-42-13" name="__codelineno-42-13" href="#__codelineno-42-13"></a>    # note that this subgraph node can communicate with the parent graph via the shared &quot;foo&quot; key
</span><span id="__span-42-14"><a id="__codelineno-42-14" name="__codelineno-42-14" href="#__codelineno-42-14"></a>    return {&quot;foo&quot;: state[&quot;foo&quot;] + &quot;bar&quot;}
</span><span id="__span-42-15"><a id="__codelineno-42-15" name="__codelineno-42-15" href="#__codelineno-42-15"></a>
</span><span id="__span-42-16"><a id="__codelineno-42-16" name="__codelineno-42-16" href="#__codelineno-42-16"></a>subgraph_builder = StateGraph(SubgraphState)
</span><span id="__span-42-17"><a id="__codelineno-42-17" name="__codelineno-42-17" href="#__codelineno-42-17"></a>subgraph_builder.add_node(subgraph_node)
</span><span id="__span-42-18"><a id="__codelineno-42-18" name="__codelineno-42-18" href="#__codelineno-42-18"></a>...
</span><span id="__span-42-19"><a id="__codelineno-42-19" name="__codelineno-42-19" href="#__codelineno-42-19"></a>subgraph = subgraph_builder.compile()
</span><span id="__span-42-20"><a id="__codelineno-42-20" name="__codelineno-42-20" href="#__codelineno-42-20"></a>
</span><span id="__span-42-21"><a id="__codelineno-42-21" name="__codelineno-42-21" href="#__codelineno-42-21"></a># Define parent graph
</span><span id="__span-42-22"><a id="__codelineno-42-22" name="__codelineno-42-22" href="#__codelineno-42-22"></a>builder = StateGraph(State)
</span><span id="__span-42-23"><a id="__codelineno-42-23" name="__codelineno-42-23" href="#__codelineno-42-23"></a>builder.add_node(&quot;subgraph&quot;, subgraph)
</span><span id="__span-42-24"><a id="__codelineno-42-24" name="__codelineno-42-24" href="#__codelineno-42-24"></a>...
</span><span id="__span-42-25"><a id="__codelineno-42-25" name="__codelineno-42-25" href="#__codelineno-42-25"></a>graph = builder.compile()
</span></code></pre></div>
<h2 id="as-a-function">As a function<a class="headerlink" href="#as-a-function" title="Permanent link">#</a></h2>
<p>You might want to define a subgraph with a completely different schema. In this case, you can create a node function that invokes the subgraph. This function will need to transform the input (parent) state to the subgraph state before invoking the subgraph, and transform the results back to the parent state before returning the state update from the node.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a>class State(TypedDict):
</span><span id="__span-43-2"><a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a>    foo: str
</span><span id="__span-43-3"><a id="__codelineno-43-3" name="__codelineno-43-3" href="#__codelineno-43-3"></a>
</span><span id="__span-43-4"><a id="__codelineno-43-4" name="__codelineno-43-4" href="#__codelineno-43-4"></a>class SubgraphState(TypedDict):
</span><span id="__span-43-5"><a id="__codelineno-43-5" name="__codelineno-43-5" href="#__codelineno-43-5"></a>    # note that none of these keys are shared with the parent graph state
</span><span id="__span-43-6"><a id="__codelineno-43-6" name="__codelineno-43-6" href="#__codelineno-43-6"></a>    bar: str
</span><span id="__span-43-7"><a id="__codelineno-43-7" name="__codelineno-43-7" href="#__codelineno-43-7"></a>    baz: str
</span><span id="__span-43-8"><a id="__codelineno-43-8" name="__codelineno-43-8" href="#__codelineno-43-8"></a>
</span><span id="__span-43-9"><a id="__codelineno-43-9" name="__codelineno-43-9" href="#__codelineno-43-9"></a># Define subgraph
</span><span id="__span-43-10"><a id="__codelineno-43-10" name="__codelineno-43-10" href="#__codelineno-43-10"></a>def subgraph_node(state: SubgraphState):
</span><span id="__span-43-11"><a id="__codelineno-43-11" name="__codelineno-43-11" href="#__codelineno-43-11"></a>    return {&quot;bar&quot;: state[&quot;bar&quot;] + &quot;baz&quot;}
</span><span id="__span-43-12"><a id="__codelineno-43-12" name="__codelineno-43-12" href="#__codelineno-43-12"></a>
</span><span id="__span-43-13"><a id="__codelineno-43-13" name="__codelineno-43-13" href="#__codelineno-43-13"></a>subgraph_builder = StateGraph(SubgraphState)
</span><span id="__span-43-14"><a id="__codelineno-43-14" name="__codelineno-43-14" href="#__codelineno-43-14"></a>subgraph_builder.add_node(subgraph_node)
</span><span id="__span-43-15"><a id="__codelineno-43-15" name="__codelineno-43-15" href="#__codelineno-43-15"></a>...
</span><span id="__span-43-16"><a id="__codelineno-43-16" name="__codelineno-43-16" href="#__codelineno-43-16"></a>subgraph = subgraph_builder.compile()
</span><span id="__span-43-17"><a id="__codelineno-43-17" name="__codelineno-43-17" href="#__codelineno-43-17"></a>
</span><span id="__span-43-18"><a id="__codelineno-43-18" name="__codelineno-43-18" href="#__codelineno-43-18"></a># Define parent graph
</span><span id="__span-43-19"><a id="__codelineno-43-19" name="__codelineno-43-19" href="#__codelineno-43-19"></a>def node(state: State):
</span><span id="__span-43-20"><a id="__codelineno-43-20" name="__codelineno-43-20" href="#__codelineno-43-20"></a>    # transform the state to the subgraph state
</span><span id="__span-43-21"><a id="__codelineno-43-21" name="__codelineno-43-21" href="#__codelineno-43-21"></a>    response = subgraph.invoke({&quot;bar&quot;: state[&quot;foo&quot;]})
</span><span id="__span-43-22"><a id="__codelineno-43-22" name="__codelineno-43-22" href="#__codelineno-43-22"></a>    # transform response back to the parent state
</span><span id="__span-43-23"><a id="__codelineno-43-23" name="__codelineno-43-23" href="#__codelineno-43-23"></a>    return {&quot;foo&quot;: response[&quot;bar&quot;]}
</span><span id="__span-43-24"><a id="__codelineno-43-24" name="__codelineno-43-24" href="#__codelineno-43-24"></a>
</span><span id="__span-43-25"><a id="__codelineno-43-25" name="__codelineno-43-25" href="#__codelineno-43-25"></a>builder = StateGraph(State)
</span><span id="__span-43-26"><a id="__codelineno-43-26" name="__codelineno-43-26" href="#__codelineno-43-26"></a># note that we are using `node` function instead of a compiled subgraph
</span><span id="__span-43-27"><a id="__codelineno-43-27" name="__codelineno-43-27" href="#__codelineno-43-27"></a>builder.add_node(node)
</span><span id="__span-43-28"><a id="__codelineno-43-28" name="__codelineno-43-28" href="#__codelineno-43-28"></a>...
</span><span id="__span-43-29"><a id="__codelineno-43-29" name="__codelineno-43-29" href="#__codelineno-43-29"></a>graph = builder.compile()
</span></code></pre></div>
<h2 id="visualization">Visualization<a class="headerlink" href="#visualization" title="Permanent link">#</a></h2>
<p>It's often nice to be able to visualize graphs, especially as they get more complex. LangGraph comes with several built-in ways to visualize graphs.
<a href="https://langchain-ai.github.io/langgraph/how-tos/visualization/">visualize</a></p>
<h2 id="streaming">Streaming<a class="headerlink" href="#streaming" title="Permanent link">#</a></h2>
<p>LangGraph is built with first class support for streaming, including streaming updates from graph nodes during the execution, streaming tokens from LLM calls and more. See this conceptual guide for more information.
<a href="https://langchain-ai.github.io/langgraph/concepts/streaming/">streaming</a></p>
<h2 id="how-to-create-branches-for-parallel-node-execution">How to create branches for parallel node execution¶<a class="headerlink" href="#how-to-create-branches-for-parallel-node-execution" title="Permanent link">#</a></h2>
<p>Parallel execution of nodes is essential to speed up overall graph operation. LangGraph offers native support for parallel execution of nodes, which can significantly enhance the performance of graph-based workflows. This parallelization is achieved through fan-out and fan-in mechanisms, utilizing both standard edges and conditional_edges. Below are some examples showing how to add create branching dataflows that work for you.</p>
<h2 id="how-to-run-graph-nodes-in-parallel">How to run graph nodes in parallel<a class="headerlink" href="#how-to-run-graph-nodes-in-parallel" title="Permanent link">#</a></h2>
<p>In this example, we fan out from Node A to B and C and then fan in to D. With our state, we specify the reducer add operation. This will combine or accumulate values for the specific key in the State, rather than simply overwriting the existing value. For lists, this means concatenating the new list with the existing list. See this guide for more detail on updating state with reducers.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a>import operator
</span><span id="__span-44-2"><a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a>from typing import Annotated, Any
</span><span id="__span-44-3"><a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a>
</span><span id="__span-44-4"><a id="__codelineno-44-4" name="__codelineno-44-4" href="#__codelineno-44-4"></a>from typing_extensions import TypedDict
</span><span id="__span-44-5"><a id="__codelineno-44-5" name="__codelineno-44-5" href="#__codelineno-44-5"></a>
</span><span id="__span-44-6"><a id="__codelineno-44-6" name="__codelineno-44-6" href="#__codelineno-44-6"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-44-7"><a id="__codelineno-44-7" name="__codelineno-44-7" href="#__codelineno-44-7"></a>
</span><span id="__span-44-8"><a id="__codelineno-44-8" name="__codelineno-44-8" href="#__codelineno-44-8"></a>
</span><span id="__span-44-9"><a id="__codelineno-44-9" name="__codelineno-44-9" href="#__codelineno-44-9"></a>class State(TypedDict):
</span><span id="__span-44-10"><a id="__codelineno-44-10" name="__codelineno-44-10" href="#__codelineno-44-10"></a>    # The operator.add reducer fn makes this append-only
</span><span id="__span-44-11"><a id="__codelineno-44-11" name="__codelineno-44-11" href="#__codelineno-44-11"></a>    aggregate: Annotated[list, operator.add]
</span><span id="__span-44-12"><a id="__codelineno-44-12" name="__codelineno-44-12" href="#__codelineno-44-12"></a>
</span><span id="__span-44-13"><a id="__codelineno-44-13" name="__codelineno-44-13" href="#__codelineno-44-13"></a>
</span><span id="__span-44-14"><a id="__codelineno-44-14" name="__codelineno-44-14" href="#__codelineno-44-14"></a>def a(state: State):
</span><span id="__span-44-15"><a id="__codelineno-44-15" name="__codelineno-44-15" href="#__codelineno-44-15"></a>    print(f&#39;Adding &quot;A&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-44-16"><a id="__codelineno-44-16" name="__codelineno-44-16" href="#__codelineno-44-16"></a>    return {&quot;aggregate&quot;: [&quot;A&quot;]}
</span><span id="__span-44-17"><a id="__codelineno-44-17" name="__codelineno-44-17" href="#__codelineno-44-17"></a>
</span><span id="__span-44-18"><a id="__codelineno-44-18" name="__codelineno-44-18" href="#__codelineno-44-18"></a>
</span><span id="__span-44-19"><a id="__codelineno-44-19" name="__codelineno-44-19" href="#__codelineno-44-19"></a>def b(state: State):
</span><span id="__span-44-20"><a id="__codelineno-44-20" name="__codelineno-44-20" href="#__codelineno-44-20"></a>    print(f&#39;Adding &quot;B&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-44-21"><a id="__codelineno-44-21" name="__codelineno-44-21" href="#__codelineno-44-21"></a>    return {&quot;aggregate&quot;: [&quot;B&quot;]}
</span><span id="__span-44-22"><a id="__codelineno-44-22" name="__codelineno-44-22" href="#__codelineno-44-22"></a>
</span><span id="__span-44-23"><a id="__codelineno-44-23" name="__codelineno-44-23" href="#__codelineno-44-23"></a>
</span><span id="__span-44-24"><a id="__codelineno-44-24" name="__codelineno-44-24" href="#__codelineno-44-24"></a>def c(state: State):
</span><span id="__span-44-25"><a id="__codelineno-44-25" name="__codelineno-44-25" href="#__codelineno-44-25"></a>    print(f&#39;Adding &quot;C&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-44-26"><a id="__codelineno-44-26" name="__codelineno-44-26" href="#__codelineno-44-26"></a>    return {&quot;aggregate&quot;: [&quot;C&quot;]}
</span><span id="__span-44-27"><a id="__codelineno-44-27" name="__codelineno-44-27" href="#__codelineno-44-27"></a>
</span><span id="__span-44-28"><a id="__codelineno-44-28" name="__codelineno-44-28" href="#__codelineno-44-28"></a>
</span><span id="__span-44-29"><a id="__codelineno-44-29" name="__codelineno-44-29" href="#__codelineno-44-29"></a>def d(state: State):
</span><span id="__span-44-30"><a id="__codelineno-44-30" name="__codelineno-44-30" href="#__codelineno-44-30"></a>    print(f&#39;Adding &quot;D&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-44-31"><a id="__codelineno-44-31" name="__codelineno-44-31" href="#__codelineno-44-31"></a>    return {&quot;aggregate&quot;: [&quot;D&quot;]}
</span><span id="__span-44-32"><a id="__codelineno-44-32" name="__codelineno-44-32" href="#__codelineno-44-32"></a>
</span><span id="__span-44-33"><a id="__codelineno-44-33" name="__codelineno-44-33" href="#__codelineno-44-33"></a>
</span><span id="__span-44-34"><a id="__codelineno-44-34" name="__codelineno-44-34" href="#__codelineno-44-34"></a>builder = StateGraph(State)
</span><span id="__span-44-35"><a id="__codelineno-44-35" name="__codelineno-44-35" href="#__codelineno-44-35"></a>builder.add_node(a)
</span><span id="__span-44-36"><a id="__codelineno-44-36" name="__codelineno-44-36" href="#__codelineno-44-36"></a>builder.add_node(b)
</span><span id="__span-44-37"><a id="__codelineno-44-37" name="__codelineno-44-37" href="#__codelineno-44-37"></a>builder.add_node(c)
</span><span id="__span-44-38"><a id="__codelineno-44-38" name="__codelineno-44-38" href="#__codelineno-44-38"></a>builder.add_node(d)
</span><span id="__span-44-39"><a id="__codelineno-44-39" name="__codelineno-44-39" href="#__codelineno-44-39"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-44-40"><a id="__codelineno-44-40" name="__codelineno-44-40" href="#__codelineno-44-40"></a>builder.add_edge(&quot;a&quot;, &quot;b&quot;)
</span><span id="__span-44-41"><a id="__codelineno-44-41" name="__codelineno-44-41" href="#__codelineno-44-41"></a>builder.add_edge(&quot;a&quot;, &quot;c&quot;)
</span><span id="__span-44-42"><a id="__codelineno-44-42" name="__codelineno-44-42" href="#__codelineno-44-42"></a>builder.add_edge(&quot;b&quot;, &quot;d&quot;)
</span><span id="__span-44-43"><a id="__codelineno-44-43" name="__codelineno-44-43" href="#__codelineno-44-43"></a>builder.add_edge(&quot;c&quot;, &quot;d&quot;)
</span><span id="__span-44-44"><a id="__codelineno-44-44" name="__codelineno-44-44" href="#__codelineno-44-44"></a>builder.add_edge(&quot;d&quot;, END)
</span><span id="__span-44-45"><a id="__codelineno-44-45" name="__codelineno-44-45" href="#__codelineno-44-45"></a>graph = builder.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a>from IPython.display import Image, display
</span><span id="__span-45-2"><a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a>
</span><span id="__span-45-3"><a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a>display(Image(graph.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<p>With the reducer, you can see that the values added in each node are accumulated.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a>graph.invoke({&quot;aggregate&quot;: []}, {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;foo&quot;}})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a>Adding &quot;A&quot; to []
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2" href="#__codelineno-47-2"></a>Adding &quot;B&quot; to [&#39;A&#39;]
</span><span id="__span-47-3"><a id="__codelineno-47-3" name="__codelineno-47-3" href="#__codelineno-47-3"></a>Adding &quot;C&quot; to [&#39;A&#39;]
</span><span id="__span-47-4"><a id="__codelineno-47-4" name="__codelineno-47-4" href="#__codelineno-47-4"></a>Adding &quot;D&quot; to [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]
</span></code></pre></div>
<p><strong>Note:</strong> In the above example, nodes "b" and "c" are executed concurrently in the same superstep. Because they are in the same step, node "d" executes after both "b" and "c" are finished.</p>
<p>Importantly, updates from a parallel superstep may not be ordered consistently. If you need a consistent, predetermined ordering of updates from a parallel superstep, you should write the outputs to a separate field in the state together with a value with which to order them.</p>
<h2 id="parallel-node-fan-out-and-fan-in-with-extra-steps">Parallel node fan-out and fan-in with extra steps<a class="headerlink" href="#parallel-node-fan-out-and-fan-in-with-extra-steps" title="Permanent link">#</a></h2>
<p>The above example showed how to fan-out and fan-in when each path was only one step. But what if one path had more than one step? Let's add a node b_2 in the "b" branch:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-48-1"><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a>def b_2(state: State):
</span><span id="__span-48-2"><a id="__codelineno-48-2" name="__codelineno-48-2" href="#__codelineno-48-2"></a>    print(f&#39;Adding &quot;B_2&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-48-3"><a id="__codelineno-48-3" name="__codelineno-48-3" href="#__codelineno-48-3"></a>    return {&quot;aggregate&quot;: [&quot;B_2&quot;]}
</span><span id="__span-48-4"><a id="__codelineno-48-4" name="__codelineno-48-4" href="#__codelineno-48-4"></a>
</span><span id="__span-48-5"><a id="__codelineno-48-5" name="__codelineno-48-5" href="#__codelineno-48-5"></a>
</span><span id="__span-48-6"><a id="__codelineno-48-6" name="__codelineno-48-6" href="#__codelineno-48-6"></a>builder = StateGraph(State)
</span><span id="__span-48-7"><a id="__codelineno-48-7" name="__codelineno-48-7" href="#__codelineno-48-7"></a>builder.add_node(a)
</span><span id="__span-48-8"><a id="__codelineno-48-8" name="__codelineno-48-8" href="#__codelineno-48-8"></a>builder.add_node(b)
</span><span id="__span-48-9"><a id="__codelineno-48-9" name="__codelineno-48-9" href="#__codelineno-48-9"></a>builder.add_node(b_2)
</span><span id="__span-48-10"><a id="__codelineno-48-10" name="__codelineno-48-10" href="#__codelineno-48-10"></a>builder.add_node(c)
</span><span id="__span-48-11"><a id="__codelineno-48-11" name="__codelineno-48-11" href="#__codelineno-48-11"></a>builder.add_node(d)
</span><span id="__span-48-12"><a id="__codelineno-48-12" name="__codelineno-48-12" href="#__codelineno-48-12"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-48-13"><a id="__codelineno-48-13" name="__codelineno-48-13" href="#__codelineno-48-13"></a>builder.add_edge(&quot;a&quot;, &quot;b&quot;)
</span><span id="__span-48-14"><a id="__codelineno-48-14" name="__codelineno-48-14" href="#__codelineno-48-14"></a>builder.add_edge(&quot;a&quot;, &quot;c&quot;)
</span><span id="__span-48-15"><a id="__codelineno-48-15" name="__codelineno-48-15" href="#__codelineno-48-15"></a>builder.add_edge(&quot;b&quot;, &quot;b_2&quot;)
</span><span id="__span-48-16"><a id="__codelineno-48-16" name="__codelineno-48-16" href="#__codelineno-48-16"></a>builder.add_edge([&quot;b_2&quot;, &quot;c&quot;], &quot;d&quot;)
</span><span id="__span-48-17"><a id="__codelineno-48-17" name="__codelineno-48-17" href="#__codelineno-48-17"></a>builder.add_edge(&quot;d&quot;, END)
</span><span id="__span-48-18"><a id="__codelineno-48-18" name="__codelineno-48-18" href="#__codelineno-48-18"></a>graph = builder.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-49-1"><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a>from IPython.display import Image, display
</span><span id="__span-49-2"><a id="__codelineno-49-2" name="__codelineno-49-2" href="#__codelineno-49-2"></a>
</span><span id="__span-49-3"><a id="__codelineno-49-3" name="__codelineno-49-3" href="#__codelineno-49-3"></a>display(Image(graph.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-50-1"><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a>graph.invoke({&quot;aggregate&quot;: []})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-51-1"><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a>Adding &quot;A&quot; to []
</span><span id="__span-51-2"><a id="__codelineno-51-2" name="__codelineno-51-2" href="#__codelineno-51-2"></a>Adding &quot;B&quot; to [&#39;A&#39;]
</span><span id="__span-51-3"><a id="__codelineno-51-3" name="__codelineno-51-3" href="#__codelineno-51-3"></a>Adding &quot;C&quot; to [&#39;A&#39;]
</span><span id="__span-51-4"><a id="__codelineno-51-4" name="__codelineno-51-4" href="#__codelineno-51-4"></a>Adding &quot;B_2&quot; to [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]
</span><span id="__span-51-5"><a id="__codelineno-51-5" name="__codelineno-51-5" href="#__codelineno-51-5"></a>Adding &quot;D&quot; to [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;B_2&#39;]
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-52-1"><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a>{&#39;aggregate&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;B_2&#39;, &#39;D&#39;]}
</span></code></pre></div>
<p><strong>Note:</strong> In the above example, nodes "b" and "c" are executed concurrently in the same superstep. What happens in the next step?</p>
<p>We use add_edge(["b_2", "c"], "d") here to force node "d" to only run when both nodes "b_2" and "c" have finished execution. If we added two separate edges, node "d" would run twice: after node b2 finishes and once again after node c (in whichever order those nodes finish).</p>
<h2 id="conditional-branching">Conditional Branching<a class="headerlink" href="#conditional-branching" title="Permanent link">#</a></h2>
<p>If your fan-out is not deterministic, you can use add_conditional_edges directly.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-53-1"><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a>import operator
</span><span id="__span-53-2"><a id="__codelineno-53-2" name="__codelineno-53-2" href="#__codelineno-53-2"></a>from typing import Annotated, Sequence
</span><span id="__span-53-3"><a id="__codelineno-53-3" name="__codelineno-53-3" href="#__codelineno-53-3"></a>
</span><span id="__span-53-4"><a id="__codelineno-53-4" name="__codelineno-53-4" href="#__codelineno-53-4"></a>from typing_extensions import TypedDict
</span><span id="__span-53-5"><a id="__codelineno-53-5" name="__codelineno-53-5" href="#__codelineno-53-5"></a>
</span><span id="__span-53-6"><a id="__codelineno-53-6" name="__codelineno-53-6" href="#__codelineno-53-6"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-53-7"><a id="__codelineno-53-7" name="__codelineno-53-7" href="#__codelineno-53-7"></a>
</span><span id="__span-53-8"><a id="__codelineno-53-8" name="__codelineno-53-8" href="#__codelineno-53-8"></a>
</span><span id="__span-53-9"><a id="__codelineno-53-9" name="__codelineno-53-9" href="#__codelineno-53-9"></a>class State(TypedDict):
</span><span id="__span-53-10"><a id="__codelineno-53-10" name="__codelineno-53-10" href="#__codelineno-53-10"></a>    aggregate: Annotated[list, operator.add]
</span><span id="__span-53-11"><a id="__codelineno-53-11" name="__codelineno-53-11" href="#__codelineno-53-11"></a>    # Add a key to the state. We will set this key to determine
</span><span id="__span-53-12"><a id="__codelineno-53-12" name="__codelineno-53-12" href="#__codelineno-53-12"></a>    # how we branch.
</span><span id="__span-53-13"><a id="__codelineno-53-13" name="__codelineno-53-13" href="#__codelineno-53-13"></a>    which: str
</span><span id="__span-53-14"><a id="__codelineno-53-14" name="__codelineno-53-14" href="#__codelineno-53-14"></a>
</span><span id="__span-53-15"><a id="__codelineno-53-15" name="__codelineno-53-15" href="#__codelineno-53-15"></a>
</span><span id="__span-53-16"><a id="__codelineno-53-16" name="__codelineno-53-16" href="#__codelineno-53-16"></a>def a(state: State):
</span><span id="__span-53-17"><a id="__codelineno-53-17" name="__codelineno-53-17" href="#__codelineno-53-17"></a>    print(f&#39;Adding &quot;A&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-53-18"><a id="__codelineno-53-18" name="__codelineno-53-18" href="#__codelineno-53-18"></a>    return {&quot;aggregate&quot;: [&quot;A&quot;]}
</span><span id="__span-53-19"><a id="__codelineno-53-19" name="__codelineno-53-19" href="#__codelineno-53-19"></a>
</span><span id="__span-53-20"><a id="__codelineno-53-20" name="__codelineno-53-20" href="#__codelineno-53-20"></a>
</span><span id="__span-53-21"><a id="__codelineno-53-21" name="__codelineno-53-21" href="#__codelineno-53-21"></a>def b(state: State):
</span><span id="__span-53-22"><a id="__codelineno-53-22" name="__codelineno-53-22" href="#__codelineno-53-22"></a>    print(f&#39;Adding &quot;B&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-53-23"><a id="__codelineno-53-23" name="__codelineno-53-23" href="#__codelineno-53-23"></a>    return {&quot;aggregate&quot;: [&quot;B&quot;]}
</span><span id="__span-53-24"><a id="__codelineno-53-24" name="__codelineno-53-24" href="#__codelineno-53-24"></a>
</span><span id="__span-53-25"><a id="__codelineno-53-25" name="__codelineno-53-25" href="#__codelineno-53-25"></a>
</span><span id="__span-53-26"><a id="__codelineno-53-26" name="__codelineno-53-26" href="#__codelineno-53-26"></a>def c(state: State):
</span><span id="__span-53-27"><a id="__codelineno-53-27" name="__codelineno-53-27" href="#__codelineno-53-27"></a>    print(f&#39;Adding &quot;C&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-53-28"><a id="__codelineno-53-28" name="__codelineno-53-28" href="#__codelineno-53-28"></a>    return {&quot;aggregate&quot;: [&quot;C&quot;]}
</span><span id="__span-53-29"><a id="__codelineno-53-29" name="__codelineno-53-29" href="#__codelineno-53-29"></a>
</span><span id="__span-53-30"><a id="__codelineno-53-30" name="__codelineno-53-30" href="#__codelineno-53-30"></a>
</span><span id="__span-53-31"><a id="__codelineno-53-31" name="__codelineno-53-31" href="#__codelineno-53-31"></a>def d(state: State):
</span><span id="__span-53-32"><a id="__codelineno-53-32" name="__codelineno-53-32" href="#__codelineno-53-32"></a>    print(f&#39;Adding &quot;D&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-53-33"><a id="__codelineno-53-33" name="__codelineno-53-33" href="#__codelineno-53-33"></a>    return {&quot;aggregate&quot;: [&quot;D&quot;]}
</span><span id="__span-53-34"><a id="__codelineno-53-34" name="__codelineno-53-34" href="#__codelineno-53-34"></a>
</span><span id="__span-53-35"><a id="__codelineno-53-35" name="__codelineno-53-35" href="#__codelineno-53-35"></a>
</span><span id="__span-53-36"><a id="__codelineno-53-36" name="__codelineno-53-36" href="#__codelineno-53-36"></a>def e(state: State):
</span><span id="__span-53-37"><a id="__codelineno-53-37" name="__codelineno-53-37" href="#__codelineno-53-37"></a>    print(f&#39;Adding &quot;E&quot; to {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-53-38"><a id="__codelineno-53-38" name="__codelineno-53-38" href="#__codelineno-53-38"></a>    return {&quot;aggregate&quot;: [&quot;E&quot;]}
</span><span id="__span-53-39"><a id="__codelineno-53-39" name="__codelineno-53-39" href="#__codelineno-53-39"></a>
</span><span id="__span-53-40"><a id="__codelineno-53-40" name="__codelineno-53-40" href="#__codelineno-53-40"></a>
</span><span id="__span-53-41"><a id="__codelineno-53-41" name="__codelineno-53-41" href="#__codelineno-53-41"></a>builder = StateGraph(State)
</span><span id="__span-53-42"><a id="__codelineno-53-42" name="__codelineno-53-42" href="#__codelineno-53-42"></a>builder.add_node(a)
</span><span id="__span-53-43"><a id="__codelineno-53-43" name="__codelineno-53-43" href="#__codelineno-53-43"></a>builder.add_node(b)
</span><span id="__span-53-44"><a id="__codelineno-53-44" name="__codelineno-53-44" href="#__codelineno-53-44"></a>builder.add_node(c)
</span><span id="__span-53-45"><a id="__codelineno-53-45" name="__codelineno-53-45" href="#__codelineno-53-45"></a>builder.add_node(d)
</span><span id="__span-53-46"><a id="__codelineno-53-46" name="__codelineno-53-46" href="#__codelineno-53-46"></a>builder.add_node(e)
</span><span id="__span-53-47"><a id="__codelineno-53-47" name="__codelineno-53-47" href="#__codelineno-53-47"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-53-48"><a id="__codelineno-53-48" name="__codelineno-53-48" href="#__codelineno-53-48"></a>
</span><span id="__span-53-49"><a id="__codelineno-53-49" name="__codelineno-53-49" href="#__codelineno-53-49"></a>
</span><span id="__span-53-50"><a id="__codelineno-53-50" name="__codelineno-53-50" href="#__codelineno-53-50"></a>def route_bc_or_cd(state: State) -&gt; Sequence[str]:
</span><span id="__span-53-51"><a id="__codelineno-53-51" name="__codelineno-53-51" href="#__codelineno-53-51"></a>    if state[&quot;which&quot;] == &quot;cd&quot;:
</span><span id="__span-53-52"><a id="__codelineno-53-52" name="__codelineno-53-52" href="#__codelineno-53-52"></a>        return [&quot;c&quot;, &quot;d&quot;]
</span><span id="__span-53-53"><a id="__codelineno-53-53" name="__codelineno-53-53" href="#__codelineno-53-53"></a>    return [&quot;b&quot;, &quot;c&quot;]
</span><span id="__span-53-54"><a id="__codelineno-53-54" name="__codelineno-53-54" href="#__codelineno-53-54"></a>
</span><span id="__span-53-55"><a id="__codelineno-53-55" name="__codelineno-53-55" href="#__codelineno-53-55"></a>
</span><span id="__span-53-56"><a id="__codelineno-53-56" name="__codelineno-53-56" href="#__codelineno-53-56"></a>intermediates = [&quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
</span><span id="__span-53-57"><a id="__codelineno-53-57" name="__codelineno-53-57" href="#__codelineno-53-57"></a>builder.add_conditional_edges(
</span><span id="__span-53-58"><a id="__codelineno-53-58" name="__codelineno-53-58" href="#__codelineno-53-58"></a>    &quot;a&quot;,
</span><span id="__span-53-59"><a id="__codelineno-53-59" name="__codelineno-53-59" href="#__codelineno-53-59"></a>    route_bc_or_cd,
</span><span id="__span-53-60"><a id="__codelineno-53-60" name="__codelineno-53-60" href="#__codelineno-53-60"></a>    intermediates,
</span><span id="__span-53-61"><a id="__codelineno-53-61" name="__codelineno-53-61" href="#__codelineno-53-61"></a>)
</span><span id="__span-53-62"><a id="__codelineno-53-62" name="__codelineno-53-62" href="#__codelineno-53-62"></a>for node in intermediates:
</span><span id="__span-53-63"><a id="__codelineno-53-63" name="__codelineno-53-63" href="#__codelineno-53-63"></a>    builder.add_edge(node, &quot;e&quot;)
</span><span id="__span-53-64"><a id="__codelineno-53-64" name="__codelineno-53-64" href="#__codelineno-53-64"></a>
</span><span id="__span-53-65"><a id="__codelineno-53-65" name="__codelineno-53-65" href="#__codelineno-53-65"></a>builder.add_edge(&quot;e&quot;, END)
</span><span id="__span-53-66"><a id="__codelineno-53-66" name="__codelineno-53-66" href="#__codelineno-53-66"></a>graph = builder.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-54-1"><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a>from IPython.display import Image, display
</span><span id="__span-54-2"><a id="__codelineno-54-2" name="__codelineno-54-2" href="#__codelineno-54-2"></a>
</span><span id="__span-54-3"><a id="__codelineno-54-3" name="__codelineno-54-3" href="#__codelineno-54-3"></a>display(Image(graph.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-55-1"><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a>graph.invoke({&quot;aggregate&quot;: [], &quot;which&quot;: &quot;bc&quot;})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-56-1"><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a>graph.invoke({&quot;aggregate&quot;: [], &quot;which&quot;: &quot;cd&quot;})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-57-1"><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a>Adding &quot;A&quot; to []
</span><span id="__span-57-2"><a id="__codelineno-57-2" name="__codelineno-57-2" href="#__codelineno-57-2"></a>Adding &quot;C&quot; to [&#39;A&#39;]
</span><span id="__span-57-3"><a id="__codelineno-57-3" name="__codelineno-57-3" href="#__codelineno-57-3"></a>Adding &quot;D&quot; to [&#39;A&#39;]
</span><span id="__span-57-4"><a id="__codelineno-57-4" name="__codelineno-57-4" href="#__codelineno-57-4"></a>Adding &quot;E&quot; to [&#39;A&#39;, &#39;C&#39;, &#39;D&#39;]
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-58-1"><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a>{&#39;aggregate&#39;: [&#39;A&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;], &#39;which&#39;: &#39;cd&#39;}
</span></code></pre></div>
<h2 id="how-to-create-map-reduce-branches-for-parallel-execution">How to create map-reduce branches for parallel execution<a class="headerlink" href="#how-to-create-map-reduce-branches-for-parallel-execution" title="Permanent link">#</a></h2>
<p>Map-reduce operations are essential for efficient task decomposition and parallel processing. This approach involves breaking a task into smaller sub-tasks, processing each sub-task in parallel, and aggregating the results across all of the completed sub-tasks.</p>
<p>Consider this example: given a general topic from the user, generate a list of related subjects, generate a joke for each subject, and select the best joke from the resulting list. In this design pattern, a first node may generate a list of objects (e.g., related subjects) and we want to apply some other node (e.g., generate a joke) to all those objects (e.g., subjects). However, two main challenges arise.</p>
<p>(1) the number of objects (e.g., subjects) may be unknown ahead of time (meaning the number of edges may not be known) when we lay out the graph and (2) the input State to the downstream Node should be different (one for each generated object).</p>
<p>LangGraph addresses these challenges through its Send API. By utilizing conditional edges, Send can distribute different states (e.g., subjects) to multiple instances of a node (e.g., joke generation). Importantly, the sent state can differ from the core graph's state, allowing for flexible and dynamic workflow management.</p>
<p><img alt="map-reduce" src="../image/map-reduce.png" /></p>
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">#</a></h2>
<p>First, let's install the required packages and set our API keys</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-59-1"><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a>%%capture --no-stderr
</span><span id="__span-59-2"><a id="__codelineno-59-2" name="__codelineno-59-2" href="#__codelineno-59-2"></a>%pip install -U langchain-anthropic langgraph
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a>import os
</span><span id="__span-60-2"><a id="__codelineno-60-2" name="__codelineno-60-2" href="#__codelineno-60-2"></a>import getpass
</span><span id="__span-60-3"><a id="__codelineno-60-3" name="__codelineno-60-3" href="#__codelineno-60-3"></a>
</span><span id="__span-60-4"><a id="__codelineno-60-4" name="__codelineno-60-4" href="#__codelineno-60-4"></a>
</span><span id="__span-60-5"><a id="__codelineno-60-5" name="__codelineno-60-5" href="#__codelineno-60-5"></a>def _set_env(name: str):
</span><span id="__span-60-6"><a id="__codelineno-60-6" name="__codelineno-60-6" href="#__codelineno-60-6"></a>    if not os.getenv(name):
</span><span id="__span-60-7"><a id="__codelineno-60-7" name="__codelineno-60-7" href="#__codelineno-60-7"></a>        os.environ[name] = getpass.getpass(f&quot;{name}: &quot;)
</span><span id="__span-60-8"><a id="__codelineno-60-8" name="__codelineno-60-8" href="#__codelineno-60-8"></a>
</span><span id="__span-60-9"><a id="__codelineno-60-9" name="__codelineno-60-9" href="#__codelineno-60-9"></a>
</span><span id="__span-60-10"><a id="__codelineno-60-10" name="__codelineno-60-10" href="#__codelineno-60-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span></code></pre></div>
<h2 id="define-the-graph">Define the graph<a class="headerlink" href="#define-the-graph" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a>import operator
</span><span id="__span-61-2"><a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a>from typing import Annotated
</span><span id="__span-61-3"><a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>from typing_extensions import TypedDict
</span><span id="__span-61-4"><a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a>
</span><span id="__span-61-5"><a id="__codelineno-61-5" name="__codelineno-61-5" href="#__codelineno-61-5"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-61-6"><a id="__codelineno-61-6" name="__codelineno-61-6" href="#__codelineno-61-6"></a>
</span><span id="__span-61-7"><a id="__codelineno-61-7" name="__codelineno-61-7" href="#__codelineno-61-7"></a>from langgraph.types import Send
</span><span id="__span-61-8"><a id="__codelineno-61-8" name="__codelineno-61-8" href="#__codelineno-61-8"></a>from langgraph.graph import END, StateGraph, START
</span><span id="__span-61-9"><a id="__codelineno-61-9" name="__codelineno-61-9" href="#__codelineno-61-9"></a>
</span><span id="__span-61-10"><a id="__codelineno-61-10" name="__codelineno-61-10" href="#__codelineno-61-10"></a>from pydantic import BaseModel, Field
</span><span id="__span-61-11"><a id="__codelineno-61-11" name="__codelineno-61-11" href="#__codelineno-61-11"></a>
</span><span id="__span-61-12"><a id="__codelineno-61-12" name="__codelineno-61-12" href="#__codelineno-61-12"></a># Model and prompts
</span><span id="__span-61-13"><a id="__codelineno-61-13" name="__codelineno-61-13" href="#__codelineno-61-13"></a># Define model and prompts we will use
</span><span id="__span-61-14"><a id="__codelineno-61-14" name="__codelineno-61-14" href="#__codelineno-61-14"></a>subjects_prompt = &quot;&quot;&quot;Generate a comma separated list of between 2 and 5 examples related to: {topic}.&quot;&quot;&quot;
</span><span id="__span-61-15"><a id="__codelineno-61-15" name="__codelineno-61-15" href="#__codelineno-61-15"></a>joke_prompt = &quot;&quot;&quot;Generate a joke about {subject}&quot;&quot;&quot;
</span><span id="__span-61-16"><a id="__codelineno-61-16" name="__codelineno-61-16" href="#__codelineno-61-16"></a>best_joke_prompt = &quot;&quot;&quot;Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one.
</span><span id="__span-61-17"><a id="__codelineno-61-17" name="__codelineno-61-17" href="#__codelineno-61-17"></a>
</span><span id="__span-61-18"><a id="__codelineno-61-18" name="__codelineno-61-18" href="#__codelineno-61-18"></a>{jokes}&quot;&quot;&quot;
</span><span id="__span-61-19"><a id="__codelineno-61-19" name="__codelineno-61-19" href="#__codelineno-61-19"></a>
</span><span id="__span-61-20"><a id="__codelineno-61-20" name="__codelineno-61-20" href="#__codelineno-61-20"></a>
</span><span id="__span-61-21"><a id="__codelineno-61-21" name="__codelineno-61-21" href="#__codelineno-61-21"></a>class Subjects(BaseModel):
</span><span id="__span-61-22"><a id="__codelineno-61-22" name="__codelineno-61-22" href="#__codelineno-61-22"></a>    subjects: list[str]
</span><span id="__span-61-23"><a id="__codelineno-61-23" name="__codelineno-61-23" href="#__codelineno-61-23"></a>
</span><span id="__span-61-24"><a id="__codelineno-61-24" name="__codelineno-61-24" href="#__codelineno-61-24"></a>
</span><span id="__span-61-25"><a id="__codelineno-61-25" name="__codelineno-61-25" href="#__codelineno-61-25"></a>class Joke(BaseModel):
</span><span id="__span-61-26"><a id="__codelineno-61-26" name="__codelineno-61-26" href="#__codelineno-61-26"></a>    joke: str
</span><span id="__span-61-27"><a id="__codelineno-61-27" name="__codelineno-61-27" href="#__codelineno-61-27"></a>
</span><span id="__span-61-28"><a id="__codelineno-61-28" name="__codelineno-61-28" href="#__codelineno-61-28"></a>
</span><span id="__span-61-29"><a id="__codelineno-61-29" name="__codelineno-61-29" href="#__codelineno-61-29"></a>class BestJoke(BaseModel):
</span><span id="__span-61-30"><a id="__codelineno-61-30" name="__codelineno-61-30" href="#__codelineno-61-30"></a>    id: int = Field(description=&quot;Index of the best joke, starting with 0&quot;, ge=0)
</span><span id="__span-61-31"><a id="__codelineno-61-31" name="__codelineno-61-31" href="#__codelineno-61-31"></a>
</span><span id="__span-61-32"><a id="__codelineno-61-32" name="__codelineno-61-32" href="#__codelineno-61-32"></a>
</span><span id="__span-61-33"><a id="__codelineno-61-33" name="__codelineno-61-33" href="#__codelineno-61-33"></a>model = ChatAnthropic(model=&quot;claude-3-5-sonnet-20240620&quot;)
</span><span id="__span-61-34"><a id="__codelineno-61-34" name="__codelineno-61-34" href="#__codelineno-61-34"></a>
</span><span id="__span-61-35"><a id="__codelineno-61-35" name="__codelineno-61-35" href="#__codelineno-61-35"></a># Graph components: define the components that will make up the graph
</span><span id="__span-61-36"><a id="__codelineno-61-36" name="__codelineno-61-36" href="#__codelineno-61-36"></a>
</span><span id="__span-61-37"><a id="__codelineno-61-37" name="__codelineno-61-37" href="#__codelineno-61-37"></a>
</span><span id="__span-61-38"><a id="__codelineno-61-38" name="__codelineno-61-38" href="#__codelineno-61-38"></a># This will be the overall state of the main graph.
</span><span id="__span-61-39"><a id="__codelineno-61-39" name="__codelineno-61-39" href="#__codelineno-61-39"></a># It will contain a topic (which we expect the user to provide)
</span><span id="__span-61-40"><a id="__codelineno-61-40" name="__codelineno-61-40" href="#__codelineno-61-40"></a># and then will generate a list of subjects, and then a joke for
</span><span id="__span-61-41"><a id="__codelineno-61-41" name="__codelineno-61-41" href="#__codelineno-61-41"></a># each subject
</span><span id="__span-61-42"><a id="__codelineno-61-42" name="__codelineno-61-42" href="#__codelineno-61-42"></a>class OverallState(TypedDict):
</span><span id="__span-61-43"><a id="__codelineno-61-43" name="__codelineno-61-43" href="#__codelineno-61-43"></a>    topic: str
</span><span id="__span-61-44"><a id="__codelineno-61-44" name="__codelineno-61-44" href="#__codelineno-61-44"></a>    subjects: list
</span><span id="__span-61-45"><a id="__codelineno-61-45" name="__codelineno-61-45" href="#__codelineno-61-45"></a>    # Notice here we use the operator.add
</span><span id="__span-61-46"><a id="__codelineno-61-46" name="__codelineno-61-46" href="#__codelineno-61-46"></a>    # This is because we want combine all the jokes we generate
</span><span id="__span-61-47"><a id="__codelineno-61-47" name="__codelineno-61-47" href="#__codelineno-61-47"></a>    # from individual nodes back into one list - this is essentially
</span><span id="__span-61-48"><a id="__codelineno-61-48" name="__codelineno-61-48" href="#__codelineno-61-48"></a>    # the &quot;reduce&quot; part
</span><span id="__span-61-49"><a id="__codelineno-61-49" name="__codelineno-61-49" href="#__codelineno-61-49"></a>    jokes: Annotated[list, operator.add]
</span><span id="__span-61-50"><a id="__codelineno-61-50" name="__codelineno-61-50" href="#__codelineno-61-50"></a>    best_selected_joke: str
</span><span id="__span-61-51"><a id="__codelineno-61-51" name="__codelineno-61-51" href="#__codelineno-61-51"></a>
</span><span id="__span-61-52"><a id="__codelineno-61-52" name="__codelineno-61-52" href="#__codelineno-61-52"></a>
</span><span id="__span-61-53"><a id="__codelineno-61-53" name="__codelineno-61-53" href="#__codelineno-61-53"></a># This will be the state of the node that we will &quot;map&quot; all
</span><span id="__span-61-54"><a id="__codelineno-61-54" name="__codelineno-61-54" href="#__codelineno-61-54"></a># subjects to in order to generate a joke
</span><span id="__span-61-55"><a id="__codelineno-61-55" name="__codelineno-61-55" href="#__codelineno-61-55"></a>class JokeState(TypedDict):
</span><span id="__span-61-56"><a id="__codelineno-61-56" name="__codelineno-61-56" href="#__codelineno-61-56"></a>    subject: str
</span><span id="__span-61-57"><a id="__codelineno-61-57" name="__codelineno-61-57" href="#__codelineno-61-57"></a>
</span><span id="__span-61-58"><a id="__codelineno-61-58" name="__codelineno-61-58" href="#__codelineno-61-58"></a>
</span><span id="__span-61-59"><a id="__codelineno-61-59" name="__codelineno-61-59" href="#__codelineno-61-59"></a># This is the function we will use to generate the subjects of the jokes
</span><span id="__span-61-60"><a id="__codelineno-61-60" name="__codelineno-61-60" href="#__codelineno-61-60"></a>def generate_topics(state: OverallState):
</span><span id="__span-61-61"><a id="__codelineno-61-61" name="__codelineno-61-61" href="#__codelineno-61-61"></a>    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])
</span><span id="__span-61-62"><a id="__codelineno-61-62" name="__codelineno-61-62" href="#__codelineno-61-62"></a>    response = model.with_structured_output(Subjects).invoke(prompt)
</span><span id="__span-61-63"><a id="__codelineno-61-63" name="__codelineno-61-63" href="#__codelineno-61-63"></a>    return {&quot;subjects&quot;: response.subjects}
</span><span id="__span-61-64"><a id="__codelineno-61-64" name="__codelineno-61-64" href="#__codelineno-61-64"></a>
</span><span id="__span-61-65"><a id="__codelineno-61-65" name="__codelineno-61-65" href="#__codelineno-61-65"></a>
</span><span id="__span-61-66"><a id="__codelineno-61-66" name="__codelineno-61-66" href="#__codelineno-61-66"></a># Here we generate a joke, given a subject
</span><span id="__span-61-67"><a id="__codelineno-61-67" name="__codelineno-61-67" href="#__codelineno-61-67"></a>def generate_joke(state: JokeState):
</span><span id="__span-61-68"><a id="__codelineno-61-68" name="__codelineno-61-68" href="#__codelineno-61-68"></a>    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])
</span><span id="__span-61-69"><a id="__codelineno-61-69" name="__codelineno-61-69" href="#__codelineno-61-69"></a>    response = model.with_structured_output(Joke).invoke(prompt)
</span><span id="__span-61-70"><a id="__codelineno-61-70" name="__codelineno-61-70" href="#__codelineno-61-70"></a>    return {&quot;jokes&quot;: [response.joke]}
</span><span id="__span-61-71"><a id="__codelineno-61-71" name="__codelineno-61-71" href="#__codelineno-61-71"></a>
</span><span id="__span-61-72"><a id="__codelineno-61-72" name="__codelineno-61-72" href="#__codelineno-61-72"></a>
</span><span id="__span-61-73"><a id="__codelineno-61-73" name="__codelineno-61-73" href="#__codelineno-61-73"></a># Here we define the logic to map out over the generated subjects
</span><span id="__span-61-74"><a id="__codelineno-61-74" name="__codelineno-61-74" href="#__codelineno-61-74"></a># We will use this as an edge in the graph
</span><span id="__span-61-75"><a id="__codelineno-61-75" name="__codelineno-61-75" href="#__codelineno-61-75"></a>def continue_to_jokes(state: OverallState):
</span><span id="__span-61-76"><a id="__codelineno-61-76" name="__codelineno-61-76" href="#__codelineno-61-76"></a>    # We will return a list of `Send` objects
</span><span id="__span-61-77"><a id="__codelineno-61-77" name="__codelineno-61-77" href="#__codelineno-61-77"></a>    # Each `Send` object consists of the name of a node in the graph
</span><span id="__span-61-78"><a id="__codelineno-61-78" name="__codelineno-61-78" href="#__codelineno-61-78"></a>    # as well as the state to send to that node
</span><span id="__span-61-79"><a id="__codelineno-61-79" name="__codelineno-61-79" href="#__codelineno-61-79"></a>    return [Send(&quot;generate_joke&quot;, {&quot;subject&quot;: s}) for s in state[&quot;subjects&quot;]]
</span><span id="__span-61-80"><a id="__codelineno-61-80" name="__codelineno-61-80" href="#__codelineno-61-80"></a>
</span><span id="__span-61-81"><a id="__codelineno-61-81" name="__codelineno-61-81" href="#__codelineno-61-81"></a>
</span><span id="__span-61-82"><a id="__codelineno-61-82" name="__codelineno-61-82" href="#__codelineno-61-82"></a># Here we will judge the best joke
</span><span id="__span-61-83"><a id="__codelineno-61-83" name="__codelineno-61-83" href="#__codelineno-61-83"></a>def best_joke(state: OverallState):
</span><span id="__span-61-84"><a id="__codelineno-61-84" name="__codelineno-61-84" href="#__codelineno-61-84"></a>    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])
</span><span id="__span-61-85"><a id="__codelineno-61-85" name="__codelineno-61-85" href="#__codelineno-61-85"></a>    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)
</span><span id="__span-61-86"><a id="__codelineno-61-86" name="__codelineno-61-86" href="#__codelineno-61-86"></a>    response = model.with_structured_output(BestJoke).invoke(prompt)
</span><span id="__span-61-87"><a id="__codelineno-61-87" name="__codelineno-61-87" href="#__codelineno-61-87"></a>    return {&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]}
</span><span id="__span-61-88"><a id="__codelineno-61-88" name="__codelineno-61-88" href="#__codelineno-61-88"></a>
</span><span id="__span-61-89"><a id="__codelineno-61-89" name="__codelineno-61-89" href="#__codelineno-61-89"></a>
</span><span id="__span-61-90"><a id="__codelineno-61-90" name="__codelineno-61-90" href="#__codelineno-61-90"></a># Construct the graph: here we put everything together to construct our graph
</span><span id="__span-61-91"><a id="__codelineno-61-91" name="__codelineno-61-91" href="#__codelineno-61-91"></a>graph = StateGraph(OverallState)
</span><span id="__span-61-92"><a id="__codelineno-61-92" name="__codelineno-61-92" href="#__codelineno-61-92"></a>graph.add_node(&quot;generate_topics&quot;, generate_topics)
</span><span id="__span-61-93"><a id="__codelineno-61-93" name="__codelineno-61-93" href="#__codelineno-61-93"></a>graph.add_node(&quot;generate_joke&quot;, generate_joke)
</span><span id="__span-61-94"><a id="__codelineno-61-94" name="__codelineno-61-94" href="#__codelineno-61-94"></a>graph.add_node(&quot;best_joke&quot;, best_joke)
</span><span id="__span-61-95"><a id="__codelineno-61-95" name="__codelineno-61-95" href="#__codelineno-61-95"></a>graph.add_edge(START, &quot;generate_topics&quot;)
</span><span id="__span-61-96"><a id="__codelineno-61-96" name="__codelineno-61-96" href="#__codelineno-61-96"></a>graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])
</span><span id="__span-61-97"><a id="__codelineno-61-97" name="__codelineno-61-97" href="#__codelineno-61-97"></a>graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)
</span><span id="__span-61-98"><a id="__codelineno-61-98" name="__codelineno-61-98" href="#__codelineno-61-98"></a>graph.add_edge(&quot;best_joke&quot;, END)
</span><span id="__span-61-99"><a id="__codelineno-61-99" name="__codelineno-61-99" href="#__codelineno-61-99"></a>app = graph.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-62-1"><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a>from IPython.display import Image
</span><span id="__span-62-2"><a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a>
</span><span id="__span-62-3"><a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a>Image(app.get_graph().draw_mermaid_png())
</span></code></pre></div>
<h2 id="use-the-graph">Use the graph<a class="headerlink" href="#use-the-graph" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-63-1"><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a># Call the graph: here we call it to generate a list of jokes
</span><span id="__span-63-2"><a id="__codelineno-63-2" name="__codelineno-63-2" href="#__codelineno-63-2"></a>for s in app.stream({&quot;topic&quot;: &quot;animals&quot;}):
</span><span id="__span-63-3"><a id="__codelineno-63-3" name="__codelineno-63-3" href="#__codelineno-63-3"></a>    print(s)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-64-1"><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a>{&#39;generate_topics&#39;: {&#39;subjects&#39;: [&#39;Lions&#39;, &#39;Elephants&#39;, &#39;Penguins&#39;, &#39;Dolphins&#39;]}}
</span><span id="__span-64-2"><a id="__codelineno-64-2" name="__codelineno-64-2" href="#__codelineno-64-2"></a>{&#39;generate_joke&#39;: {&#39;jokes&#39;: [&quot;Why don&#39;t elephants use computers? They&#39;re afraid of the mouse!&quot;]}}
</span><span id="__span-64-3"><a id="__codelineno-64-3" name="__codelineno-64-3" href="#__codelineno-64-3"></a>{&#39;generate_joke&#39;: {&#39;jokes&#39;: [&quot;Why don&#39;t dolphins use smartphones? Because they&#39;re afraid of phishing!&quot;]}}
</span><span id="__span-64-4"><a id="__codelineno-64-4" name="__codelineno-64-4" href="#__codelineno-64-4"></a>{&#39;generate_joke&#39;: {&#39;jokes&#39;: [&quot;Why don&#39;t you see penguins in Britain? Because they&#39;re afraid of Wales!&quot;]}}
</span><span id="__span-64-5"><a id="__codelineno-64-5" name="__codelineno-64-5" href="#__codelineno-64-5"></a>{&#39;generate_joke&#39;: {&#39;jokes&#39;: [&quot;Why don&#39;t lions like fast food? Because they can&#39;t catch it!&quot;]}}
</span><span id="__span-64-6"><a id="__codelineno-64-6" name="__codelineno-64-6" href="#__codelineno-64-6"></a>{&#39;best_joke&#39;: {&#39;best_selected_joke&#39;: &quot;Why don&#39;t dolphins use smartphones? Because they&#39;re afraid of phishing!&quot;}}
</span></code></pre></div>
<h2 id="how-to-create-and-control-loops">How to create and control loops<a class="headerlink" href="#how-to-create-and-control-loops" title="Permanent link">#</a></h2>
<p>When creating a graph with a loop, we require a mechanism for terminating execution. This is most commonly done by adding a conditional edge that routes to the END node once we reach some termination condition.</p>
<p>You can also set the graph recursion limit when invoking or streaming the graph. The recursion limit sets the number of supersteps that the graph is allowed to execute before it raises an error. Read more about the concept of recursion limits here.</p>
<p>Let's consider a simple graph with a loop to better understand how these mechanisms work.</p>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">#</a></h2>
<p>When creating a loop, you can include a conditional edge that specifies a termination condition:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-65-1"><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a>builder = StateGraph(State)
</span><span id="__span-65-2"><a id="__codelineno-65-2" name="__codelineno-65-2" href="#__codelineno-65-2"></a>builder.add_node(a)
</span><span id="__span-65-3"><a id="__codelineno-65-3" name="__codelineno-65-3" href="#__codelineno-65-3"></a>builder.add_node(b)
</span><span id="__span-65-4"><a id="__codelineno-65-4" name="__codelineno-65-4" href="#__codelineno-65-4"></a>
</span><span id="__span-65-5"><a id="__codelineno-65-5" name="__codelineno-65-5" href="#__codelineno-65-5"></a>def route(state: State) -&gt; Literal[&quot;b&quot;, END]:
</span><span id="__span-65-6"><a id="__codelineno-65-6" name="__codelineno-65-6" href="#__codelineno-65-6"></a>    if termination_condition(state):
</span><span id="__span-65-7"><a id="__codelineno-65-7" name="__codelineno-65-7" href="#__codelineno-65-7"></a>        return END
</span><span id="__span-65-8"><a id="__codelineno-65-8" name="__codelineno-65-8" href="#__codelineno-65-8"></a>    else:
</span><span id="__span-65-9"><a id="__codelineno-65-9" name="__codelineno-65-9" href="#__codelineno-65-9"></a>        return &quot;a&quot;
</span><span id="__span-65-10"><a id="__codelineno-65-10" name="__codelineno-65-10" href="#__codelineno-65-10"></a>
</span><span id="__span-65-11"><a id="__codelineno-65-11" name="__codelineno-65-11" href="#__codelineno-65-11"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-65-12"><a id="__codelineno-65-12" name="__codelineno-65-12" href="#__codelineno-65-12"></a>builder.add_conditional_edges(&quot;a&quot;, route)
</span><span id="__span-65-13"><a id="__codelineno-65-13" name="__codelineno-65-13" href="#__codelineno-65-13"></a>builder.add_edge(&quot;b&quot;, &quot;a&quot;)
</span><span id="__span-65-14"><a id="__codelineno-65-14" name="__codelineno-65-14" href="#__codelineno-65-14"></a>graph = builder.compile()
</span></code></pre></div>
<p>To control the recursion limit, specify "recursion_limit" in the config. This will raise a GraphRecursionError, which you can catch and handle:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-66-1"><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a>from langgraph.errors import GraphRecursionError
</span><span id="__span-66-2"><a id="__codelineno-66-2" name="__codelineno-66-2" href="#__codelineno-66-2"></a>
</span><span id="__span-66-3"><a id="__codelineno-66-3" name="__codelineno-66-3" href="#__codelineno-66-3"></a>try:
</span><span id="__span-66-4"><a id="__codelineno-66-4" name="__codelineno-66-4" href="#__codelineno-66-4"></a>    graph.invoke(inputs, {&quot;recursion_limit&quot;: 3})
</span><span id="__span-66-5"><a id="__codelineno-66-5" name="__codelineno-66-5" href="#__codelineno-66-5"></a>except GraphRecursionError:
</span><span id="__span-66-6"><a id="__codelineno-66-6" name="__codelineno-66-6" href="#__codelineno-66-6"></a>    print(&quot;Recursion Error&quot;)
</span></code></pre></div>
<h2 id="define-the-graph_1">Define the graph<a class="headerlink" href="#define-the-graph_1" title="Permanent link">#</a></h2>
<p>Let's define a graph with a simple loop. Note that we use a conditional edge to implement a termination condition.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-67-1"><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a>import operator
</span><span id="__span-67-2"><a id="__codelineno-67-2" name="__codelineno-67-2" href="#__codelineno-67-2"></a>from typing import Annotated, Literal
</span><span id="__span-67-3"><a id="__codelineno-67-3" name="__codelineno-67-3" href="#__codelineno-67-3"></a>
</span><span id="__span-67-4"><a id="__codelineno-67-4" name="__codelineno-67-4" href="#__codelineno-67-4"></a>from typing_extensions import TypedDict
</span><span id="__span-67-5"><a id="__codelineno-67-5" name="__codelineno-67-5" href="#__codelineno-67-5"></a>
</span><span id="__span-67-6"><a id="__codelineno-67-6" name="__codelineno-67-6" href="#__codelineno-67-6"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-67-7"><a id="__codelineno-67-7" name="__codelineno-67-7" href="#__codelineno-67-7"></a>
</span><span id="__span-67-8"><a id="__codelineno-67-8" name="__codelineno-67-8" href="#__codelineno-67-8"></a>
</span><span id="__span-67-9"><a id="__codelineno-67-9" name="__codelineno-67-9" href="#__codelineno-67-9"></a>class State(TypedDict):
</span><span id="__span-67-10"><a id="__codelineno-67-10" name="__codelineno-67-10" href="#__codelineno-67-10"></a>    # The operator.add reducer fn makes this append-only
</span><span id="__span-67-11"><a id="__codelineno-67-11" name="__codelineno-67-11" href="#__codelineno-67-11"></a>    aggregate: Annotated[list, operator.add]
</span><span id="__span-67-12"><a id="__codelineno-67-12" name="__codelineno-67-12" href="#__codelineno-67-12"></a>
</span><span id="__span-67-13"><a id="__codelineno-67-13" name="__codelineno-67-13" href="#__codelineno-67-13"></a>
</span><span id="__span-67-14"><a id="__codelineno-67-14" name="__codelineno-67-14" href="#__codelineno-67-14"></a>def a(state: State):
</span><span id="__span-67-15"><a id="__codelineno-67-15" name="__codelineno-67-15" href="#__codelineno-67-15"></a>    print(f&#39;Node A sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-67-16"><a id="__codelineno-67-16" name="__codelineno-67-16" href="#__codelineno-67-16"></a>    return {&quot;aggregate&quot;: [&quot;A&quot;]}
</span><span id="__span-67-17"><a id="__codelineno-67-17" name="__codelineno-67-17" href="#__codelineno-67-17"></a>
</span><span id="__span-67-18"><a id="__codelineno-67-18" name="__codelineno-67-18" href="#__codelineno-67-18"></a>
</span><span id="__span-67-19"><a id="__codelineno-67-19" name="__codelineno-67-19" href="#__codelineno-67-19"></a>def b(state: State):
</span><span id="__span-67-20"><a id="__codelineno-67-20" name="__codelineno-67-20" href="#__codelineno-67-20"></a>    print(f&#39;Node B sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-67-21"><a id="__codelineno-67-21" name="__codelineno-67-21" href="#__codelineno-67-21"></a>    return {&quot;aggregate&quot;: [&quot;B&quot;]}
</span><span id="__span-67-22"><a id="__codelineno-67-22" name="__codelineno-67-22" href="#__codelineno-67-22"></a>
</span><span id="__span-67-23"><a id="__codelineno-67-23" name="__codelineno-67-23" href="#__codelineno-67-23"></a>
</span><span id="__span-67-24"><a id="__codelineno-67-24" name="__codelineno-67-24" href="#__codelineno-67-24"></a># Define nodes
</span><span id="__span-67-25"><a id="__codelineno-67-25" name="__codelineno-67-25" href="#__codelineno-67-25"></a>builder = StateGraph(State)
</span><span id="__span-67-26"><a id="__codelineno-67-26" name="__codelineno-67-26" href="#__codelineno-67-26"></a>builder.add_node(a)
</span><span id="__span-67-27"><a id="__codelineno-67-27" name="__codelineno-67-27" href="#__codelineno-67-27"></a>builder.add_node(b)
</span><span id="__span-67-28"><a id="__codelineno-67-28" name="__codelineno-67-28" href="#__codelineno-67-28"></a>
</span><span id="__span-67-29"><a id="__codelineno-67-29" name="__codelineno-67-29" href="#__codelineno-67-29"></a>
</span><span id="__span-67-30"><a id="__codelineno-67-30" name="__codelineno-67-30" href="#__codelineno-67-30"></a># Define edges
</span><span id="__span-67-31"><a id="__codelineno-67-31" name="__codelineno-67-31" href="#__codelineno-67-31"></a>def route(state: State) -&gt; Literal[&quot;b&quot;, END]:
</span><span id="__span-67-32"><a id="__codelineno-67-32" name="__codelineno-67-32" href="#__codelineno-67-32"></a>    if len(state[&quot;aggregate&quot;]) &lt; 7:
</span><span id="__span-67-33"><a id="__codelineno-67-33" name="__codelineno-67-33" href="#__codelineno-67-33"></a>        return &quot;b&quot;
</span><span id="__span-67-34"><a id="__codelineno-67-34" name="__codelineno-67-34" href="#__codelineno-67-34"></a>    else:
</span><span id="__span-67-35"><a id="__codelineno-67-35" name="__codelineno-67-35" href="#__codelineno-67-35"></a>        return END
</span><span id="__span-67-36"><a id="__codelineno-67-36" name="__codelineno-67-36" href="#__codelineno-67-36"></a>
</span><span id="__span-67-37"><a id="__codelineno-67-37" name="__codelineno-67-37" href="#__codelineno-67-37"></a>
</span><span id="__span-67-38"><a id="__codelineno-67-38" name="__codelineno-67-38" href="#__codelineno-67-38"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-67-39"><a id="__codelineno-67-39" name="__codelineno-67-39" href="#__codelineno-67-39"></a>builder.add_conditional_edges(&quot;a&quot;, route)
</span><span id="__span-67-40"><a id="__codelineno-67-40" name="__codelineno-67-40" href="#__codelineno-67-40"></a>builder.add_edge(&quot;b&quot;, &quot;a&quot;)
</span><span id="__span-67-41"><a id="__codelineno-67-41" name="__codelineno-67-41" href="#__codelineno-67-41"></a>graph = builder.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-68-1"><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a>from IPython.display import Image, display
</span><span id="__span-68-2"><a id="__codelineno-68-2" name="__codelineno-68-2" href="#__codelineno-68-2"></a>
</span><span id="__span-68-3"><a id="__codelineno-68-3" name="__codelineno-68-3" href="#__codelineno-68-3"></a>display(Image(graph.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<p>This architecture is similar to a ReAct agent in which node "a" is a tool-calling model, and node "b" represents the tools.</p>
<p>In our route conditional edge, we specify that we should end after the "aggregate" list in the state passes a threshold length.</p>
<p>Invoking the graph, we see that we alternate between nodes "a" and "b" before terminating once we reach the termination condition.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-69-1"><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a>graph.invoke({&quot;aggregate&quot;: []})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-70-1"><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a>Node A sees []
</span><span id="__span-70-2"><a id="__codelineno-70-2" name="__codelineno-70-2" href="#__codelineno-70-2"></a>Node B sees [&#39;A&#39;]
</span><span id="__span-70-3"><a id="__codelineno-70-3" name="__codelineno-70-3" href="#__codelineno-70-3"></a>Node A sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-70-4"><a id="__codelineno-70-4" name="__codelineno-70-4" href="#__codelineno-70-4"></a>Node B sees [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;]
</span><span id="__span-70-5"><a id="__codelineno-70-5" name="__codelineno-70-5" href="#__codelineno-70-5"></a>Node A sees [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;]
</span><span id="__span-70-6"><a id="__codelineno-70-6" name="__codelineno-70-6" href="#__codelineno-70-6"></a>Node B sees [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;]
</span><span id="__span-70-7"><a id="__codelineno-70-7" name="__codelineno-70-7" href="#__codelineno-70-7"></a>Node A sees [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;]
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-71-1"><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a>{&#39;aggregate&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;]}
</span></code></pre></div>
<h2 id="impose-a-recursion-limit">Impose a recursion limit<a class="headerlink" href="#impose-a-recursion-limit" title="Permanent link">#</a></h2>
<p>In some applications, we may not have a guarantee that we will reach a given termination condition. In these cases, we can set the graph's recursion limit. This will raise a GraphRecursionError after a given number of supersteps. We can then catch and handle this exception:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-72-1"><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a>from langgraph.errors import GraphRecursionError
</span><span id="__span-72-2"><a id="__codelineno-72-2" name="__codelineno-72-2" href="#__codelineno-72-2"></a>
</span><span id="__span-72-3"><a id="__codelineno-72-3" name="__codelineno-72-3" href="#__codelineno-72-3"></a>try:
</span><span id="__span-72-4"><a id="__codelineno-72-4" name="__codelineno-72-4" href="#__codelineno-72-4"></a>    graph.invoke({&quot;aggregate&quot;: []}, {&quot;recursion_limit&quot;: 4})
</span><span id="__span-72-5"><a id="__codelineno-72-5" name="__codelineno-72-5" href="#__codelineno-72-5"></a>except GraphRecursionError:
</span><span id="__span-72-6"><a id="__codelineno-72-6" name="__codelineno-72-6" href="#__codelineno-72-6"></a>    print(&quot;Recursion Error&quot;)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-73-1"><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a>Node A sees []
</span><span id="__span-73-2"><a id="__codelineno-73-2" name="__codelineno-73-2" href="#__codelineno-73-2"></a>Node B sees [&#39;A&#39;]
</span><span id="__span-73-3"><a id="__codelineno-73-3" name="__codelineno-73-3" href="#__codelineno-73-3"></a>Node A sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-73-4"><a id="__codelineno-73-4" name="__codelineno-73-4" href="#__codelineno-73-4"></a>Node B sees [&#39;A&#39;, &#39;B&#39;, &#39;A&#39;]
</span><span id="__span-73-5"><a id="__codelineno-73-5" name="__codelineno-73-5" href="#__codelineno-73-5"></a>Recursion Error
</span></code></pre></div>
<h2 id="loops-with-branches">Loops with branches<a class="headerlink" href="#loops-with-branches" title="Permanent link">#</a></h2>
<p>To better understand how the recursion limit works, let's consider a more complex example. Below we implement a loop, but one step fans out into two nodes:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-74-1"><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a>import operator
</span><span id="__span-74-2"><a id="__codelineno-74-2" name="__codelineno-74-2" href="#__codelineno-74-2"></a>from typing import Annotated, Literal
</span><span id="__span-74-3"><a id="__codelineno-74-3" name="__codelineno-74-3" href="#__codelineno-74-3"></a>
</span><span id="__span-74-4"><a id="__codelineno-74-4" name="__codelineno-74-4" href="#__codelineno-74-4"></a>from typing_extensions import TypedDict
</span><span id="__span-74-5"><a id="__codelineno-74-5" name="__codelineno-74-5" href="#__codelineno-74-5"></a>
</span><span id="__span-74-6"><a id="__codelineno-74-6" name="__codelineno-74-6" href="#__codelineno-74-6"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-74-7"><a id="__codelineno-74-7" name="__codelineno-74-7" href="#__codelineno-74-7"></a>
</span><span id="__span-74-8"><a id="__codelineno-74-8" name="__codelineno-74-8" href="#__codelineno-74-8"></a>
</span><span id="__span-74-9"><a id="__codelineno-74-9" name="__codelineno-74-9" href="#__codelineno-74-9"></a>class State(TypedDict):
</span><span id="__span-74-10"><a id="__codelineno-74-10" name="__codelineno-74-10" href="#__codelineno-74-10"></a>    aggregate: Annotated[list, operator.add]
</span><span id="__span-74-11"><a id="__codelineno-74-11" name="__codelineno-74-11" href="#__codelineno-74-11"></a>
</span><span id="__span-74-12"><a id="__codelineno-74-12" name="__codelineno-74-12" href="#__codelineno-74-12"></a>
</span><span id="__span-74-13"><a id="__codelineno-74-13" name="__codelineno-74-13" href="#__codelineno-74-13"></a>def a(state: State):
</span><span id="__span-74-14"><a id="__codelineno-74-14" name="__codelineno-74-14" href="#__codelineno-74-14"></a>    print(f&#39;Node A sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-74-15"><a id="__codelineno-74-15" name="__codelineno-74-15" href="#__codelineno-74-15"></a>    return {&quot;aggregate&quot;: [&quot;A&quot;]}
</span><span id="__span-74-16"><a id="__codelineno-74-16" name="__codelineno-74-16" href="#__codelineno-74-16"></a>
</span><span id="__span-74-17"><a id="__codelineno-74-17" name="__codelineno-74-17" href="#__codelineno-74-17"></a>
</span><span id="__span-74-18"><a id="__codelineno-74-18" name="__codelineno-74-18" href="#__codelineno-74-18"></a>def b(state: State):
</span><span id="__span-74-19"><a id="__codelineno-74-19" name="__codelineno-74-19" href="#__codelineno-74-19"></a>    print(f&#39;Node B sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-74-20"><a id="__codelineno-74-20" name="__codelineno-74-20" href="#__codelineno-74-20"></a>    return {&quot;aggregate&quot;: [&quot;B&quot;]}
</span><span id="__span-74-21"><a id="__codelineno-74-21" name="__codelineno-74-21" href="#__codelineno-74-21"></a>
</span><span id="__span-74-22"><a id="__codelineno-74-22" name="__codelineno-74-22" href="#__codelineno-74-22"></a>
</span><span id="__span-74-23"><a id="__codelineno-74-23" name="__codelineno-74-23" href="#__codelineno-74-23"></a>def c(state: State):
</span><span id="__span-74-24"><a id="__codelineno-74-24" name="__codelineno-74-24" href="#__codelineno-74-24"></a>    print(f&#39;Node C sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-74-25"><a id="__codelineno-74-25" name="__codelineno-74-25" href="#__codelineno-74-25"></a>    return {&quot;aggregate&quot;: [&quot;C&quot;]}
</span><span id="__span-74-26"><a id="__codelineno-74-26" name="__codelineno-74-26" href="#__codelineno-74-26"></a>
</span><span id="__span-74-27"><a id="__codelineno-74-27" name="__codelineno-74-27" href="#__codelineno-74-27"></a>
</span><span id="__span-74-28"><a id="__codelineno-74-28" name="__codelineno-74-28" href="#__codelineno-74-28"></a>def d(state: State):
</span><span id="__span-74-29"><a id="__codelineno-74-29" name="__codelineno-74-29" href="#__codelineno-74-29"></a>    print(f&#39;Node D sees {state[&quot;aggregate&quot;]}&#39;)
</span><span id="__span-74-30"><a id="__codelineno-74-30" name="__codelineno-74-30" href="#__codelineno-74-30"></a>    return {&quot;aggregate&quot;: [&quot;D&quot;]}
</span><span id="__span-74-31"><a id="__codelineno-74-31" name="__codelineno-74-31" href="#__codelineno-74-31"></a>
</span><span id="__span-74-32"><a id="__codelineno-74-32" name="__codelineno-74-32" href="#__codelineno-74-32"></a>
</span><span id="__span-74-33"><a id="__codelineno-74-33" name="__codelineno-74-33" href="#__codelineno-74-33"></a># Define nodes
</span><span id="__span-74-34"><a id="__codelineno-74-34" name="__codelineno-74-34" href="#__codelineno-74-34"></a>builder = StateGraph(State)
</span><span id="__span-74-35"><a id="__codelineno-74-35" name="__codelineno-74-35" href="#__codelineno-74-35"></a>builder.add_node(a)
</span><span id="__span-74-36"><a id="__codelineno-74-36" name="__codelineno-74-36" href="#__codelineno-74-36"></a>builder.add_node(b)
</span><span id="__span-74-37"><a id="__codelineno-74-37" name="__codelineno-74-37" href="#__codelineno-74-37"></a>builder.add_node(c)
</span><span id="__span-74-38"><a id="__codelineno-74-38" name="__codelineno-74-38" href="#__codelineno-74-38"></a>builder.add_node(d)
</span><span id="__span-74-39"><a id="__codelineno-74-39" name="__codelineno-74-39" href="#__codelineno-74-39"></a>
</span><span id="__span-74-40"><a id="__codelineno-74-40" name="__codelineno-74-40" href="#__codelineno-74-40"></a>
</span><span id="__span-74-41"><a id="__codelineno-74-41" name="__codelineno-74-41" href="#__codelineno-74-41"></a># Define edges
</span><span id="__span-74-42"><a id="__codelineno-74-42" name="__codelineno-74-42" href="#__codelineno-74-42"></a>def route(state: State) -&gt; Literal[&quot;b&quot;, END]:
</span><span id="__span-74-43"><a id="__codelineno-74-43" name="__codelineno-74-43" href="#__codelineno-74-43"></a>    if len(state[&quot;aggregate&quot;]) &lt; 7:
</span><span id="__span-74-44"><a id="__codelineno-74-44" name="__codelineno-74-44" href="#__codelineno-74-44"></a>        return &quot;b&quot;
</span><span id="__span-74-45"><a id="__codelineno-74-45" name="__codelineno-74-45" href="#__codelineno-74-45"></a>    else:
</span><span id="__span-74-46"><a id="__codelineno-74-46" name="__codelineno-74-46" href="#__codelineno-74-46"></a>        return END
</span><span id="__span-74-47"><a id="__codelineno-74-47" name="__codelineno-74-47" href="#__codelineno-74-47"></a>
</span><span id="__span-74-48"><a id="__codelineno-74-48" name="__codelineno-74-48" href="#__codelineno-74-48"></a>
</span><span id="__span-74-49"><a id="__codelineno-74-49" name="__codelineno-74-49" href="#__codelineno-74-49"></a>builder.add_edge(START, &quot;a&quot;)
</span><span id="__span-74-50"><a id="__codelineno-74-50" name="__codelineno-74-50" href="#__codelineno-74-50"></a>builder.add_conditional_edges(&quot;a&quot;, route)
</span><span id="__span-74-51"><a id="__codelineno-74-51" name="__codelineno-74-51" href="#__codelineno-74-51"></a>builder.add_edge(&quot;b&quot;, &quot;c&quot;)
</span><span id="__span-74-52"><a id="__codelineno-74-52" name="__codelineno-74-52" href="#__codelineno-74-52"></a>builder.add_edge(&quot;b&quot;, &quot;d&quot;)
</span><span id="__span-74-53"><a id="__codelineno-74-53" name="__codelineno-74-53" href="#__codelineno-74-53"></a>builder.add_edge([&quot;c&quot;, &quot;d&quot;], &quot;a&quot;)
</span><span id="__span-74-54"><a id="__codelineno-74-54" name="__codelineno-74-54" href="#__codelineno-74-54"></a>graph = builder.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-75-1"><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a>from IPython.display import Image, display
</span><span id="__span-75-2"><a id="__codelineno-75-2" name="__codelineno-75-2" href="#__codelineno-75-2"></a>
</span><span id="__span-75-3"><a id="__codelineno-75-3" name="__codelineno-75-3" href="#__codelineno-75-3"></a>display(Image(graph.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<p>This graph looks complex, but can be conceptualized as loop of supersteps:</p>
<ol>
<li>Node A</li>
<li>Node B</li>
<li>Nodes C and D</li>
<li>Node A</li>
<li>...
We have a loop of four supersteps, where nodes C and D are executed concurrently.</li>
</ol>
<p>Invoking the graph as before, we see that we complete two full "laps" before hitting the termination condition:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-76-1"><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a>result = graph.invoke({&quot;aggregate&quot;: []})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-77-1"><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a>Node A sees []
</span><span id="__span-77-2"><a id="__codelineno-77-2" name="__codelineno-77-2" href="#__codelineno-77-2"></a>Node B sees [&#39;A&#39;]
</span><span id="__span-77-3"><a id="__codelineno-77-3" name="__codelineno-77-3" href="#__codelineno-77-3"></a>Node D sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-77-4"><a id="__codelineno-77-4" name="__codelineno-77-4" href="#__codelineno-77-4"></a>Node C sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-77-5"><a id="__codelineno-77-5" name="__codelineno-77-5" href="#__codelineno-77-5"></a>Node A sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;]
</span><span id="__span-77-6"><a id="__codelineno-77-6" name="__codelineno-77-6" href="#__codelineno-77-6"></a>Node B sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;A&#39;]
</span><span id="__span-77-7"><a id="__codelineno-77-7" name="__codelineno-77-7" href="#__codelineno-77-7"></a>Node D sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;A&#39;, &#39;B&#39;]
</span><span id="__span-77-8"><a id="__codelineno-77-8" name="__codelineno-77-8" href="#__codelineno-77-8"></a>Node C sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;A&#39;, &#39;B&#39;]
</span><span id="__span-77-9"><a id="__codelineno-77-9" name="__codelineno-77-9" href="#__codelineno-77-9"></a>Node A sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;]
</span></code></pre></div>
<p>However, if we set the recursion limit to four, we only complete one lap because each lap is four supersteps:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-78-1"><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a>from langgraph.errors import GraphRecursionError
</span><span id="__span-78-2"><a id="__codelineno-78-2" name="__codelineno-78-2" href="#__codelineno-78-2"></a>
</span><span id="__span-78-3"><a id="__codelineno-78-3" name="__codelineno-78-3" href="#__codelineno-78-3"></a>try:
</span><span id="__span-78-4"><a id="__codelineno-78-4" name="__codelineno-78-4" href="#__codelineno-78-4"></a>    result = graph.invoke({&quot;aggregate&quot;: []}, {&quot;recursion_limit&quot;: 4})
</span><span id="__span-78-5"><a id="__codelineno-78-5" name="__codelineno-78-5" href="#__codelineno-78-5"></a>except GraphRecursionError:
</span><span id="__span-78-6"><a id="__codelineno-78-6" name="__codelineno-78-6" href="#__codelineno-78-6"></a>    print(&quot;Recursion Error&quot;)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-79-1"><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a>Node A sees []
</span><span id="__span-79-2"><a id="__codelineno-79-2" name="__codelineno-79-2" href="#__codelineno-79-2"></a>Node B sees [&#39;A&#39;]
</span><span id="__span-79-3"><a id="__codelineno-79-3" name="__codelineno-79-3" href="#__codelineno-79-3"></a>Node C sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-79-4"><a id="__codelineno-79-4" name="__codelineno-79-4" href="#__codelineno-79-4"></a>Node D sees [&#39;A&#39;, &#39;B&#39;]
</span><span id="__span-79-5"><a id="__codelineno-79-5" name="__codelineno-79-5" href="#__codelineno-79-5"></a>Node A sees [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;]
</span><span id="__span-79-6"><a id="__codelineno-79-6" name="__codelineno-79-6" href="#__codelineno-79-6"></a>Recursion Error
</span></code></pre></div>
<h2 id="how-to-visualize-your-graph">How to visualize your graph<a class="headerlink" href="#how-to-visualize-your-graph" title="Permanent link">#</a></h2>
<h2 id="set-up-graph">Set up Graph<a class="headerlink" href="#set-up-graph" title="Permanent link">#</a></h2>
<p>You can visualize any arbitrary Graph, including StateGraph. Let's have some fun by drawing fractals :).</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-80-1"><a id="__codelineno-80-1" name="__codelineno-80-1" href="#__codelineno-80-1"></a>import random
</span><span id="__span-80-2"><a id="__codelineno-80-2" name="__codelineno-80-2" href="#__codelineno-80-2"></a>from typing import Annotated, Literal
</span><span id="__span-80-3"><a id="__codelineno-80-3" name="__codelineno-80-3" href="#__codelineno-80-3"></a>
</span><span id="__span-80-4"><a id="__codelineno-80-4" name="__codelineno-80-4" href="#__codelineno-80-4"></a>from typing_extensions import TypedDict
</span><span id="__span-80-5"><a id="__codelineno-80-5" name="__codelineno-80-5" href="#__codelineno-80-5"></a>
</span><span id="__span-80-6"><a id="__codelineno-80-6" name="__codelineno-80-6" href="#__codelineno-80-6"></a>from langgraph.graph import StateGraph, START, END
</span><span id="__span-80-7"><a id="__codelineno-80-7" name="__codelineno-80-7" href="#__codelineno-80-7"></a>from langgraph.graph.message import add_messages
</span><span id="__span-80-8"><a id="__codelineno-80-8" name="__codelineno-80-8" href="#__codelineno-80-8"></a>
</span><span id="__span-80-9"><a id="__codelineno-80-9" name="__codelineno-80-9" href="#__codelineno-80-9"></a>
</span><span id="__span-80-10"><a id="__codelineno-80-10" name="__codelineno-80-10" href="#__codelineno-80-10"></a>class State(TypedDict):
</span><span id="__span-80-11"><a id="__codelineno-80-11" name="__codelineno-80-11" href="#__codelineno-80-11"></a>    messages: Annotated[list, add_messages]
</span><span id="__span-80-12"><a id="__codelineno-80-12" name="__codelineno-80-12" href="#__codelineno-80-12"></a>
</span><span id="__span-80-13"><a id="__codelineno-80-13" name="__codelineno-80-13" href="#__codelineno-80-13"></a>
</span><span id="__span-80-14"><a id="__codelineno-80-14" name="__codelineno-80-14" href="#__codelineno-80-14"></a>class MyNode:
</span><span id="__span-80-15"><a id="__codelineno-80-15" name="__codelineno-80-15" href="#__codelineno-80-15"></a>    def __init__(self, name: str):
</span><span id="__span-80-16"><a id="__codelineno-80-16" name="__codelineno-80-16" href="#__codelineno-80-16"></a>        self.name = name
</span><span id="__span-80-17"><a id="__codelineno-80-17" name="__codelineno-80-17" href="#__codelineno-80-17"></a>
</span><span id="__span-80-18"><a id="__codelineno-80-18" name="__codelineno-80-18" href="#__codelineno-80-18"></a>    def __call__(self, state: State):
</span><span id="__span-80-19"><a id="__codelineno-80-19" name="__codelineno-80-19" href="#__codelineno-80-19"></a>        return {&quot;messages&quot;: [(&quot;assistant&quot;, f&quot;Called node {self.name}&quot;)]}
</span><span id="__span-80-20"><a id="__codelineno-80-20" name="__codelineno-80-20" href="#__codelineno-80-20"></a>
</span><span id="__span-80-21"><a id="__codelineno-80-21" name="__codelineno-80-21" href="#__codelineno-80-21"></a>
</span><span id="__span-80-22"><a id="__codelineno-80-22" name="__codelineno-80-22" href="#__codelineno-80-22"></a>def route(state) -&gt; Literal[&quot;entry_node&quot;, &quot;__end__&quot;]:
</span><span id="__span-80-23"><a id="__codelineno-80-23" name="__codelineno-80-23" href="#__codelineno-80-23"></a>    if len(state[&quot;messages&quot;]) &gt; 10:
</span><span id="__span-80-24"><a id="__codelineno-80-24" name="__codelineno-80-24" href="#__codelineno-80-24"></a>        return &quot;__end__&quot;
</span><span id="__span-80-25"><a id="__codelineno-80-25" name="__codelineno-80-25" href="#__codelineno-80-25"></a>    return &quot;entry_node&quot;
</span><span id="__span-80-26"><a id="__codelineno-80-26" name="__codelineno-80-26" href="#__codelineno-80-26"></a>
</span><span id="__span-80-27"><a id="__codelineno-80-27" name="__codelineno-80-27" href="#__codelineno-80-27"></a>
</span><span id="__span-80-28"><a id="__codelineno-80-28" name="__codelineno-80-28" href="#__codelineno-80-28"></a>def add_fractal_nodes(builder, current_node, level, max_level):
</span><span id="__span-80-29"><a id="__codelineno-80-29" name="__codelineno-80-29" href="#__codelineno-80-29"></a>    if level &gt; max_level:
</span><span id="__span-80-30"><a id="__codelineno-80-30" name="__codelineno-80-30" href="#__codelineno-80-30"></a>        return
</span><span id="__span-80-31"><a id="__codelineno-80-31" name="__codelineno-80-31" href="#__codelineno-80-31"></a>
</span><span id="__span-80-32"><a id="__codelineno-80-32" name="__codelineno-80-32" href="#__codelineno-80-32"></a>    # Number of nodes to create at this level
</span><span id="__span-80-33"><a id="__codelineno-80-33" name="__codelineno-80-33" href="#__codelineno-80-33"></a>    num_nodes = random.randint(1, 3)  # Adjust randomness as needed
</span><span id="__span-80-34"><a id="__codelineno-80-34" name="__codelineno-80-34" href="#__codelineno-80-34"></a>    for i in range(num_nodes):
</span><span id="__span-80-35"><a id="__codelineno-80-35" name="__codelineno-80-35" href="#__codelineno-80-35"></a>        nm = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;][i]
</span><span id="__span-80-36"><a id="__codelineno-80-36" name="__codelineno-80-36" href="#__codelineno-80-36"></a>        node_name = f&quot;node_{current_node}_{nm}&quot;
</span><span id="__span-80-37"><a id="__codelineno-80-37" name="__codelineno-80-37" href="#__codelineno-80-37"></a>        builder.add_node(node_name, MyNode(node_name))
</span><span id="__span-80-38"><a id="__codelineno-80-38" name="__codelineno-80-38" href="#__codelineno-80-38"></a>        builder.add_edge(current_node, node_name)
</span><span id="__span-80-39"><a id="__codelineno-80-39" name="__codelineno-80-39" href="#__codelineno-80-39"></a>
</span><span id="__span-80-40"><a id="__codelineno-80-40" name="__codelineno-80-40" href="#__codelineno-80-40"></a>        # Recursively add more nodes
</span><span id="__span-80-41"><a id="__codelineno-80-41" name="__codelineno-80-41" href="#__codelineno-80-41"></a>        r = random.random()
</span><span id="__span-80-42"><a id="__codelineno-80-42" name="__codelineno-80-42" href="#__codelineno-80-42"></a>        if r &gt; 0.2 and level + 1 &lt; max_level:
</span><span id="__span-80-43"><a id="__codelineno-80-43" name="__codelineno-80-43" href="#__codelineno-80-43"></a>            add_fractal_nodes(builder, node_name, level + 1, max_level)
</span><span id="__span-80-44"><a id="__codelineno-80-44" name="__codelineno-80-44" href="#__codelineno-80-44"></a>        elif r &gt; 0.05:
</span><span id="__span-80-45"><a id="__codelineno-80-45" name="__codelineno-80-45" href="#__codelineno-80-45"></a>            builder.add_conditional_edges(node_name, route, node_name)
</span><span id="__span-80-46"><a id="__codelineno-80-46" name="__codelineno-80-46" href="#__codelineno-80-46"></a>        else:
</span><span id="__span-80-47"><a id="__codelineno-80-47" name="__codelineno-80-47" href="#__codelineno-80-47"></a>            # End
</span><span id="__span-80-48"><a id="__codelineno-80-48" name="__codelineno-80-48" href="#__codelineno-80-48"></a>            builder.add_edge(node_name, &quot;__end__&quot;)
</span><span id="__span-80-49"><a id="__codelineno-80-49" name="__codelineno-80-49" href="#__codelineno-80-49"></a>
</span><span id="__span-80-50"><a id="__codelineno-80-50" name="__codelineno-80-50" href="#__codelineno-80-50"></a>
</span><span id="__span-80-51"><a id="__codelineno-80-51" name="__codelineno-80-51" href="#__codelineno-80-51"></a>def build_fractal_graph(max_level: int):
</span><span id="__span-80-52"><a id="__codelineno-80-52" name="__codelineno-80-52" href="#__codelineno-80-52"></a>    builder = StateGraph(State)
</span><span id="__span-80-53"><a id="__codelineno-80-53" name="__codelineno-80-53" href="#__codelineno-80-53"></a>    entry_point = &quot;entry_node&quot;
</span><span id="__span-80-54"><a id="__codelineno-80-54" name="__codelineno-80-54" href="#__codelineno-80-54"></a>    builder.add_node(entry_point, MyNode(entry_point))
</span><span id="__span-80-55"><a id="__codelineno-80-55" name="__codelineno-80-55" href="#__codelineno-80-55"></a>    builder.add_edge(START, entry_point)
</span><span id="__span-80-56"><a id="__codelineno-80-56" name="__codelineno-80-56" href="#__codelineno-80-56"></a>
</span><span id="__span-80-57"><a id="__codelineno-80-57" name="__codelineno-80-57" href="#__codelineno-80-57"></a>    add_fractal_nodes(builder, entry_point, 1, max_level)
</span><span id="__span-80-58"><a id="__codelineno-80-58" name="__codelineno-80-58" href="#__codelineno-80-58"></a>
</span><span id="__span-80-59"><a id="__codelineno-80-59" name="__codelineno-80-59" href="#__codelineno-80-59"></a>    # Optional: set a finish point if required
</span><span id="__span-80-60"><a id="__codelineno-80-60" name="__codelineno-80-60" href="#__codelineno-80-60"></a>    builder.add_edge(entry_point, END)  # or any specific node
</span><span id="__span-80-61"><a id="__codelineno-80-61" name="__codelineno-80-61" href="#__codelineno-80-61"></a>
</span><span id="__span-80-62"><a id="__codelineno-80-62" name="__codelineno-80-62" href="#__codelineno-80-62"></a>    return builder.compile()
</span><span id="__span-80-63"><a id="__codelineno-80-63" name="__codelineno-80-63" href="#__codelineno-80-63"></a>
</span><span id="__span-80-64"><a id="__codelineno-80-64" name="__codelineno-80-64" href="#__codelineno-80-64"></a>
</span><span id="__span-80-65"><a id="__codelineno-80-65" name="__codelineno-80-65" href="#__codelineno-80-65"></a>app = build_fractal_graph(3)
</span></code></pre></div>
<h2 id="mermaid">Mermaid<a class="headerlink" href="#mermaid" title="Permanent link">#</a></h2>
<p>We can also convert a graph class into Mermaid syntax.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-81-1"><a id="__codelineno-81-1" name="__codelineno-81-1" href="#__codelineno-81-1"></a>print(app.get_graph().draw_mermaid())
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-82-1"><a id="__codelineno-82-1" name="__codelineno-82-1" href="#__codelineno-82-1"></a>%%{init: {&#39;flowchart&#39;: {&#39;curve&#39;: &#39;linear&#39;}}}%%
</span><span id="__span-82-2"><a id="__codelineno-82-2" name="__codelineno-82-2" href="#__codelineno-82-2"></a>graph TD;
</span><span id="__span-82-3"><a id="__codelineno-82-3" name="__codelineno-82-3" href="#__codelineno-82-3"></a>    __start__([&lt;p&gt;__start__&lt;/p&gt;]):::first
</span><span id="__span-82-4"><a id="__codelineno-82-4" name="__codelineno-82-4" href="#__codelineno-82-4"></a>    entry_node(entry_node)
</span><span id="__span-82-5"><a id="__codelineno-82-5" name="__codelineno-82-5" href="#__codelineno-82-5"></a>    node_entry_node_A(node_entry_node_A)
</span><span id="__span-82-6"><a id="__codelineno-82-6" name="__codelineno-82-6" href="#__codelineno-82-6"></a>    node_entry_node_B(node_entry_node_B)
</span><span id="__span-82-7"><a id="__codelineno-82-7" name="__codelineno-82-7" href="#__codelineno-82-7"></a>    node_node_entry_node_B_A(node_node_entry_node_B_A)
</span><span id="__span-82-8"><a id="__codelineno-82-8" name="__codelineno-82-8" href="#__codelineno-82-8"></a>    node_node_entry_node_B_B(node_node_entry_node_B_B)
</span><span id="__span-82-9"><a id="__codelineno-82-9" name="__codelineno-82-9" href="#__codelineno-82-9"></a>    node_node_entry_node_B_C(node_node_entry_node_B_C)
</span><span id="__span-82-10"><a id="__codelineno-82-10" name="__codelineno-82-10" href="#__codelineno-82-10"></a>    __end__([&lt;p&gt;__end__&lt;/p&gt;]):::last
</span><span id="__span-82-11"><a id="__codelineno-82-11" name="__codelineno-82-11" href="#__codelineno-82-11"></a>    __start__ --&gt; entry_node;
</span><span id="__span-82-12"><a id="__codelineno-82-12" name="__codelineno-82-12" href="#__codelineno-82-12"></a>    entry_node --&gt; __end__;
</span><span id="__span-82-13"><a id="__codelineno-82-13" name="__codelineno-82-13" href="#__codelineno-82-13"></a>    entry_node --&gt; node_entry_node_A;
</span><span id="__span-82-14"><a id="__codelineno-82-14" name="__codelineno-82-14" href="#__codelineno-82-14"></a>    entry_node --&gt; node_entry_node_B;
</span><span id="__span-82-15"><a id="__codelineno-82-15" name="__codelineno-82-15" href="#__codelineno-82-15"></a>    node_entry_node_B --&gt; node_node_entry_node_B_A;
</span><span id="__span-82-16"><a id="__codelineno-82-16" name="__codelineno-82-16" href="#__codelineno-82-16"></a>    node_entry_node_B --&gt; node_node_entry_node_B_B;
</span><span id="__span-82-17"><a id="__codelineno-82-17" name="__codelineno-82-17" href="#__codelineno-82-17"></a>    node_entry_node_B --&gt; node_node_entry_node_B_C;
</span><span id="__span-82-18"><a id="__codelineno-82-18" name="__codelineno-82-18" href="#__codelineno-82-18"></a>    node_entry_node_A -.-&gt; entry_node;
</span><span id="__span-82-19"><a id="__codelineno-82-19" name="__codelineno-82-19" href="#__codelineno-82-19"></a>    node_entry_node_A -.-&gt; __end__;
</span><span id="__span-82-20"><a id="__codelineno-82-20" name="__codelineno-82-20" href="#__codelineno-82-20"></a>    node_node_entry_node_B_A -.-&gt; entry_node;
</span><span id="__span-82-21"><a id="__codelineno-82-21" name="__codelineno-82-21" href="#__codelineno-82-21"></a>    node_node_entry_node_B_A -.-&gt; __end__;
</span><span id="__span-82-22"><a id="__codelineno-82-22" name="__codelineno-82-22" href="#__codelineno-82-22"></a>    node_node_entry_node_B_B -.-&gt; entry_node;
</span><span id="__span-82-23"><a id="__codelineno-82-23" name="__codelineno-82-23" href="#__codelineno-82-23"></a>    node_node_entry_node_B_B -.-&gt; __end__;
</span><span id="__span-82-24"><a id="__codelineno-82-24" name="__codelineno-82-24" href="#__codelineno-82-24"></a>    node_node_entry_node_B_C -.-&gt; entry_node;
</span><span id="__span-82-25"><a id="__codelineno-82-25" name="__codelineno-82-25" href="#__codelineno-82-25"></a>    node_node_entry_node_B_C -.-&gt; __end__;
</span><span id="__span-82-26"><a id="__codelineno-82-26" name="__codelineno-82-26" href="#__codelineno-82-26"></a>    classDef default fill:#f2f0ff,line-height:1.2
</span><span id="__span-82-27"><a id="__codelineno-82-27" name="__codelineno-82-27" href="#__codelineno-82-27"></a>    classDef first fill-opacity:0
</span><span id="__span-82-28"><a id="__codelineno-82-28" name="__codelineno-82-28" href="#__codelineno-82-28"></a>    classDef last fill:#bfb6fc
</span></code></pre></div>
<h2 id="png">PNG<a class="headerlink" href="#png" title="Permanent link">#</a></h2>
<p>If preferred, we could render the Graph into a .png. Here we could use three options:</p>
<ul>
<li>Using Mermaid.ink API (does not require additional packages)</li>
<li>Using Mermaid + Pyppeteer (requires pip install pyppeteer)</li>
<li>Using graphviz (which requires pip install graphviz)</li>
</ul>
<h2 id="using-mermaidink">Using Mermaid.Ink<a class="headerlink" href="#using-mermaidink" title="Permanent link">#</a></h2>
<p>By default, draw_mermaid_png() uses Mermaid.Ink's API to generate the diagram.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-83-1"><a id="__codelineno-83-1" name="__codelineno-83-1" href="#__codelineno-83-1"></a>from IPython.display import Image, display
</span><span id="__span-83-2"><a id="__codelineno-83-2" name="__codelineno-83-2" href="#__codelineno-83-2"></a>from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles
</span><span id="__span-83-3"><a id="__codelineno-83-3" name="__codelineno-83-3" href="#__codelineno-83-3"></a>
</span><span id="__span-83-4"><a id="__codelineno-83-4" name="__codelineno-83-4" href="#__codelineno-83-4"></a>display(
</span><span id="__span-83-5"><a id="__codelineno-83-5" name="__codelineno-83-5" href="#__codelineno-83-5"></a>    Image(
</span><span id="__span-83-6"><a id="__codelineno-83-6" name="__codelineno-83-6" href="#__codelineno-83-6"></a>        app.get_graph().draw_mermaid_png(
</span><span id="__span-83-7"><a id="__codelineno-83-7" name="__codelineno-83-7" href="#__codelineno-83-7"></a>            draw_method=MermaidDrawMethod.API,
</span><span id="__span-83-8"><a id="__codelineno-83-8" name="__codelineno-83-8" href="#__codelineno-83-8"></a>        )
</span><span id="__span-83-9"><a id="__codelineno-83-9" name="__codelineno-83-9" href="#__codelineno-83-9"></a>    )
</span><span id="__span-83-10"><a id="__codelineno-83-10" name="__codelineno-83-10" href="#__codelineno-83-10"></a>)
</span></code></pre></div>
<p><img alt="Mermaid" src="../image/Mermaid.png" /></p>
<h2 id="using-mermaid-pyppeteer">Using Mermaid + Pyppeteer<a class="headerlink" href="#using-mermaid-pyppeteer" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-84-1"><a id="__codelineno-84-1" name="__codelineno-84-1" href="#__codelineno-84-1"></a>%%capture --no-stderr
</span><span id="__span-84-2"><a id="__codelineno-84-2" name="__codelineno-84-2" href="#__codelineno-84-2"></a>%pip install --quiet pyppeteer
</span><span id="__span-84-3"><a id="__codelineno-84-3" name="__codelineno-84-3" href="#__codelineno-84-3"></a>%pip install --quiet nest_asyncio
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-85-1"><a id="__codelineno-85-1" name="__codelineno-85-1" href="#__codelineno-85-1"></a>import nest_asyncio
</span><span id="__span-85-2"><a id="__codelineno-85-2" name="__codelineno-85-2" href="#__codelineno-85-2"></a>
</span><span id="__span-85-3"><a id="__codelineno-85-3" name="__codelineno-85-3" href="#__codelineno-85-3"></a>nest_asyncio.apply()  # Required for Jupyter Notebook to run async functions
</span><span id="__span-85-4"><a id="__codelineno-85-4" name="__codelineno-85-4" href="#__codelineno-85-4"></a>
</span><span id="__span-85-5"><a id="__codelineno-85-5" name="__codelineno-85-5" href="#__codelineno-85-5"></a>display(
</span><span id="__span-85-6"><a id="__codelineno-85-6" name="__codelineno-85-6" href="#__codelineno-85-6"></a>    Image(
</span><span id="__span-85-7"><a id="__codelineno-85-7" name="__codelineno-85-7" href="#__codelineno-85-7"></a>        app.get_graph().draw_mermaid_png(
</span><span id="__span-85-8"><a id="__codelineno-85-8" name="__codelineno-85-8" href="#__codelineno-85-8"></a>            curve_style=CurveStyle.LINEAR,
</span><span id="__span-85-9"><a id="__codelineno-85-9" name="__codelineno-85-9" href="#__codelineno-85-9"></a>            node_colors=NodeStyles(first=&quot;#ffdfba&quot;, last=&quot;#baffc9&quot;, default=&quot;#fad7de&quot;),
</span><span id="__span-85-10"><a id="__codelineno-85-10" name="__codelineno-85-10" href="#__codelineno-85-10"></a>            wrap_label_n_words=9,
</span><span id="__span-85-11"><a id="__codelineno-85-11" name="__codelineno-85-11" href="#__codelineno-85-11"></a>            output_file_path=None,
</span><span id="__span-85-12"><a id="__codelineno-85-12" name="__codelineno-85-12" href="#__codelineno-85-12"></a>            draw_method=MermaidDrawMethod.PYPPETEER,
</span><span id="__span-85-13"><a id="__codelineno-85-13" name="__codelineno-85-13" href="#__codelineno-85-13"></a>            background_color=&quot;white&quot;,
</span><span id="__span-85-14"><a id="__codelineno-85-14" name="__codelineno-85-14" href="#__codelineno-85-14"></a>            padding=10,
</span><span id="__span-85-15"><a id="__codelineno-85-15" name="__codelineno-85-15" href="#__codelineno-85-15"></a>        )
</span><span id="__span-85-16"><a id="__codelineno-85-16" name="__codelineno-85-16" href="#__codelineno-85-16"></a>    )
</span><span id="__span-85-17"><a id="__codelineno-85-17" name="__codelineno-85-17" href="#__codelineno-85-17"></a>)
</span></code></pre></div>
<p><img alt="Pyppeteer" src="../image/Pyppeteer.png" /></p>
<h2 id="using-graphviz">Using Graphviz<a class="headerlink" href="#using-graphviz" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-86-1"><a id="__codelineno-86-1" name="__codelineno-86-1" href="#__codelineno-86-1"></a>%%capture --no-stderr
</span><span id="__span-86-2"><a id="__codelineno-86-2" name="__codelineno-86-2" href="#__codelineno-86-2"></a>%pip install pygraphviz
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-87-1"><a id="__codelineno-87-1" name="__codelineno-87-1" href="#__codelineno-87-1"></a>try:
</span><span id="__span-87-2"><a id="__codelineno-87-2" name="__codelineno-87-2" href="#__codelineno-87-2"></a>    display(Image(app.get_graph().draw_png()))
</span><span id="__span-87-3"><a id="__codelineno-87-3" name="__codelineno-87-3" href="#__codelineno-87-3"></a>except ImportError:
</span><span id="__span-87-4"><a id="__codelineno-87-4" name="__codelineno-87-4" href="#__codelineno-87-4"></a>    print(
</span><span id="__span-87-5"><a id="__codelineno-87-5" name="__codelineno-87-5" href="#__codelineno-87-5"></a>        &quot;You likely need to install dependencies for pygraphviz, see more here https://github.com/pygraphviz/pygraphviz/blob/main/INSTALL.txt&quot;
</span><span id="__span-87-6"><a id="__codelineno-87-6" name="__codelineno-87-6" href="#__codelineno-87-6"></a>    )
</span></code></pre></div>
<p><img alt="Graphviz" src="../image/Graphviz.png" /></p>
<h1 id="fine-grained-control">Fine-grained Control<a class="headerlink" href="#fine-grained-control" title="Permanent link">#</a></h1>
<h2 id="how-to-combine-control-flow-and-state-updates-with-command">How to combine control flow and state updates with Command<a class="headerlink" href="#how-to-combine-control-flow-and-state-updates-with-command" title="Permanent link">#</a></h2>
<p>It can be useful to combine control flow (edges) and state updates (nodes). For example, you might want to BOTH perform state updates AND decide which node to go to next in the SAME node. LangGraph provides a way to do so by returning a Command object from node functions:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-88-1"><a id="__codelineno-88-1" name="__codelineno-88-1" href="#__codelineno-88-1"></a>def my_node(state: State) -&gt; Command[Literal[&quot;my_other_node&quot;]]:
</span><span id="__span-88-2"><a id="__codelineno-88-2" name="__codelineno-88-2" href="#__codelineno-88-2"></a>    return Command(
</span><span id="__span-88-3"><a id="__codelineno-88-3" name="__codelineno-88-3" href="#__codelineno-88-3"></a>        # state update
</span><span id="__span-88-4"><a id="__codelineno-88-4" name="__codelineno-88-4" href="#__codelineno-88-4"></a>        update={&quot;foo&quot;: &quot;bar&quot;},
</span><span id="__span-88-5"><a id="__codelineno-88-5" name="__codelineno-88-5" href="#__codelineno-88-5"></a>        # control flow
</span><span id="__span-88-6"><a id="__codelineno-88-6" name="__codelineno-88-6" href="#__codelineno-88-6"></a>        goto=&quot;my_other_node&quot;
</span><span id="__span-88-7"><a id="__codelineno-88-7" name="__codelineno-88-7" href="#__codelineno-88-7"></a>    )
</span></code></pre></div>
<p>If you are using subgraphs, you might want to navigate from a node within a subgraph to a different subgraph (i.e. a different node in the parent graph). To do so, you can specify graph=Command.PARENT in Command:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-89-1"><a id="__codelineno-89-1" name="__codelineno-89-1" href="#__codelineno-89-1"></a>def my_node(state: State) -&gt; Command[Literal[&quot;my_other_node&quot;]]:
</span><span id="__span-89-2"><a id="__codelineno-89-2" name="__codelineno-89-2" href="#__codelineno-89-2"></a>    return Command(
</span><span id="__span-89-3"><a id="__codelineno-89-3" name="__codelineno-89-3" href="#__codelineno-89-3"></a>        update={&quot;foo&quot;: &quot;bar&quot;},
</span><span id="__span-89-4"><a id="__codelineno-89-4" name="__codelineno-89-4" href="#__codelineno-89-4"></a>        goto=&quot;other_subgraph&quot;,  # where `other_subgraph` is a node in the parent graph
</span><span id="__span-89-5"><a id="__codelineno-89-5" name="__codelineno-89-5" href="#__codelineno-89-5"></a>        graph=Command.PARENT
</span><span id="__span-89-6"><a id="__codelineno-89-6" name="__codelineno-89-6" href="#__codelineno-89-6"></a>    )
</span></code></pre></div>
<h2 id="how-to-add-node-retry-policies">How to add node retry policies<a class="headerlink" href="#how-to-add-node-retry-policies" title="Permanent link">#</a></h2>
<p>There are many use cases where you may wish for your node to have a custom retry policy, for example if you are calling an API, querying a database, or calling an LLM, etc.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-90-1"><a id="__codelineno-90-1" name="__codelineno-90-1" href="#__codelineno-90-1"></a>%%capture --no-stderr
</span><span id="__span-90-2"><a id="__codelineno-90-2" name="__codelineno-90-2" href="#__codelineno-90-2"></a>%pip install -U langgraph langchain_anthropic langchain_community
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-91-1"><a id="__codelineno-91-1" name="__codelineno-91-1" href="#__codelineno-91-1"></a>import getpass
</span><span id="__span-91-2"><a id="__codelineno-91-2" name="__codelineno-91-2" href="#__codelineno-91-2"></a>import os
</span><span id="__span-91-3"><a id="__codelineno-91-3" name="__codelineno-91-3" href="#__codelineno-91-3"></a>
</span><span id="__span-91-4"><a id="__codelineno-91-4" name="__codelineno-91-4" href="#__codelineno-91-4"></a>
</span><span id="__span-91-5"><a id="__codelineno-91-5" name="__codelineno-91-5" href="#__codelineno-91-5"></a>def _set_env(var: str):
</span><span id="__span-91-6"><a id="__codelineno-91-6" name="__codelineno-91-6" href="#__codelineno-91-6"></a>    if not os.environ.get(var):
</span><span id="__span-91-7"><a id="__codelineno-91-7" name="__codelineno-91-7" href="#__codelineno-91-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-91-8"><a id="__codelineno-91-8" name="__codelineno-91-8" href="#__codelineno-91-8"></a>
</span><span id="__span-91-9"><a id="__codelineno-91-9" name="__codelineno-91-9" href="#__codelineno-91-9"></a>
</span><span id="__span-91-10"><a id="__codelineno-91-10" name="__codelineno-91-10" href="#__codelineno-91-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span></code></pre></div>
<p>In order to configure the retry policy, you have to pass the retry parameter to the add_node. The retry parameter takes in a RetryPolicy named tuple object. Below we instantiate a RetryPolicy object with the default parameters:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-92-1"><a id="__codelineno-92-1" name="__codelineno-92-1" href="#__codelineno-92-1"></a>from langgraph.pregel import RetryPolicy
</span><span id="__span-92-2"><a id="__codelineno-92-2" name="__codelineno-92-2" href="#__codelineno-92-2"></a>
</span><span id="__span-92-3"><a id="__codelineno-92-3" name="__codelineno-92-3" href="#__codelineno-92-3"></a>RetryPolicy()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-93-1"><a id="__codelineno-93-1" name="__codelineno-93-1" href="#__codelineno-93-1"></a>RetryPolicy(initial_interval=0.5, backoff_factor=2.0, max_interval=128.0, max_attempts=3, jitter=True, retry_on=&lt;function default_retry_on at 0x78b964b89940&gt;)
</span></code></pre></div>
<p>By default, the retry_on parameter uses the default_retry_on function, which retries on any exception except for the following:</p>
<ul>
<li>ValueError</li>
<li>TypeError</li>
<li>ArithmeticError</li>
<li>ImportError</li>
<li>LookupError</li>
<li>NameError</li>
<li>SyntaxError</li>
<li>RuntimeError</li>
<li>ReferenceError</li>
<li>StopIteration</li>
<li>StopAsyncIteration</li>
<li>OSError</li>
</ul>
<p>In addition, for exceptions from popular http request libraries such as requests and httpx it only retries on 5xx status codes.</p>
<h2 id="passing-a-retry-policy-to-a-node">Passing a retry policy to a node<a class="headerlink" href="#passing-a-retry-policy-to-a-node" title="Permanent link">#</a></h2>
<p>Lastly, we can pass RetryPolicy objects when we call the add_node function. In the example below we pass two different retry policies to each of our nodes:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-94-1"><a id="__codelineno-94-1" name="__codelineno-94-1" href="#__codelineno-94-1"></a>import operator
</span><span id="__span-94-2"><a id="__codelineno-94-2" name="__codelineno-94-2" href="#__codelineno-94-2"></a>import sqlite3
</span><span id="__span-94-3"><a id="__codelineno-94-3" name="__codelineno-94-3" href="#__codelineno-94-3"></a>from typing import Annotated, Sequence
</span><span id="__span-94-4"><a id="__codelineno-94-4" name="__codelineno-94-4" href="#__codelineno-94-4"></a>from typing_extensions import TypedDict
</span><span id="__span-94-5"><a id="__codelineno-94-5" name="__codelineno-94-5" href="#__codelineno-94-5"></a>
</span><span id="__span-94-6"><a id="__codelineno-94-6" name="__codelineno-94-6" href="#__codelineno-94-6"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-94-7"><a id="__codelineno-94-7" name="__codelineno-94-7" href="#__codelineno-94-7"></a>from langchain_core.messages import BaseMessage
</span><span id="__span-94-8"><a id="__codelineno-94-8" name="__codelineno-94-8" href="#__codelineno-94-8"></a>
</span><span id="__span-94-9"><a id="__codelineno-94-9" name="__codelineno-94-9" href="#__codelineno-94-9"></a>from langgraph.graph import END, StateGraph, START
</span><span id="__span-94-10"><a id="__codelineno-94-10" name="__codelineno-94-10" href="#__codelineno-94-10"></a>from langchain_community.utilities import SQLDatabase
</span><span id="__span-94-11"><a id="__codelineno-94-11" name="__codelineno-94-11" href="#__codelineno-94-11"></a>from langchain_core.messages import AIMessage
</span><span id="__span-94-12"><a id="__codelineno-94-12" name="__codelineno-94-12" href="#__codelineno-94-12"></a>
</span><span id="__span-94-13"><a id="__codelineno-94-13" name="__codelineno-94-13" href="#__codelineno-94-13"></a>db = SQLDatabase.from_uri(&quot;sqlite:///:memory:&quot;)
</span><span id="__span-94-14"><a id="__codelineno-94-14" name="__codelineno-94-14" href="#__codelineno-94-14"></a>
</span><span id="__span-94-15"><a id="__codelineno-94-15" name="__codelineno-94-15" href="#__codelineno-94-15"></a>model = ChatAnthropic(model_name=&quot;claude-2.1&quot;)
</span><span id="__span-94-16"><a id="__codelineno-94-16" name="__codelineno-94-16" href="#__codelineno-94-16"></a>
</span><span id="__span-94-17"><a id="__codelineno-94-17" name="__codelineno-94-17" href="#__codelineno-94-17"></a>
</span><span id="__span-94-18"><a id="__codelineno-94-18" name="__codelineno-94-18" href="#__codelineno-94-18"></a>class AgentState(TypedDict):
</span><span id="__span-94-19"><a id="__codelineno-94-19" name="__codelineno-94-19" href="#__codelineno-94-19"></a>    messages: Annotated[Sequence[BaseMessage], operator.add]
</span><span id="__span-94-20"><a id="__codelineno-94-20" name="__codelineno-94-20" href="#__codelineno-94-20"></a>
</span><span id="__span-94-21"><a id="__codelineno-94-21" name="__codelineno-94-21" href="#__codelineno-94-21"></a>
</span><span id="__span-94-22"><a id="__codelineno-94-22" name="__codelineno-94-22" href="#__codelineno-94-22"></a>def query_database(state):
</span><span id="__span-94-23"><a id="__codelineno-94-23" name="__codelineno-94-23" href="#__codelineno-94-23"></a>    query_result = db.run(&quot;SELECT * FROM Artist LIMIT 10;&quot;)
</span><span id="__span-94-24"><a id="__codelineno-94-24" name="__codelineno-94-24" href="#__codelineno-94-24"></a>    return {&quot;messages&quot;: [AIMessage(content=query_result)]}
</span><span id="__span-94-25"><a id="__codelineno-94-25" name="__codelineno-94-25" href="#__codelineno-94-25"></a>
</span><span id="__span-94-26"><a id="__codelineno-94-26" name="__codelineno-94-26" href="#__codelineno-94-26"></a>
</span><span id="__span-94-27"><a id="__codelineno-94-27" name="__codelineno-94-27" href="#__codelineno-94-27"></a>def call_model(state):
</span><span id="__span-94-28"><a id="__codelineno-94-28" name="__codelineno-94-28" href="#__codelineno-94-28"></a>    response = model.invoke(state[&quot;messages&quot;])
</span><span id="__span-94-29"><a id="__codelineno-94-29" name="__codelineno-94-29" href="#__codelineno-94-29"></a>    return {&quot;messages&quot;: [response]}
</span><span id="__span-94-30"><a id="__codelineno-94-30" name="__codelineno-94-30" href="#__codelineno-94-30"></a>
</span><span id="__span-94-31"><a id="__codelineno-94-31" name="__codelineno-94-31" href="#__codelineno-94-31"></a>
</span><span id="__span-94-32"><a id="__codelineno-94-32" name="__codelineno-94-32" href="#__codelineno-94-32"></a># Define a new graph
</span><span id="__span-94-33"><a id="__codelineno-94-33" name="__codelineno-94-33" href="#__codelineno-94-33"></a>builder = StateGraph(AgentState)
</span><span id="__span-94-34"><a id="__codelineno-94-34" name="__codelineno-94-34" href="#__codelineno-94-34"></a>builder.add_node(
</span><span id="__span-94-35"><a id="__codelineno-94-35" name="__codelineno-94-35" href="#__codelineno-94-35"></a>    &quot;query_database&quot;,
</span><span id="__span-94-36"><a id="__codelineno-94-36" name="__codelineno-94-36" href="#__codelineno-94-36"></a>    query_database,
</span><span id="__span-94-37"><a id="__codelineno-94-37" name="__codelineno-94-37" href="#__codelineno-94-37"></a>    retry=RetryPolicy(retry_on=sqlite3.OperationalError),
</span><span id="__span-94-38"><a id="__codelineno-94-38" name="__codelineno-94-38" href="#__codelineno-94-38"></a>)
</span><span id="__span-94-39"><a id="__codelineno-94-39" name="__codelineno-94-39" href="#__codelineno-94-39"></a>builder.add_node(&quot;model&quot;, call_model, retry=RetryPolicy(max_attempts=5))
</span><span id="__span-94-40"><a id="__codelineno-94-40" name="__codelineno-94-40" href="#__codelineno-94-40"></a>builder.add_edge(START, &quot;model&quot;)
</span><span id="__span-94-41"><a id="__codelineno-94-41" name="__codelineno-94-41" href="#__codelineno-94-41"></a>builder.add_edge(&quot;model&quot;, &quot;query_database&quot;)
</span><span id="__span-94-42"><a id="__codelineno-94-42" name="__codelineno-94-42" href="#__codelineno-94-42"></a>builder.add_edge(&quot;query_database&quot;, END)
</span><span id="__span-94-43"><a id="__codelineno-94-43" name="__codelineno-94-43" href="#__codelineno-94-43"></a>
</span><span id="__span-94-44"><a id="__codelineno-94-44" name="__codelineno-94-44" href="#__codelineno-94-44"></a>graph = builder.compile()
</span></code></pre></div>
<h2 id="how-to-return-state-before-hitting-recursion-limit">How to return state before hitting recursion limit<a class="headerlink" href="#how-to-return-state-before-hitting-recursion-limit" title="Permanent link">#</a></h2>
<p>Setting the graph recursion limit can help you control how long your graph will stay running, but if the recursion limit is hit your graph returns an error - which may not be ideal for all use cases. Instead you may wish to return the value of the state just before the recursion limit is hit. This how-to will show you how to do this.</p>
<h2 id="without-returning-state">Without returning state<a class="headerlink" href="#without-returning-state" title="Permanent link">#</a></h2>
<p>We are going to define a dummy graph in this example that will always hit the recursion limit. First, we will implement it without returning the state and show that it hits the recursion limit. This graph is based on the ReAct architecture, but instead of actually making decisions and taking actions it just loops forever.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-95-1"><a id="__codelineno-95-1" name="__codelineno-95-1" href="#__codelineno-95-1"></a>from typing_extensions import TypedDict
</span><span id="__span-95-2"><a id="__codelineno-95-2" name="__codelineno-95-2" href="#__codelineno-95-2"></a>from langgraph.graph import StateGraph
</span><span id="__span-95-3"><a id="__codelineno-95-3" name="__codelineno-95-3" href="#__codelineno-95-3"></a>from langgraph.graph import START, END
</span><span id="__span-95-4"><a id="__codelineno-95-4" name="__codelineno-95-4" href="#__codelineno-95-4"></a>
</span><span id="__span-95-5"><a id="__codelineno-95-5" name="__codelineno-95-5" href="#__codelineno-95-5"></a>
</span><span id="__span-95-6"><a id="__codelineno-95-6" name="__codelineno-95-6" href="#__codelineno-95-6"></a>class State(TypedDict):
</span><span id="__span-95-7"><a id="__codelineno-95-7" name="__codelineno-95-7" href="#__codelineno-95-7"></a>    value: str
</span><span id="__span-95-8"><a id="__codelineno-95-8" name="__codelineno-95-8" href="#__codelineno-95-8"></a>    action_result: str
</span><span id="__span-95-9"><a id="__codelineno-95-9" name="__codelineno-95-9" href="#__codelineno-95-9"></a>
</span><span id="__span-95-10"><a id="__codelineno-95-10" name="__codelineno-95-10" href="#__codelineno-95-10"></a>
</span><span id="__span-95-11"><a id="__codelineno-95-11" name="__codelineno-95-11" href="#__codelineno-95-11"></a>def router(state: State):
</span><span id="__span-95-12"><a id="__codelineno-95-12" name="__codelineno-95-12" href="#__codelineno-95-12"></a>    if state[&quot;value&quot;] == &quot;end&quot;:
</span><span id="__span-95-13"><a id="__codelineno-95-13" name="__codelineno-95-13" href="#__codelineno-95-13"></a>        return END
</span><span id="__span-95-14"><a id="__codelineno-95-14" name="__codelineno-95-14" href="#__codelineno-95-14"></a>    else:
</span><span id="__span-95-15"><a id="__codelineno-95-15" name="__codelineno-95-15" href="#__codelineno-95-15"></a>        return &quot;action&quot;
</span><span id="__span-95-16"><a id="__codelineno-95-16" name="__codelineno-95-16" href="#__codelineno-95-16"></a>
</span><span id="__span-95-17"><a id="__codelineno-95-17" name="__codelineno-95-17" href="#__codelineno-95-17"></a>
</span><span id="__span-95-18"><a id="__codelineno-95-18" name="__codelineno-95-18" href="#__codelineno-95-18"></a>def decision_node(state):
</span><span id="__span-95-19"><a id="__codelineno-95-19" name="__codelineno-95-19" href="#__codelineno-95-19"></a>    return {&quot;value&quot;: &quot;keep going!&quot;}
</span><span id="__span-95-20"><a id="__codelineno-95-20" name="__codelineno-95-20" href="#__codelineno-95-20"></a>
</span><span id="__span-95-21"><a id="__codelineno-95-21" name="__codelineno-95-21" href="#__codelineno-95-21"></a>
</span><span id="__span-95-22"><a id="__codelineno-95-22" name="__codelineno-95-22" href="#__codelineno-95-22"></a>def action_node(state: State):
</span><span id="__span-95-23"><a id="__codelineno-95-23" name="__codelineno-95-23" href="#__codelineno-95-23"></a>    # Do your action here ...
</span><span id="__span-95-24"><a id="__codelineno-95-24" name="__codelineno-95-24" href="#__codelineno-95-24"></a>    return {&quot;action_result&quot;: &quot;what a great result!&quot;}
</span><span id="__span-95-25"><a id="__codelineno-95-25" name="__codelineno-95-25" href="#__codelineno-95-25"></a>
</span><span id="__span-95-26"><a id="__codelineno-95-26" name="__codelineno-95-26" href="#__codelineno-95-26"></a>
</span><span id="__span-95-27"><a id="__codelineno-95-27" name="__codelineno-95-27" href="#__codelineno-95-27"></a>workflow = StateGraph(State)
</span><span id="__span-95-28"><a id="__codelineno-95-28" name="__codelineno-95-28" href="#__codelineno-95-28"></a>workflow.add_node(&quot;decision&quot;, decision_node)
</span><span id="__span-95-29"><a id="__codelineno-95-29" name="__codelineno-95-29" href="#__codelineno-95-29"></a>workflow.add_node(&quot;action&quot;, action_node)
</span><span id="__span-95-30"><a id="__codelineno-95-30" name="__codelineno-95-30" href="#__codelineno-95-30"></a>workflow.add_edge(START, &quot;decision&quot;)
</span><span id="__span-95-31"><a id="__codelineno-95-31" name="__codelineno-95-31" href="#__codelineno-95-31"></a>workflow.add_conditional_edges(&quot;decision&quot;, router, [&quot;action&quot;, END])
</span><span id="__span-95-32"><a id="__codelineno-95-32" name="__codelineno-95-32" href="#__codelineno-95-32"></a>workflow.add_edge(&quot;action&quot;, &quot;decision&quot;)
</span><span id="__span-95-33"><a id="__codelineno-95-33" name="__codelineno-95-33" href="#__codelineno-95-33"></a>app = workflow.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-96-1"><a id="__codelineno-96-1" name="__codelineno-96-1" href="#__codelineno-96-1"></a>from IPython.display import Image, display
</span><span id="__span-96-2"><a id="__codelineno-96-2" name="__codelineno-96-2" href="#__codelineno-96-2"></a>
</span><span id="__span-96-3"><a id="__codelineno-96-3" name="__codelineno-96-3" href="#__codelineno-96-3"></a>display(Image(app.get_graph().draw_mermaid_png()))
</span></code></pre></div>
<p>Let's verify that our graph will always hit the recursion limit:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-97-1"><a id="__codelineno-97-1" name="__codelineno-97-1" href="#__codelineno-97-1"></a>from langgraph.errors import GraphRecursionError
</span><span id="__span-97-2"><a id="__codelineno-97-2" name="__codelineno-97-2" href="#__codelineno-97-2"></a>
</span><span id="__span-97-3"><a id="__codelineno-97-3" name="__codelineno-97-3" href="#__codelineno-97-3"></a>try:
</span><span id="__span-97-4"><a id="__codelineno-97-4" name="__codelineno-97-4" href="#__codelineno-97-4"></a>    app.invoke({&quot;value&quot;: &quot;hi!&quot;})
</span><span id="__span-97-5"><a id="__codelineno-97-5" name="__codelineno-97-5" href="#__codelineno-97-5"></a>except GraphRecursionError:
</span><span id="__span-97-6"><a id="__codelineno-97-6" name="__codelineno-97-6" href="#__codelineno-97-6"></a>    print(&quot;Recursion Error&quot;)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-98-1"><a id="__codelineno-98-1" name="__codelineno-98-1" href="#__codelineno-98-1"></a>Recursion Error
</span></code></pre></div>
<h2 id="with-returning-state">With returning state<a class="headerlink" href="#with-returning-state" title="Permanent link">#</a></h2>
<p>To avoid hitting the recursion limit, we can introduce a new key to our state called remaining_steps. It will keep track of number of steps until reaching the recursion limit. We can then check the value of remaining_steps to determine whether we should terminate the graph execution and return the state to the user without causing the RecursionError.</p>
<p>To do so, we will use a special RemainingSteps annotation. Under the hood, it creates a special ManagedValue channel -- a state channel that will exist for the duration of our graph run and no longer.</p>
<p>Since our action node is going to always induce at least 2 extra steps to our graph (since the action node ALWAYS calls the decision node afterwards), we will use this channel to check if we are within 2 steps of the limit.</p>
<p>Now, when we run our graph we should receive no errors and instead get the last value of the state before the recursion limit was hit.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-99-1"><a id="__codelineno-99-1" name="__codelineno-99-1" href="#__codelineno-99-1"></a>from typing_extensions import TypedDict
</span><span id="__span-99-2"><a id="__codelineno-99-2" name="__codelineno-99-2" href="#__codelineno-99-2"></a>from langgraph.graph import StateGraph
</span><span id="__span-99-3"><a id="__codelineno-99-3" name="__codelineno-99-3" href="#__codelineno-99-3"></a>from typing import Annotated
</span><span id="__span-99-4"><a id="__codelineno-99-4" name="__codelineno-99-4" href="#__codelineno-99-4"></a>
</span><span id="__span-99-5"><a id="__codelineno-99-5" name="__codelineno-99-5" href="#__codelineno-99-5"></a>from langgraph.managed.is_last_step import RemainingSteps
</span><span id="__span-99-6"><a id="__codelineno-99-6" name="__codelineno-99-6" href="#__codelineno-99-6"></a>
</span><span id="__span-99-7"><a id="__codelineno-99-7" name="__codelineno-99-7" href="#__codelineno-99-7"></a>
</span><span id="__span-99-8"><a id="__codelineno-99-8" name="__codelineno-99-8" href="#__codelineno-99-8"></a>class State(TypedDict):
</span><span id="__span-99-9"><a id="__codelineno-99-9" name="__codelineno-99-9" href="#__codelineno-99-9"></a>    value: str
</span><span id="__span-99-10"><a id="__codelineno-99-10" name="__codelineno-99-10" href="#__codelineno-99-10"></a>    action_result: str
</span><span id="__span-99-11"><a id="__codelineno-99-11" name="__codelineno-99-11" href="#__codelineno-99-11"></a>    remaining_steps: RemainingSteps
</span><span id="__span-99-12"><a id="__codelineno-99-12" name="__codelineno-99-12" href="#__codelineno-99-12"></a>
</span><span id="__span-99-13"><a id="__codelineno-99-13" name="__codelineno-99-13" href="#__codelineno-99-13"></a>
</span><span id="__span-99-14"><a id="__codelineno-99-14" name="__codelineno-99-14" href="#__codelineno-99-14"></a>def router(state: State):
</span><span id="__span-99-15"><a id="__codelineno-99-15" name="__codelineno-99-15" href="#__codelineno-99-15"></a>    # Force the agent to end
</span><span id="__span-99-16"><a id="__codelineno-99-16" name="__codelineno-99-16" href="#__codelineno-99-16"></a>    if state[&quot;remaining_steps&quot;] &lt;= 2:
</span><span id="__span-99-17"><a id="__codelineno-99-17" name="__codelineno-99-17" href="#__codelineno-99-17"></a>        return END
</span><span id="__span-99-18"><a id="__codelineno-99-18" name="__codelineno-99-18" href="#__codelineno-99-18"></a>    if state[&quot;value&quot;] == &quot;end&quot;:
</span><span id="__span-99-19"><a id="__codelineno-99-19" name="__codelineno-99-19" href="#__codelineno-99-19"></a>        return END
</span><span id="__span-99-20"><a id="__codelineno-99-20" name="__codelineno-99-20" href="#__codelineno-99-20"></a>    else:
</span><span id="__span-99-21"><a id="__codelineno-99-21" name="__codelineno-99-21" href="#__codelineno-99-21"></a>        return &quot;action&quot;
</span><span id="__span-99-22"><a id="__codelineno-99-22" name="__codelineno-99-22" href="#__codelineno-99-22"></a>
</span><span id="__span-99-23"><a id="__codelineno-99-23" name="__codelineno-99-23" href="#__codelineno-99-23"></a>
</span><span id="__span-99-24"><a id="__codelineno-99-24" name="__codelineno-99-24" href="#__codelineno-99-24"></a>def decision_node(state):
</span><span id="__span-99-25"><a id="__codelineno-99-25" name="__codelineno-99-25" href="#__codelineno-99-25"></a>    return {&quot;value&quot;: &quot;keep going!&quot;}
</span><span id="__span-99-26"><a id="__codelineno-99-26" name="__codelineno-99-26" href="#__codelineno-99-26"></a>
</span><span id="__span-99-27"><a id="__codelineno-99-27" name="__codelineno-99-27" href="#__codelineno-99-27"></a>
</span><span id="__span-99-28"><a id="__codelineno-99-28" name="__codelineno-99-28" href="#__codelineno-99-28"></a>def action_node(state: State):
</span><span id="__span-99-29"><a id="__codelineno-99-29" name="__codelineno-99-29" href="#__codelineno-99-29"></a>    # Do your action here ...
</span><span id="__span-99-30"><a id="__codelineno-99-30" name="__codelineno-99-30" href="#__codelineno-99-30"></a>    return {&quot;action_result&quot;: &quot;what a great result!&quot;}
</span><span id="__span-99-31"><a id="__codelineno-99-31" name="__codelineno-99-31" href="#__codelineno-99-31"></a>
</span><span id="__span-99-32"><a id="__codelineno-99-32" name="__codelineno-99-32" href="#__codelineno-99-32"></a>
</span><span id="__span-99-33"><a id="__codelineno-99-33" name="__codelineno-99-33" href="#__codelineno-99-33"></a>workflow = StateGraph(State)
</span><span id="__span-99-34"><a id="__codelineno-99-34" name="__codelineno-99-34" href="#__codelineno-99-34"></a>workflow.add_node(&quot;decision&quot;, decision_node)
</span><span id="__span-99-35"><a id="__codelineno-99-35" name="__codelineno-99-35" href="#__codelineno-99-35"></a>workflow.add_node(&quot;action&quot;, action_node)
</span><span id="__span-99-36"><a id="__codelineno-99-36" name="__codelineno-99-36" href="#__codelineno-99-36"></a>workflow.add_edge(START, &quot;decision&quot;)
</span><span id="__span-99-37"><a id="__codelineno-99-37" name="__codelineno-99-37" href="#__codelineno-99-37"></a>workflow.add_conditional_edges(&quot;decision&quot;, router, [&quot;action&quot;, END])
</span><span id="__span-99-38"><a id="__codelineno-99-38" name="__codelineno-99-38" href="#__codelineno-99-38"></a>workflow.add_edge(&quot;action&quot;, &quot;decision&quot;)
</span><span id="__span-99-39"><a id="__codelineno-99-39" name="__codelineno-99-39" href="#__codelineno-99-39"></a>app = workflow.compile()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-100-1"><a id="__codelineno-100-1" name="__codelineno-100-1" href="#__codelineno-100-1"></a>app.invoke({&quot;value&quot;: &quot;hi!&quot;})
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-101-1"><a id="__codelineno-101-1" name="__codelineno-101-1" href="#__codelineno-101-1"></a>{&#39;value&#39;: &#39;keep going!&#39;, &#39;action_result&#39;: &#39;what a great result!&#39;}
</span></code></pre></div>
<h2 id="persistence_1">Persistence<a class="headerlink" href="#persistence_1" title="Permanent link">#</a></h2>
<p>LangGraph Persistence makes it easy to persist state across graph runs (per-thread persistence) and across threads (cross-thread persistence). These how-to guides show how to add persistence to your graph.</p>
<h2 id="how-to-add-thread-level-persistence-to-your-graph">How to add thread-level persistence to your graph<a class="headerlink" href="#how-to-add-thread-level-persistence-to-your-graph" title="Permanent link">#</a></h2>
<p>Many AI applications need memory to share context across multiple interactions. In LangGraph, this kind of memory can be added to any StateGraph using thread-level persistence .</p>
<p>When creating any LangGraph graph, you can set it up to persist its state by adding a checkpointer when compiling the graph:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-102-1"><a id="__codelineno-102-1" name="__codelineno-102-1" href="#__codelineno-102-1"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-102-2"><a id="__codelineno-102-2" name="__codelineno-102-2" href="#__codelineno-102-2"></a>
</span><span id="__span-102-3"><a id="__codelineno-102-3" name="__codelineno-102-3" href="#__codelineno-102-3"></a>checkpointer = MemorySaver()
</span><span id="__span-102-4"><a id="__codelineno-102-4" name="__codelineno-102-4" href="#__codelineno-102-4"></a>graph.compile(checkpointer=checkpointer)
</span></code></pre></div>
<p><strong>Note:</strong> If you need memory that is shared across multiple conversations or users (cross-thread persistence), check out this how-to guide.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-103-1"><a id="__codelineno-103-1" name="__codelineno-103-1" href="#__codelineno-103-1"></a>%%capture --no-stderr
</span><span id="__span-103-2"><a id="__codelineno-103-2" name="__codelineno-103-2" href="#__codelineno-103-2"></a>%pip install --quiet -U langgraph langchain_anthropic
</span></code></pre></div>
<p>Next, we need to set API key for Anthropic (the LLM we will use).</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-104-1"><a id="__codelineno-104-1" name="__codelineno-104-1" href="#__codelineno-104-1"></a>import getpass
</span><span id="__span-104-2"><a id="__codelineno-104-2" name="__codelineno-104-2" href="#__codelineno-104-2"></a>import os
</span><span id="__span-104-3"><a id="__codelineno-104-3" name="__codelineno-104-3" href="#__codelineno-104-3"></a>
</span><span id="__span-104-4"><a id="__codelineno-104-4" name="__codelineno-104-4" href="#__codelineno-104-4"></a>
</span><span id="__span-104-5"><a id="__codelineno-104-5" name="__codelineno-104-5" href="#__codelineno-104-5"></a>def _set_env(var: str):
</span><span id="__span-104-6"><a id="__codelineno-104-6" name="__codelineno-104-6" href="#__codelineno-104-6"></a>    if not os.environ.get(var):
</span><span id="__span-104-7"><a id="__codelineno-104-7" name="__codelineno-104-7" href="#__codelineno-104-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-104-8"><a id="__codelineno-104-8" name="__codelineno-104-8" href="#__codelineno-104-8"></a>
</span><span id="__span-104-9"><a id="__codelineno-104-9" name="__codelineno-104-9" href="#__codelineno-104-9"></a>
</span><span id="__span-104-10"><a id="__codelineno-104-10" name="__codelineno-104-10" href="#__codelineno-104-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span></code></pre></div>
<h2 id="define-graph">Define graph<a class="headerlink" href="#define-graph" title="Permanent link">#</a></h2>
<p>We will be using a single-node graph that calls a chat model.</p>
<p>Let's first define the model we'll be using:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-105-1"><a id="__codelineno-105-1" name="__codelineno-105-1" href="#__codelineno-105-1"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-105-2"><a id="__codelineno-105-2" name="__codelineno-105-2" href="#__codelineno-105-2"></a>
</span><span id="__span-105-3"><a id="__codelineno-105-3" name="__codelineno-105-3" href="#__codelineno-105-3"></a>model = ChatAnthropic(model=&quot;claude-3-5-sonnet-20240620&quot;)
</span></code></pre></div>
<p>Now we can define our StateGraph and add our model-calling node:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-106-1"><a id="__codelineno-106-1" name="__codelineno-106-1" href="#__codelineno-106-1"></a>from typing import Annotated
</span><span id="__span-106-2"><a id="__codelineno-106-2" name="__codelineno-106-2" href="#__codelineno-106-2"></a>from typing_extensions import TypedDict
</span><span id="__span-106-3"><a id="__codelineno-106-3" name="__codelineno-106-3" href="#__codelineno-106-3"></a>
</span><span id="__span-106-4"><a id="__codelineno-106-4" name="__codelineno-106-4" href="#__codelineno-106-4"></a>from langgraph.graph import StateGraph, MessagesState, START
</span><span id="__span-106-5"><a id="__codelineno-106-5" name="__codelineno-106-5" href="#__codelineno-106-5"></a>
</span><span id="__span-106-6"><a id="__codelineno-106-6" name="__codelineno-106-6" href="#__codelineno-106-6"></a>
</span><span id="__span-106-7"><a id="__codelineno-106-7" name="__codelineno-106-7" href="#__codelineno-106-7"></a>def call_model(state: MessagesState):
</span><span id="__span-106-8"><a id="__codelineno-106-8" name="__codelineno-106-8" href="#__codelineno-106-8"></a>    response = model.invoke(state[&quot;messages&quot;])
</span><span id="__span-106-9"><a id="__codelineno-106-9" name="__codelineno-106-9" href="#__codelineno-106-9"></a>    return {&quot;messages&quot;: response}
</span><span id="__span-106-10"><a id="__codelineno-106-10" name="__codelineno-106-10" href="#__codelineno-106-10"></a>
</span><span id="__span-106-11"><a id="__codelineno-106-11" name="__codelineno-106-11" href="#__codelineno-106-11"></a>
</span><span id="__span-106-12"><a id="__codelineno-106-12" name="__codelineno-106-12" href="#__codelineno-106-12"></a>builder = StateGraph(MessagesState)
</span><span id="__span-106-13"><a id="__codelineno-106-13" name="__codelineno-106-13" href="#__codelineno-106-13"></a>builder.add_node(&quot;call_model&quot;, call_model)
</span><span id="__span-106-14"><a id="__codelineno-106-14" name="__codelineno-106-14" href="#__codelineno-106-14"></a>builder.add_edge(START, &quot;call_model&quot;)
</span><span id="__span-106-15"><a id="__codelineno-106-15" name="__codelineno-106-15" href="#__codelineno-106-15"></a>graph = builder.compile()
</span></code></pre></div>
<p>If we try to use this graph, the context of the conversation will not be persisted across interactions:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-107-1"><a id="__codelineno-107-1" name="__codelineno-107-1" href="#__codelineno-107-1"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi! I&#39;m bob&quot;}
</span><span id="__span-107-2"><a id="__codelineno-107-2" name="__codelineno-107-2" href="#__codelineno-107-2"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, stream_mode=&quot;values&quot;):
</span><span id="__span-107-3"><a id="__codelineno-107-3" name="__codelineno-107-3" href="#__codelineno-107-3"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span><span id="__span-107-4"><a id="__codelineno-107-4" name="__codelineno-107-4" href="#__codelineno-107-4"></a>
</span><span id="__span-107-5"><a id="__codelineno-107-5" name="__codelineno-107-5" href="#__codelineno-107-5"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#39;s my name?&quot;}
</span><span id="__span-107-6"><a id="__codelineno-107-6" name="__codelineno-107-6" href="#__codelineno-107-6"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, stream_mode=&quot;values&quot;):
</span><span id="__span-107-7"><a id="__codelineno-107-7" name="__codelineno-107-7" href="#__codelineno-107-7"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-108-1"><a id="__codelineno-108-1" name="__codelineno-108-1" href="#__codelineno-108-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-108-2"><a id="__codelineno-108-2" name="__codelineno-108-2" href="#__codelineno-108-2"></a>
</span><span id="__span-108-3"><a id="__codelineno-108-3" name="__codelineno-108-3" href="#__codelineno-108-3"></a>hi! I&#39;m bob
</span><span id="__span-108-4"><a id="__codelineno-108-4" name="__codelineno-108-4" href="#__codelineno-108-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-108-5"><a id="__codelineno-108-5" name="__codelineno-108-5" href="#__codelineno-108-5"></a>
</span><span id="__span-108-6"><a id="__codelineno-108-6" name="__codelineno-108-6" href="#__codelineno-108-6"></a>Hello Bob! It&#39;s nice to meet you. How are you doing today? Is there anything I can help you with or would you like to chat about something in particular?
</span><span id="__span-108-7"><a id="__codelineno-108-7" name="__codelineno-108-7" href="#__codelineno-108-7"></a>================================[1m Human Message [0m=================================
</span><span id="__span-108-8"><a id="__codelineno-108-8" name="__codelineno-108-8" href="#__codelineno-108-8"></a>
</span><span id="__span-108-9"><a id="__codelineno-108-9" name="__codelineno-108-9" href="#__codelineno-108-9"></a>what&#39;s my name?
</span><span id="__span-108-10"><a id="__codelineno-108-10" name="__codelineno-108-10" href="#__codelineno-108-10"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-108-11"><a id="__codelineno-108-11" name="__codelineno-108-11" href="#__codelineno-108-11"></a>
</span><span id="__span-108-12"><a id="__codelineno-108-12" name="__codelineno-108-12" href="#__codelineno-108-12"></a>I apologize, but I don&#39;t have access to your personal information, including your name. I&#39;m an AI language model designed to provide general information and answer questions to the best of my ability based on my training data. I don&#39;t have any information about individual users or their personal details. If you&#39;d like to share your name, you&#39;re welcome to do so, but I won&#39;t be able to recall it in future conversations.
</span></code></pre></div>
<h2 id="add-persistence">Add persistence<a class="headerlink" href="#add-persistence" title="Permanent link">#</a></h2>
<p>To add in persistence, we need to pass in a Checkpointer when compiling the graph.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-109-1"><a id="__codelineno-109-1" name="__codelineno-109-1" href="#__codelineno-109-1"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-109-2"><a id="__codelineno-109-2" name="__codelineno-109-2" href="#__codelineno-109-2"></a>
</span><span id="__span-109-3"><a id="__codelineno-109-3" name="__codelineno-109-3" href="#__codelineno-109-3"></a>memory = MemorySaver()
</span><span id="__span-109-4"><a id="__codelineno-109-4" name="__codelineno-109-4" href="#__codelineno-109-4"></a>graph = builder.compile(checkpointer=memory)
</span><span id="__span-109-5"><a id="__codelineno-109-5" name="__codelineno-109-5" href="#__codelineno-109-5"></a># If you&#39;re using LangGraph Cloud or LangGraph Studio, you don&#39;t need to pass the checkpointer when compiling the graph, since it&#39;s done automatically.
</span></code></pre></div>
<p>We can now interact with the agent and see that it remembers previous messages!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-110-1"><a id="__codelineno-110-1" name="__codelineno-110-1" href="#__codelineno-110-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;}}
</span><span id="__span-110-2"><a id="__codelineno-110-2" name="__codelineno-110-2" href="#__codelineno-110-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi! I&#39;m bob&quot;}
</span><span id="__span-110-3"><a id="__codelineno-110-3" name="__codelineno-110-3" href="#__codelineno-110-3"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-110-4"><a id="__codelineno-110-4" name="__codelineno-110-4" href="#__codelineno-110-4"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<p>You can always resume previous threads:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-111-1"><a id="__codelineno-111-1" name="__codelineno-111-1" href="#__codelineno-111-1"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#39;s my name?&quot;}
</span><span id="__span-111-2"><a id="__codelineno-111-2" name="__codelineno-111-2" href="#__codelineno-111-2"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-111-3"><a id="__codelineno-111-3" name="__codelineno-111-3" href="#__codelineno-111-3"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-112-1"><a id="__codelineno-112-1" name="__codelineno-112-1" href="#__codelineno-112-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-112-2"><a id="__codelineno-112-2" name="__codelineno-112-2" href="#__codelineno-112-2"></a>
</span><span id="__span-112-3"><a id="__codelineno-112-3" name="__codelineno-112-3" href="#__codelineno-112-3"></a>what&#39;s my name?
</span><span id="__span-112-4"><a id="__codelineno-112-4" name="__codelineno-112-4" href="#__codelineno-112-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-112-5"><a id="__codelineno-112-5" name="__codelineno-112-5" href="#__codelineno-112-5"></a>
</span><span id="__span-112-6"><a id="__codelineno-112-6" name="__codelineno-112-6" href="#__codelineno-112-6"></a>Your name is Bob, as you introduced yourself at the beginning of our conversation.
</span></code></pre></div>
<p>If we want to start a new conversation, we can pass in a different thread_id. Poof! All the memories are gone!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-113-1"><a id="__codelineno-113-1" name="__codelineno-113-1" href="#__codelineno-113-1"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#39;s my name?&quot;}
</span><span id="__span-113-2"><a id="__codelineno-113-2" name="__codelineno-113-2" href="#__codelineno-113-2"></a>for chunk in graph.stream(
</span><span id="__span-113-3"><a id="__codelineno-113-3" name="__codelineno-113-3" href="#__codelineno-113-3"></a>    {&quot;messages&quot;: [input_message]},
</span><span id="__span-113-4"><a id="__codelineno-113-4" name="__codelineno-113-4" href="#__codelineno-113-4"></a>    {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}},
</span><span id="__span-113-5"><a id="__codelineno-113-5" name="__codelineno-113-5" href="#__codelineno-113-5"></a>    stream_mode=&quot;values&quot;,
</span><span id="__span-113-6"><a id="__codelineno-113-6" name="__codelineno-113-6" href="#__codelineno-113-6"></a>):
</span><span id="__span-113-7"><a id="__codelineno-113-7" name="__codelineno-113-7" href="#__codelineno-113-7"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-114-1"><a id="__codelineno-114-1" name="__codelineno-114-1" href="#__codelineno-114-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-114-2"><a id="__codelineno-114-2" name="__codelineno-114-2" href="#__codelineno-114-2"></a>
</span><span id="__span-114-3"><a id="__codelineno-114-3" name="__codelineno-114-3" href="#__codelineno-114-3"></a>what&#39;s is my name?
</span><span id="__span-114-4"><a id="__codelineno-114-4" name="__codelineno-114-4" href="#__codelineno-114-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-114-5"><a id="__codelineno-114-5" name="__codelineno-114-5" href="#__codelineno-114-5"></a>
</span><span id="__span-114-6"><a id="__codelineno-114-6" name="__codelineno-114-6" href="#__codelineno-114-6"></a>I apologize, but I don&#39;t have access to your personal information, including your name. As an AI language model, I don&#39;t have any information about individual users unless it&#39;s provided within the conversation. If you&#39;d like to share your name, you&#39;re welcome to do so, but otherwise, I won&#39;t be able to know or guess it.
</span></code></pre></div>
<h2 id="how-to-add-thread-level-persistence-to-a-subgraph">How to add thread-level persistence to a subgraph<a class="headerlink" href="#how-to-add-thread-level-persistence-to-a-subgraph" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-115-1"><a id="__codelineno-115-1" name="__codelineno-115-1" href="#__codelineno-115-1"></a>%%capture --no-stderr
</span><span id="__span-115-2"><a id="__codelineno-115-2" name="__codelineno-115-2" href="#__codelineno-115-2"></a>%pip install -U langgraph
</span></code></pre></div>
<h2 id="define-the-graph-with-persistence">Define the graph with persistence<a class="headerlink" href="#define-the-graph-with-persistence" title="Permanent link">#</a></h2>
<p>To add persistence to a graph with subgraphs, all you need to do is pass a checkpointer when compiling the parent graph. LangGraph will automatically propagate the checkpointer to the child subgraphs.</p>
<p><strong>Note:</strong> You shouldn't provide a checkpointer when compiling a subgraph. Instead, you must define a single checkpointer that you pass to parent_graph.compile(), and LangGraph will automatically propagate the checkpointer to the child subgraphs. If you pass the checkpointer to the subgraph.compile(), it will simply be ignored. This also applies when you add a node function that invokes the subgraph.</p>
<p>Let's define a simple graph with a single subgraph node to show how to do this.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-116-1"><a id="__codelineno-116-1" name="__codelineno-116-1" href="#__codelineno-116-1"></a>from langgraph.graph import START, StateGraph
</span><span id="__span-116-2"><a id="__codelineno-116-2" name="__codelineno-116-2" href="#__codelineno-116-2"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-116-3"><a id="__codelineno-116-3" name="__codelineno-116-3" href="#__codelineno-116-3"></a>from typing import TypedDict
</span><span id="__span-116-4"><a id="__codelineno-116-4" name="__codelineno-116-4" href="#__codelineno-116-4"></a>
</span><span id="__span-116-5"><a id="__codelineno-116-5" name="__codelineno-116-5" href="#__codelineno-116-5"></a>
</span><span id="__span-116-6"><a id="__codelineno-116-6" name="__codelineno-116-6" href="#__codelineno-116-6"></a># subgraph
</span><span id="__span-116-7"><a id="__codelineno-116-7" name="__codelineno-116-7" href="#__codelineno-116-7"></a>
</span><span id="__span-116-8"><a id="__codelineno-116-8" name="__codelineno-116-8" href="#__codelineno-116-8"></a>
</span><span id="__span-116-9"><a id="__codelineno-116-9" name="__codelineno-116-9" href="#__codelineno-116-9"></a>class SubgraphState(TypedDict):
</span><span id="__span-116-10"><a id="__codelineno-116-10" name="__codelineno-116-10" href="#__codelineno-116-10"></a>    foo: str  # note that this key is shared with the parent graph state
</span><span id="__span-116-11"><a id="__codelineno-116-11" name="__codelineno-116-11" href="#__codelineno-116-11"></a>    bar: str
</span><span id="__span-116-12"><a id="__codelineno-116-12" name="__codelineno-116-12" href="#__codelineno-116-12"></a>
</span><span id="__span-116-13"><a id="__codelineno-116-13" name="__codelineno-116-13" href="#__codelineno-116-13"></a>
</span><span id="__span-116-14"><a id="__codelineno-116-14" name="__codelineno-116-14" href="#__codelineno-116-14"></a>def subgraph_node_1(state: SubgraphState):
</span><span id="__span-116-15"><a id="__codelineno-116-15" name="__codelineno-116-15" href="#__codelineno-116-15"></a>    return {&quot;bar&quot;: &quot;bar&quot;}
</span><span id="__span-116-16"><a id="__codelineno-116-16" name="__codelineno-116-16" href="#__codelineno-116-16"></a>
</span><span id="__span-116-17"><a id="__codelineno-116-17" name="__codelineno-116-17" href="#__codelineno-116-17"></a>
</span><span id="__span-116-18"><a id="__codelineno-116-18" name="__codelineno-116-18" href="#__codelineno-116-18"></a>def subgraph_node_2(state: SubgraphState):
</span><span id="__span-116-19"><a id="__codelineno-116-19" name="__codelineno-116-19" href="#__codelineno-116-19"></a>    # note that this node is using a state key (&#39;bar&#39;) that is only available in the subgraph
</span><span id="__span-116-20"><a id="__codelineno-116-20" name="__codelineno-116-20" href="#__codelineno-116-20"></a>    # and is sending update on the shared state key (&#39;foo&#39;)
</span><span id="__span-116-21"><a id="__codelineno-116-21" name="__codelineno-116-21" href="#__codelineno-116-21"></a>    return {&quot;foo&quot;: state[&quot;foo&quot;] + state[&quot;bar&quot;]}
</span><span id="__span-116-22"><a id="__codelineno-116-22" name="__codelineno-116-22" href="#__codelineno-116-22"></a>
</span><span id="__span-116-23"><a id="__codelineno-116-23" name="__codelineno-116-23" href="#__codelineno-116-23"></a>
</span><span id="__span-116-24"><a id="__codelineno-116-24" name="__codelineno-116-24" href="#__codelineno-116-24"></a>subgraph_builder = StateGraph(SubgraphState)
</span><span id="__span-116-25"><a id="__codelineno-116-25" name="__codelineno-116-25" href="#__codelineno-116-25"></a>subgraph_builder.add_node(subgraph_node_1)
</span><span id="__span-116-26"><a id="__codelineno-116-26" name="__codelineno-116-26" href="#__codelineno-116-26"></a>subgraph_builder.add_node(subgraph_node_2)
</span><span id="__span-116-27"><a id="__codelineno-116-27" name="__codelineno-116-27" href="#__codelineno-116-27"></a>subgraph_builder.add_edge(START, &quot;subgraph_node_1&quot;)
</span><span id="__span-116-28"><a id="__codelineno-116-28" name="__codelineno-116-28" href="#__codelineno-116-28"></a>subgraph_builder.add_edge(&quot;subgraph_node_1&quot;, &quot;subgraph_node_2&quot;)
</span><span id="__span-116-29"><a id="__codelineno-116-29" name="__codelineno-116-29" href="#__codelineno-116-29"></a>subgraph = subgraph_builder.compile()
</span><span id="__span-116-30"><a id="__codelineno-116-30" name="__codelineno-116-30" href="#__codelineno-116-30"></a>
</span><span id="__span-116-31"><a id="__codelineno-116-31" name="__codelineno-116-31" href="#__codelineno-116-31"></a>
</span><span id="__span-116-32"><a id="__codelineno-116-32" name="__codelineno-116-32" href="#__codelineno-116-32"></a># parent graph
</span><span id="__span-116-33"><a id="__codelineno-116-33" name="__codelineno-116-33" href="#__codelineno-116-33"></a>
</span><span id="__span-116-34"><a id="__codelineno-116-34" name="__codelineno-116-34" href="#__codelineno-116-34"></a>
</span><span id="__span-116-35"><a id="__codelineno-116-35" name="__codelineno-116-35" href="#__codelineno-116-35"></a>class State(TypedDict):
</span><span id="__span-116-36"><a id="__codelineno-116-36" name="__codelineno-116-36" href="#__codelineno-116-36"></a>    foo: str
</span><span id="__span-116-37"><a id="__codelineno-116-37" name="__codelineno-116-37" href="#__codelineno-116-37"></a>
</span><span id="__span-116-38"><a id="__codelineno-116-38" name="__codelineno-116-38" href="#__codelineno-116-38"></a>
</span><span id="__span-116-39"><a id="__codelineno-116-39" name="__codelineno-116-39" href="#__codelineno-116-39"></a>def node_1(state: State):
</span><span id="__span-116-40"><a id="__codelineno-116-40" name="__codelineno-116-40" href="#__codelineno-116-40"></a>    return {&quot;foo&quot;: &quot;hi! &quot; + state[&quot;foo&quot;]}
</span><span id="__span-116-41"><a id="__codelineno-116-41" name="__codelineno-116-41" href="#__codelineno-116-41"></a>
</span><span id="__span-116-42"><a id="__codelineno-116-42" name="__codelineno-116-42" href="#__codelineno-116-42"></a>
</span><span id="__span-116-43"><a id="__codelineno-116-43" name="__codelineno-116-43" href="#__codelineno-116-43"></a>builder = StateGraph(State)
</span><span id="__span-116-44"><a id="__codelineno-116-44" name="__codelineno-116-44" href="#__codelineno-116-44"></a>builder.add_node(&quot;node_1&quot;, node_1)
</span><span id="__span-116-45"><a id="__codelineno-116-45" name="__codelineno-116-45" href="#__codelineno-116-45"></a># note that we&#39;re adding the compiled subgraph as a node to the parent graph
</span><span id="__span-116-46"><a id="__codelineno-116-46" name="__codelineno-116-46" href="#__codelineno-116-46"></a>builder.add_node(&quot;node_2&quot;, subgraph)
</span><span id="__span-116-47"><a id="__codelineno-116-47" name="__codelineno-116-47" href="#__codelineno-116-47"></a>builder.add_edge(START, &quot;node_1&quot;)
</span><span id="__span-116-48"><a id="__codelineno-116-48" name="__codelineno-116-48" href="#__codelineno-116-48"></a>builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)
</span></code></pre></div>
<p>We can now compile the graph with an in-memory checkpointer (MemorySaver).</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-117-1"><a id="__codelineno-117-1" name="__codelineno-117-1" href="#__codelineno-117-1"></a>checkpointer = MemorySaver()
</span><span id="__span-117-2"><a id="__codelineno-117-2" name="__codelineno-117-2" href="#__codelineno-117-2"></a># You must only pass checkpointer when compiling the parent graph.
</span><span id="__span-117-3"><a id="__codelineno-117-3" name="__codelineno-117-3" href="#__codelineno-117-3"></a># LangGraph will automatically propagate the checkpointer to the child subgraphs.
</span><span id="__span-117-4"><a id="__codelineno-117-4" name="__codelineno-117-4" href="#__codelineno-117-4"></a>graph = builder.compile(checkpointer=checkpointer)
</span></code></pre></div>
<h2 id="verify-persistence-works">Verify persistence works<a class="headerlink" href="#verify-persistence-works" title="Permanent link">#</a></h2>
<p>Let's now run the graph and inspect the persisted state for both the parent graph and the subgraph to verify that persistence works. We should expect to see the final execution results for both the parent and subgraph in state.values.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-118-1"><a id="__codelineno-118-1" name="__codelineno-118-1" href="#__codelineno-118-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;}}
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-119-1"><a id="__codelineno-119-1" name="__codelineno-119-1" href="#__codelineno-119-1"></a>for _, chunk in graph.stream({&quot;foo&quot;: &quot;foo&quot;}, config, subgraphs=True):
</span><span id="__span-119-2"><a id="__codelineno-119-2" name="__codelineno-119-2" href="#__codelineno-119-2"></a>    print(chunk)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-120-1"><a id="__codelineno-120-1" name="__codelineno-120-1" href="#__codelineno-120-1"></a>{&#39;node_1&#39;: {&#39;foo&#39;: &#39;hi! foo&#39;}}
</span><span id="__span-120-2"><a id="__codelineno-120-2" name="__codelineno-120-2" href="#__codelineno-120-2"></a>{&#39;subgraph_node_1&#39;: {&#39;bar&#39;: &#39;bar&#39;}}
</span><span id="__span-120-3"><a id="__codelineno-120-3" name="__codelineno-120-3" href="#__codelineno-120-3"></a>{&#39;subgraph_node_2&#39;: {&#39;foo&#39;: &#39;hi! foobar&#39;}}
</span><span id="__span-120-4"><a id="__codelineno-120-4" name="__codelineno-120-4" href="#__codelineno-120-4"></a>{&#39;node_2&#39;: {&#39;foo&#39;: &#39;hi! foobar&#39;}}
</span></code></pre></div>
<p>We can now view the parent graph state by calling graph.get_state() with the same config that we used to invoke the graph.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-121-1"><a id="__codelineno-121-1" name="__codelineno-121-1" href="#__codelineno-121-1"></a>graph.get_state(config).values
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-122-1"><a id="__codelineno-122-1" name="__codelineno-122-1" href="#__codelineno-122-1"></a>{&#39;foo&#39;: &#39;hi! foobar&#39;}
</span></code></pre></div>
<p>To view the subgraph state, we need to do two things:</p>
<ol>
<li>Find the most recent config value for the subgraph</li>
<li>Use graph.get_state() to retrieve that value for the most recent subgraph config.</li>
</ol>
<p>To find the correct config, we can examine the state history from the parent graph and find the state snapshot before we return results from node_2 (the node with subgraph):</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-123-1"><a id="__codelineno-123-1" name="__codelineno-123-1" href="#__codelineno-123-1"></a>state_with_subgraph = [
</span><span id="__span-123-2"><a id="__codelineno-123-2" name="__codelineno-123-2" href="#__codelineno-123-2"></a>    s for s in graph.get_state_history(config) if s.next == (&quot;node_2&quot;,)
</span><span id="__span-123-3"><a id="__codelineno-123-3" name="__codelineno-123-3" href="#__codelineno-123-3"></a>][0]
</span></code></pre></div>
<p>The state snapshot will include the list of tasks to be executed next. When using subgraphs, the tasks will contain the config that we can use to retrieve the subgraph state:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-124-1"><a id="__codelineno-124-1" name="__codelineno-124-1" href="#__codelineno-124-1"></a>subgraph_config = state_with_subgraph.tasks[0].state
</span><span id="__span-124-2"><a id="__codelineno-124-2" name="__codelineno-124-2" href="#__codelineno-124-2"></a>subgraph_config
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-125-1"><a id="__codelineno-125-1" name="__codelineno-125-1" href="#__codelineno-125-1"></a>{&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;1&#39;,
</span><span id="__span-125-2"><a id="__codelineno-125-2" name="__codelineno-125-2" href="#__codelineno-125-2"></a>  &#39;checkpoint_ns&#39;: &#39;node_2:6ef111a6-f290-7376-0dfc-a4152307bc5b&#39;}}
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-126-1"><a id="__codelineno-126-1" name="__codelineno-126-1" href="#__codelineno-126-1"></a>graph.get_state(subgraph_config).values
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-127-1"><a id="__codelineno-127-1" name="__codelineno-127-1" href="#__codelineno-127-1"></a>{&#39;foo&#39;: &#39;hi! foobar&#39;, &#39;bar&#39;: &#39;bar&#39;}
</span></code></pre></div>
<h2 id="how-to-add-cross-thread-persistence-to-your-graph">How to add cross-thread persistence to your graph<a class="headerlink" href="#how-to-add-cross-thread-persistence-to-your-graph" title="Permanent link">#</a></h2>
<p>In the previous guide you learned how to persist graph state across multiple interactions on a single thread. LangGraph also allows you to persist data across multiple threads. For instance, you can store information about users (their names or preferences) in a shared memory and reuse them in the new conversational threads.</p>
<p>In this guide, we will show how to construct and use a graph that has a shared memory implemented using the Store interface.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-128-1"><a id="__codelineno-128-1" name="__codelineno-128-1" href="#__codelineno-128-1"></a>%%capture --no-stderr
</span><span id="__span-128-2"><a id="__codelineno-128-2" name="__codelineno-128-2" href="#__codelineno-128-2"></a>%pip install -U langchain_openai langgraph
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-129-1"><a id="__codelineno-129-1" name="__codelineno-129-1" href="#__codelineno-129-1"></a>import getpass
</span><span id="__span-129-2"><a id="__codelineno-129-2" name="__codelineno-129-2" href="#__codelineno-129-2"></a>import os
</span><span id="__span-129-3"><a id="__codelineno-129-3" name="__codelineno-129-3" href="#__codelineno-129-3"></a>
</span><span id="__span-129-4"><a id="__codelineno-129-4" name="__codelineno-129-4" href="#__codelineno-129-4"></a>
</span><span id="__span-129-5"><a id="__codelineno-129-5" name="__codelineno-129-5" href="#__codelineno-129-5"></a>def _set_env(var: str):
</span><span id="__span-129-6"><a id="__codelineno-129-6" name="__codelineno-129-6" href="#__codelineno-129-6"></a>    if not os.environ.get(var):
</span><span id="__span-129-7"><a id="__codelineno-129-7" name="__codelineno-129-7" href="#__codelineno-129-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-129-8"><a id="__codelineno-129-8" name="__codelineno-129-8" href="#__codelineno-129-8"></a>
</span><span id="__span-129-9"><a id="__codelineno-129-9" name="__codelineno-129-9" href="#__codelineno-129-9"></a>
</span><span id="__span-129-10"><a id="__codelineno-129-10" name="__codelineno-129-10" href="#__codelineno-129-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span><span id="__span-129-11"><a id="__codelineno-129-11" name="__codelineno-129-11" href="#__codelineno-129-11"></a>_set_env(&quot;OPENAI_API_KEY&quot;)
</span></code></pre></div>
<h2 id="define-store">Define store<a class="headerlink" href="#define-store" title="Permanent link">#</a></h2>
<p>In this example we will create a graph that will be able to retrieve information about a user's preferences. We will do so by defining an InMemoryStore - an object that can store data in memory and query that data. We will then pass the store object when compiling the graph. This allows each node in the graph to access the store: when you define node functions, you can define store keyword argument, and LangGraph will automatically pass the store object you compiled the graph with.</p>
<p>When storing objects using the Store interface you define two things:</p>
<ul>
<li>the namespace for the object, a tuple (similar to directories)</li>
<li>the object key (similar to filenames)</li>
</ul>
<p>In our example, we'll be using ("memories", <user_id>) as namespace and random UUID as key for each new memory.</p>
<p>Importantly, to determine the user, we will be passing user_id via the config keyword argument of the node function.</p>
<p>Let's first define an InMemoryStore already populated with some memories about the users.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-130-1"><a id="__codelineno-130-1" name="__codelineno-130-1" href="#__codelineno-130-1"></a>from langgraph.store.memory import InMemoryStore
</span><span id="__span-130-2"><a id="__codelineno-130-2" name="__codelineno-130-2" href="#__codelineno-130-2"></a>from langchain_openai import OpenAIEmbeddings
</span><span id="__span-130-3"><a id="__codelineno-130-3" name="__codelineno-130-3" href="#__codelineno-130-3"></a>
</span><span id="__span-130-4"><a id="__codelineno-130-4" name="__codelineno-130-4" href="#__codelineno-130-4"></a>in_memory_store = InMemoryStore(
</span><span id="__span-130-5"><a id="__codelineno-130-5" name="__codelineno-130-5" href="#__codelineno-130-5"></a>    index={
</span><span id="__span-130-6"><a id="__codelineno-130-6" name="__codelineno-130-6" href="#__codelineno-130-6"></a>        &quot;embed&quot;: OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;),
</span><span id="__span-130-7"><a id="__codelineno-130-7" name="__codelineno-130-7" href="#__codelineno-130-7"></a>        &quot;dims&quot;: 1536,
</span><span id="__span-130-8"><a id="__codelineno-130-8" name="__codelineno-130-8" href="#__codelineno-130-8"></a>    }
</span><span id="__span-130-9"><a id="__codelineno-130-9" name="__codelineno-130-9" href="#__codelineno-130-9"></a>)
</span></code></pre></div>
<h2 id="create-graph">Create graph<a class="headerlink" href="#create-graph" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-131-1"><a id="__codelineno-131-1" name="__codelineno-131-1" href="#__codelineno-131-1"></a>import uuid
</span><span id="__span-131-2"><a id="__codelineno-131-2" name="__codelineno-131-2" href="#__codelineno-131-2"></a>from typing import Annotated
</span><span id="__span-131-3"><a id="__codelineno-131-3" name="__codelineno-131-3" href="#__codelineno-131-3"></a>from typing_extensions import TypedDict
</span><span id="__span-131-4"><a id="__codelineno-131-4" name="__codelineno-131-4" href="#__codelineno-131-4"></a>
</span><span id="__span-131-5"><a id="__codelineno-131-5" name="__codelineno-131-5" href="#__codelineno-131-5"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-131-6"><a id="__codelineno-131-6" name="__codelineno-131-6" href="#__codelineno-131-6"></a>from langchain_core.runnables import RunnableConfig
</span><span id="__span-131-7"><a id="__codelineno-131-7" name="__codelineno-131-7" href="#__codelineno-131-7"></a>from langgraph.graph import StateGraph, MessagesState, START
</span><span id="__span-131-8"><a id="__codelineno-131-8" name="__codelineno-131-8" href="#__codelineno-131-8"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-131-9"><a id="__codelineno-131-9" name="__codelineno-131-9" href="#__codelineno-131-9"></a>from langgraph.store.base import BaseStore
</span><span id="__span-131-10"><a id="__codelineno-131-10" name="__codelineno-131-10" href="#__codelineno-131-10"></a>
</span><span id="__span-131-11"><a id="__codelineno-131-11" name="__codelineno-131-11" href="#__codelineno-131-11"></a>
</span><span id="__span-131-12"><a id="__codelineno-131-12" name="__codelineno-131-12" href="#__codelineno-131-12"></a>model = ChatAnthropic(model=&quot;claude-3-5-sonnet-20240620&quot;)
</span><span id="__span-131-13"><a id="__codelineno-131-13" name="__codelineno-131-13" href="#__codelineno-131-13"></a>
</span><span id="__span-131-14"><a id="__codelineno-131-14" name="__codelineno-131-14" href="#__codelineno-131-14"></a>
</span><span id="__span-131-15"><a id="__codelineno-131-15" name="__codelineno-131-15" href="#__codelineno-131-15"></a># NOTE: we&#39;re passing the Store param to the node --
</span><span id="__span-131-16"><a id="__codelineno-131-16" name="__codelineno-131-16" href="#__codelineno-131-16"></a># this is the Store we compile the graph with
</span><span id="__span-131-17"><a id="__codelineno-131-17" name="__codelineno-131-17" href="#__codelineno-131-17"></a>def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):
</span><span id="__span-131-18"><a id="__codelineno-131-18" name="__codelineno-131-18" href="#__codelineno-131-18"></a>    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]
</span><span id="__span-131-19"><a id="__codelineno-131-19" name="__codelineno-131-19" href="#__codelineno-131-19"></a>    namespace = (&quot;memories&quot;, user_id)
</span><span id="__span-131-20"><a id="__codelineno-131-20" name="__codelineno-131-20" href="#__codelineno-131-20"></a>    memories = store.search(namespace, query=str(state[&quot;messages&quot;][-1].content))
</span><span id="__span-131-21"><a id="__codelineno-131-21" name="__codelineno-131-21" href="#__codelineno-131-21"></a>    info = &quot;\n&quot;.join([d.value[&quot;data&quot;] for d in memories])
</span><span id="__span-131-22"><a id="__codelineno-131-22" name="__codelineno-131-22" href="#__codelineno-131-22"></a>    system_msg = f&quot;You are a helpful assistant talking to the user. User info: {info}&quot;
</span><span id="__span-131-23"><a id="__codelineno-131-23" name="__codelineno-131-23" href="#__codelineno-131-23"></a>
</span><span id="__span-131-24"><a id="__codelineno-131-24" name="__codelineno-131-24" href="#__codelineno-131-24"></a>    # Store new memories if the user asks the model to remember
</span><span id="__span-131-25"><a id="__codelineno-131-25" name="__codelineno-131-25" href="#__codelineno-131-25"></a>    last_message = state[&quot;messages&quot;][-1]
</span><span id="__span-131-26"><a id="__codelineno-131-26" name="__codelineno-131-26" href="#__codelineno-131-26"></a>    if &quot;remember&quot; in last_message.content.lower():
</span><span id="__span-131-27"><a id="__codelineno-131-27" name="__codelineno-131-27" href="#__codelineno-131-27"></a>        memory = &quot;User name is Bob&quot;
</span><span id="__span-131-28"><a id="__codelineno-131-28" name="__codelineno-131-28" href="#__codelineno-131-28"></a>        store.put(namespace, str(uuid.uuid4()), {&quot;data&quot;: memory})
</span><span id="__span-131-29"><a id="__codelineno-131-29" name="__codelineno-131-29" href="#__codelineno-131-29"></a>
</span><span id="__span-131-30"><a id="__codelineno-131-30" name="__codelineno-131-30" href="#__codelineno-131-30"></a>    response = model.invoke(
</span><span id="__span-131-31"><a id="__codelineno-131-31" name="__codelineno-131-31" href="#__codelineno-131-31"></a>        [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_msg}] + state[&quot;messages&quot;]
</span><span id="__span-131-32"><a id="__codelineno-131-32" name="__codelineno-131-32" href="#__codelineno-131-32"></a>    )
</span><span id="__span-131-33"><a id="__codelineno-131-33" name="__codelineno-131-33" href="#__codelineno-131-33"></a>    return {&quot;messages&quot;: response}
</span><span id="__span-131-34"><a id="__codelineno-131-34" name="__codelineno-131-34" href="#__codelineno-131-34"></a>
</span><span id="__span-131-35"><a id="__codelineno-131-35" name="__codelineno-131-35" href="#__codelineno-131-35"></a>
</span><span id="__span-131-36"><a id="__codelineno-131-36" name="__codelineno-131-36" href="#__codelineno-131-36"></a>builder = StateGraph(MessagesState)
</span><span id="__span-131-37"><a id="__codelineno-131-37" name="__codelineno-131-37" href="#__codelineno-131-37"></a>builder.add_node(&quot;call_model&quot;, call_model)
</span><span id="__span-131-38"><a id="__codelineno-131-38" name="__codelineno-131-38" href="#__codelineno-131-38"></a>builder.add_edge(START, &quot;call_model&quot;)
</span><span id="__span-131-39"><a id="__codelineno-131-39" name="__codelineno-131-39" href="#__codelineno-131-39"></a>
</span><span id="__span-131-40"><a id="__codelineno-131-40" name="__codelineno-131-40" href="#__codelineno-131-40"></a># NOTE: we&#39;re passing the store object here when compiling the graph
</span><span id="__span-131-41"><a id="__codelineno-131-41" name="__codelineno-131-41" href="#__codelineno-131-41"></a>graph = builder.compile(checkpointer=MemorySaver(), store=in_memory_store)
</span><span id="__span-131-42"><a id="__codelineno-131-42" name="__codelineno-131-42" href="#__codelineno-131-42"></a># If you&#39;re using LangGraph Cloud or LangGraph Studio, you don&#39;t need to pass the store or checkpointer when compiling the graph, since it&#39;s done automatically.
</span></code></pre></div>
<h2 id="run-the-graph">Run the graph!<a class="headerlink" href="#run-the-graph" title="Permanent link">#</a></h2>
<p>Now let's specify a user ID in the config and tell the model our name:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-132-1"><a id="__codelineno-132-1" name="__codelineno-132-1" href="#__codelineno-132-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;}}
</span><span id="__span-132-2"><a id="__codelineno-132-2" name="__codelineno-132-2" href="#__codelineno-132-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi! Remember: my name is Bob&quot;}
</span><span id="__span-132-3"><a id="__codelineno-132-3" name="__codelineno-132-3" href="#__codelineno-132-3"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-132-4"><a id="__codelineno-132-4" name="__codelineno-132-4" href="#__codelineno-132-4"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-133-1"><a id="__codelineno-133-1" name="__codelineno-133-1" href="#__codelineno-133-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-133-2"><a id="__codelineno-133-2" name="__codelineno-133-2" href="#__codelineno-133-2"></a>
</span><span id="__span-133-3"><a id="__codelineno-133-3" name="__codelineno-133-3" href="#__codelineno-133-3"></a>Hi! Remember: my name is Bob
</span><span id="__span-133-4"><a id="__codelineno-133-4" name="__codelineno-133-4" href="#__codelineno-133-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-133-5"><a id="__codelineno-133-5" name="__codelineno-133-5" href="#__codelineno-133-5"></a>
</span><span id="__span-133-6"><a id="__codelineno-133-6" name="__codelineno-133-6" href="#__codelineno-133-6"></a>Hello Bob! It&#39;s nice to meet you. I&#39;ll remember that your name is Bob. How can I assist you today?
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-134-1"><a id="__codelineno-134-1" name="__codelineno-134-1" href="#__codelineno-134-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;}}
</span><span id="__span-134-2"><a id="__codelineno-134-2" name="__codelineno-134-2" href="#__codelineno-134-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is my name?&quot;}
</span><span id="__span-134-3"><a id="__codelineno-134-3" name="__codelineno-134-3" href="#__codelineno-134-3"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-134-4"><a id="__codelineno-134-4" name="__codelineno-134-4" href="#__codelineno-134-4"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-135-1"><a id="__codelineno-135-1" name="__codelineno-135-1" href="#__codelineno-135-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-135-2"><a id="__codelineno-135-2" name="__codelineno-135-2" href="#__codelineno-135-2"></a>
</span><span id="__span-135-3"><a id="__codelineno-135-3" name="__codelineno-135-3" href="#__codelineno-135-3"></a>what is my name?
</span><span id="__span-135-4"><a id="__codelineno-135-4" name="__codelineno-135-4" href="#__codelineno-135-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-135-5"><a id="__codelineno-135-5" name="__codelineno-135-5" href="#__codelineno-135-5"></a>
</span><span id="__span-135-6"><a id="__codelineno-135-6" name="__codelineno-135-6" href="#__codelineno-135-6"></a>Your name is Bob.
</span></code></pre></div>
<p>We can now inspect our in-memory store and verify that we have in fact saved the memories for the user:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-136-1"><a id="__codelineno-136-1" name="__codelineno-136-1" href="#__codelineno-136-1"></a>for memory in in_memory_store.search((&quot;memories&quot;, &quot;1&quot;)):
</span><span id="__span-136-2"><a id="__codelineno-136-2" name="__codelineno-136-2" href="#__codelineno-136-2"></a>    print(memory.value)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-137-1"><a id="__codelineno-137-1" name="__codelineno-137-1" href="#__codelineno-137-1"></a>{&#39;data&#39;: &#39;User name is Bob&#39;}
</span></code></pre></div>
<p>Let's now run the graph for another user to verify that the memories about the first user are self contained:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-138-1"><a id="__codelineno-138-1" name="__codelineno-138-1" href="#__codelineno-138-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;3&quot;, &quot;user_id&quot;: &quot;2&quot;}}
</span><span id="__span-138-2"><a id="__codelineno-138-2" name="__codelineno-138-2" href="#__codelineno-138-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is my name?&quot;}
</span><span id="__span-138-3"><a id="__codelineno-138-3" name="__codelineno-138-3" href="#__codelineno-138-3"></a>for chunk in graph.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-138-4"><a id="__codelineno-138-4" name="__codelineno-138-4" href="#__codelineno-138-4"></a>    chunk[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-139-1"><a id="__codelineno-139-1" name="__codelineno-139-1" href="#__codelineno-139-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-139-2"><a id="__codelineno-139-2" name="__codelineno-139-2" href="#__codelineno-139-2"></a>
</span><span id="__span-139-3"><a id="__codelineno-139-3" name="__codelineno-139-3" href="#__codelineno-139-3"></a>what is my name?
</span><span id="__span-139-4"><a id="__codelineno-139-4" name="__codelineno-139-4" href="#__codelineno-139-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-139-5"><a id="__codelineno-139-5" name="__codelineno-139-5" href="#__codelineno-139-5"></a>
</span><span id="__span-139-6"><a id="__codelineno-139-6" name="__codelineno-139-6" href="#__codelineno-139-6"></a>I apologize, but I don&#39;t have any information about your name. As an AI assistant, I don&#39;t have access to personal information about users unless it has been specifically shared in our conversation. If you&#39;d like, you can tell me your name and I&#39;ll be happy to use it in our discussion.
</span></code></pre></div>
<h1 id="how-to-use-postgres-checkpointer-for-persistence">How to use Postgres checkpointer for persistence<a class="headerlink" href="#how-to-use-postgres-checkpointer-for-persistence" title="Permanent link">#</a></h1>
<p>When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions.</p>
<p>This how-to guide shows how to use Postgres as the backend for persisting checkpoint state using the <strong>langgraph-checkpoint-postgres</strong> library.</p>
<p>For demonstration purposes we add persistence to the pre-built create react agent.</p>
<p>In general, you can add a checkpointer to any custom graph that you build like this:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-140-1"><a id="__codelineno-140-1" name="__codelineno-140-1" href="#__codelineno-140-1"></a>from langgraph.graph import StateGraph
</span><span id="__span-140-2"><a id="__codelineno-140-2" name="__codelineno-140-2" href="#__codelineno-140-2"></a>
</span><span id="__span-140-3"><a id="__codelineno-140-3" name="__codelineno-140-3" href="#__codelineno-140-3"></a>builder = StateGraph(....)
</span><span id="__span-140-4"><a id="__codelineno-140-4" name="__codelineno-140-4" href="#__codelineno-140-4"></a># ... define the graph
</span><span id="__span-140-5"><a id="__codelineno-140-5" name="__codelineno-140-5" href="#__codelineno-140-5"></a>checkpointer = # postgres checkpointer (see examples below)
</span><span id="__span-140-6"><a id="__codelineno-140-6" name="__codelineno-140-6" href="#__codelineno-140-6"></a>graph = builder.compile(checkpointer=checkpointer)
</span><span id="__span-140-7"><a id="__codelineno-140-7" name="__codelineno-140-7" href="#__codelineno-140-7"></a>...
</span></code></pre></div>
<h2 id="setup_1">Setup<a class="headerlink" href="#setup_1" title="Permanent link">#</a></h2>
<p>You will need access to a postgres instance. 
Next, let's install the required packages and set our API keys</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-141-1"><a id="__codelineno-141-1" name="__codelineno-141-1" href="#__codelineno-141-1"></a>%%capture --no-stderr
</span><span id="__span-141-2"><a id="__codelineno-141-2" name="__codelineno-141-2" href="#__codelineno-141-2"></a>%pip install -U psycopg psycopg-pool langgraph langgraph-checkpoint-postgres
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-142-1"><a id="__codelineno-142-1" name="__codelineno-142-1" href="#__codelineno-142-1"></a>import getpass
</span><span id="__span-142-2"><a id="__codelineno-142-2" name="__codelineno-142-2" href="#__codelineno-142-2"></a>import os
</span><span id="__span-142-3"><a id="__codelineno-142-3" name="__codelineno-142-3" href="#__codelineno-142-3"></a>
</span><span id="__span-142-4"><a id="__codelineno-142-4" name="__codelineno-142-4" href="#__codelineno-142-4"></a>
</span><span id="__span-142-5"><a id="__codelineno-142-5" name="__codelineno-142-5" href="#__codelineno-142-5"></a>def _set_env(var: str):
</span><span id="__span-142-6"><a id="__codelineno-142-6" name="__codelineno-142-6" href="#__codelineno-142-6"></a>    if not os.environ.get(var):
</span><span id="__span-142-7"><a id="__codelineno-142-7" name="__codelineno-142-7" href="#__codelineno-142-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-142-8"><a id="__codelineno-142-8" name="__codelineno-142-8" href="#__codelineno-142-8"></a>
</span><span id="__span-142-9"><a id="__codelineno-142-9" name="__codelineno-142-9" href="#__codelineno-142-9"></a>
</span><span id="__span-142-10"><a id="__codelineno-142-10" name="__codelineno-142-10" href="#__codelineno-142-10"></a>_set_env(&quot;OPENAI_API_KEY&quot;)
</span></code></pre></div>
<h2 id="define-model-and-tools-for-the-graph">Define model and tools for the graph<a class="headerlink" href="#define-model-and-tools-for-the-graph" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-143-1"><a id="__codelineno-143-1" name="__codelineno-143-1" href="#__codelineno-143-1"></a>from typing import Literal
</span><span id="__span-143-2"><a id="__codelineno-143-2" name="__codelineno-143-2" href="#__codelineno-143-2"></a>
</span><span id="__span-143-3"><a id="__codelineno-143-3" name="__codelineno-143-3" href="#__codelineno-143-3"></a>from langchain_core.tools import tool
</span><span id="__span-143-4"><a id="__codelineno-143-4" name="__codelineno-143-4" href="#__codelineno-143-4"></a>from langchain_openai import ChatOpenAI
</span><span id="__span-143-5"><a id="__codelineno-143-5" name="__codelineno-143-5" href="#__codelineno-143-5"></a>from langgraph.prebuilt import create_react_agent
</span><span id="__span-143-6"><a id="__codelineno-143-6" name="__codelineno-143-6" href="#__codelineno-143-6"></a>from langgraph.checkpoint.postgres import PostgresSaver
</span><span id="__span-143-7"><a id="__codelineno-143-7" name="__codelineno-143-7" href="#__codelineno-143-7"></a>from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
</span><span id="__span-143-8"><a id="__codelineno-143-8" name="__codelineno-143-8" href="#__codelineno-143-8"></a>
</span><span id="__span-143-9"><a id="__codelineno-143-9" name="__codelineno-143-9" href="#__codelineno-143-9"></a>
</span><span id="__span-143-10"><a id="__codelineno-143-10" name="__codelineno-143-10" href="#__codelineno-143-10"></a>@tool
</span><span id="__span-143-11"><a id="__codelineno-143-11" name="__codelineno-143-11" href="#__codelineno-143-11"></a>def get_weather(city: Literal[&quot;nyc&quot;, &quot;sf&quot;]):
</span><span id="__span-143-12"><a id="__codelineno-143-12" name="__codelineno-143-12" href="#__codelineno-143-12"></a>    &quot;&quot;&quot;Use this to get weather information.&quot;&quot;&quot;
</span><span id="__span-143-13"><a id="__codelineno-143-13" name="__codelineno-143-13" href="#__codelineno-143-13"></a>    if city == &quot;nyc&quot;:
</span><span id="__span-143-14"><a id="__codelineno-143-14" name="__codelineno-143-14" href="#__codelineno-143-14"></a>        return &quot;It might be cloudy in nyc&quot;
</span><span id="__span-143-15"><a id="__codelineno-143-15" name="__codelineno-143-15" href="#__codelineno-143-15"></a>    elif city == &quot;sf&quot;:
</span><span id="__span-143-16"><a id="__codelineno-143-16" name="__codelineno-143-16" href="#__codelineno-143-16"></a>        return &quot;It&#39;s always sunny in sf&quot;
</span><span id="__span-143-17"><a id="__codelineno-143-17" name="__codelineno-143-17" href="#__codelineno-143-17"></a>    else:
</span><span id="__span-143-18"><a id="__codelineno-143-18" name="__codelineno-143-18" href="#__codelineno-143-18"></a>        raise AssertionError(&quot;Unknown city&quot;)
</span><span id="__span-143-19"><a id="__codelineno-143-19" name="__codelineno-143-19" href="#__codelineno-143-19"></a>
</span><span id="__span-143-20"><a id="__codelineno-143-20" name="__codelineno-143-20" href="#__codelineno-143-20"></a>
</span><span id="__span-143-21"><a id="__codelineno-143-21" name="__codelineno-143-21" href="#__codelineno-143-21"></a>tools = [get_weather]
</span><span id="__span-143-22"><a id="__codelineno-143-22" name="__codelineno-143-22" href="#__codelineno-143-22"></a>model = ChatOpenAI(model_name=&quot;gpt-4o-mini&quot;, temperature=0)
</span></code></pre></div>
<h2 id="use-sync-connection">Use sync connection<a class="headerlink" href="#use-sync-connection" title="Permanent link">#</a></h2>
<p>This sets up a synchronous connection to the database.</p>
<p>Synchronous connections execute operations in a blocking manner, meaning each operation waits for completion before moving to the next one. The DB_URI is the database connection URI, with the protocol used for connecting to a PostgreSQL database, authentication, and host where database is running. The connection_kwargs dictionary defines additional parameters for the database connection.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-144-1"><a id="__codelineno-144-1" name="__codelineno-144-1" href="#__codelineno-144-1"></a>DB_URI = &quot;postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable&quot;
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-145-1"><a id="__codelineno-145-1" name="__codelineno-145-1" href="#__codelineno-145-1"></a>connection_kwargs = {
</span><span id="__span-145-2"><a id="__codelineno-145-2" name="__codelineno-145-2" href="#__codelineno-145-2"></a>    &quot;autocommit&quot;: True,
</span><span id="__span-145-3"><a id="__codelineno-145-3" name="__codelineno-145-3" href="#__codelineno-145-3"></a>    &quot;prepare_threshold&quot;: 0,
</span><span id="__span-145-4"><a id="__codelineno-145-4" name="__codelineno-145-4" href="#__codelineno-145-4"></a>}
</span></code></pre></div>
<h2 id="with-a-connection-pool">With a connection pool<a class="headerlink" href="#with-a-connection-pool" title="Permanent link">#</a></h2>
<p>This manages a pool of reusable database connections: - Advantages: Efficient resource utilization, improved performance for frequent connections - Best for: Applications with many short-lived database operations</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-146-1"><a id="__codelineno-146-1" name="__codelineno-146-1" href="#__codelineno-146-1"></a>from psycopg_pool import ConnectionPool
</span><span id="__span-146-2"><a id="__codelineno-146-2" name="__codelineno-146-2" href="#__codelineno-146-2"></a>
</span><span id="__span-146-3"><a id="__codelineno-146-3" name="__codelineno-146-3" href="#__codelineno-146-3"></a>with ConnectionPool(
</span><span id="__span-146-4"><a id="__codelineno-146-4" name="__codelineno-146-4" href="#__codelineno-146-4"></a>    # Example configuration
</span><span id="__span-146-5"><a id="__codelineno-146-5" name="__codelineno-146-5" href="#__codelineno-146-5"></a>    conninfo=DB_URI,
</span><span id="__span-146-6"><a id="__codelineno-146-6" name="__codelineno-146-6" href="#__codelineno-146-6"></a>    max_size=20,
</span><span id="__span-146-7"><a id="__codelineno-146-7" name="__codelineno-146-7" href="#__codelineno-146-7"></a>    kwargs=connection_kwargs,
</span><span id="__span-146-8"><a id="__codelineno-146-8" name="__codelineno-146-8" href="#__codelineno-146-8"></a>) as pool:
</span><span id="__span-146-9"><a id="__codelineno-146-9" name="__codelineno-146-9" href="#__codelineno-146-9"></a>    checkpointer = PostgresSaver(pool)
</span><span id="__span-146-10"><a id="__codelineno-146-10" name="__codelineno-146-10" href="#__codelineno-146-10"></a>
</span><span id="__span-146-11"><a id="__codelineno-146-11" name="__codelineno-146-11" href="#__codelineno-146-11"></a>    # NOTE: you need to call .setup() the first time you&#39;re using your checkpointer
</span><span id="__span-146-12"><a id="__codelineno-146-12" name="__codelineno-146-12" href="#__codelineno-146-12"></a>    checkpointer.setup()
</span><span id="__span-146-13"><a id="__codelineno-146-13" name="__codelineno-146-13" href="#__codelineno-146-13"></a>
</span><span id="__span-146-14"><a id="__codelineno-146-14" name="__codelineno-146-14" href="#__codelineno-146-14"></a>    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
</span><span id="__span-146-15"><a id="__codelineno-146-15" name="__codelineno-146-15" href="#__codelineno-146-15"></a>    config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;}}
</span><span id="__span-146-16"><a id="__codelineno-146-16" name="__codelineno-146-16" href="#__codelineno-146-16"></a>    res = graph.invoke({&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in sf&quot;)]}, config)
</span><span id="__span-146-17"><a id="__codelineno-146-17" name="__codelineno-146-17" href="#__codelineno-146-17"></a>    checkpoint = checkpointer.get(config)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-147-1"><a id="__codelineno-147-1" name="__codelineno-147-1" href="#__codelineno-147-1"></a>res
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-148-1"><a id="__codelineno-148-1" name="__codelineno-148-1" href="#__codelineno-148-1"></a>{&#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;735b7deb-b0fe-4ad5-8920-2a3c69bbe9f7&#39;),
</span><span id="__span-148-2"><a id="__codelineno-148-2" name="__codelineno-148-2" href="#__codelineno-148-2"></a>  AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-c56b3e04-08a9-4a59-b3f5-ee52d0ef0656-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71}),
</span><span id="__span-148-3"><a id="__codelineno-148-3" name="__codelineno-148-3" href="#__codelineno-148-3"></a>  ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;0644bf7b-4d1b-4ebe-afa1-d2169ccce582&#39;, tool_call_id=&#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;),
</span><span id="__span-148-4"><a id="__codelineno-148-4" name="__codelineno-148-4" href="#__codelineno-148-4"></a>  AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 10, &#39;prompt_tokens&#39;: 84, &#39;total_tokens&#39;: 94}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-1ed9b8d0-9b50-4b87-b3a2-9860f51e9fd1-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}
</span><span id="__span-148-5"><a id="__codelineno-148-5" name="__codelineno-148-5" href="#__codelineno-148-5"></a>  ```
</span><span id="__span-148-6"><a id="__codelineno-148-6" name="__codelineno-148-6" href="#__codelineno-148-6"></a>
</span><span id="__span-148-7"><a id="__codelineno-148-7" name="__codelineno-148-7" href="#__codelineno-148-7"></a>  ```
</span><span id="__span-148-8"><a id="__codelineno-148-8" name="__codelineno-148-8" href="#__codelineno-148-8"></a>  checkpoint
</span><span id="__span-148-9"><a id="__codelineno-148-9" name="__codelineno-148-9" href="#__codelineno-148-9"></a>  ```
</span><span id="__span-148-10"><a id="__codelineno-148-10" name="__codelineno-148-10" href="#__codelineno-148-10"></a>
</span><span id="__span-148-11"><a id="__codelineno-148-11" name="__codelineno-148-11" href="#__codelineno-148-11"></a>  ```
</span><span id="__span-148-12"><a id="__codelineno-148-12" name="__codelineno-148-12" href="#__codelineno-148-12"></a>  {&#39;v&#39;: 1,
</span><span id="__span-148-13"><a id="__codelineno-148-13" name="__codelineno-148-13" href="#__codelineno-148-13"></a> &#39;id&#39;: &#39;1ef559b7-3b19-6ce8-8003-18d0f60634be&#39;,
</span><span id="__span-148-14"><a id="__codelineno-148-14" name="__codelineno-148-14" href="#__codelineno-148-14"></a> &#39;ts&#39;: &#39;2024-08-08T15:32:42.108605+00:00&#39;,
</span><span id="__span-148-15"><a id="__codelineno-148-15" name="__codelineno-148-15" href="#__codelineno-148-15"></a> &#39;current_tasks&#39;: {},
</span><span id="__span-148-16"><a id="__codelineno-148-16" name="__codelineno-148-16" href="#__codelineno-148-16"></a> &#39;pending_sends&#39;: [],
</span><span id="__span-148-17"><a id="__codelineno-148-17" name="__codelineno-148-17" href="#__codelineno-148-17"></a> &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;,
</span><span id="__span-148-18"><a id="__codelineno-148-18" name="__codelineno-148-18" href="#__codelineno-148-18"></a>   &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;},
</span><span id="__span-148-19"><a id="__codelineno-148-19" name="__codelineno-148-19" href="#__codelineno-148-19"></a>  &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;},
</span><span id="__span-148-20"><a id="__codelineno-148-20" name="__codelineno-148-20" href="#__codelineno-148-20"></a>  &#39;__input__&#39;: {},
</span><span id="__span-148-21"><a id="__codelineno-148-21" name="__codelineno-148-21" href="#__codelineno-148-21"></a>  &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}},
</span><span id="__span-148-22"><a id="__codelineno-148-22" name="__codelineno-148-22" href="#__codelineno-148-22"></a> &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af&#39;,
</span><span id="__span-148-23"><a id="__codelineno-148-23" name="__codelineno-148-23" href="#__codelineno-148-23"></a>  &#39;tools&#39;: &#39;00000000000000000000000000000005.&#39;,
</span><span id="__span-148-24"><a id="__codelineno-148-24" name="__codelineno-148-24" href="#__codelineno-148-24"></a>  &#39;messages&#39;: &#39;00000000000000000000000000000005.b9adc75836c78af94af1d6811340dd13&#39;,
</span><span id="__span-148-25"><a id="__codelineno-148-25" name="__codelineno-148-25" href="#__codelineno-148-25"></a>  &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;,
</span><span id="__span-148-26"><a id="__codelineno-148-26" name="__codelineno-148-26" href="#__codelineno-148-26"></a>  &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;,
</span><span id="__span-148-27"><a id="__codelineno-148-27" name="__codelineno-148-27" href="#__codelineno-148-27"></a>  &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;},
</span><span id="__span-148-28"><a id="__codelineno-148-28" name="__codelineno-148-28" href="#__codelineno-148-28"></a> &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;,
</span><span id="__span-148-29"><a id="__codelineno-148-29" name="__codelineno-148-29" href="#__codelineno-148-29"></a>  &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;735b7deb-b0fe-4ad5-8920-2a3c69bbe9f7&#39;),
</span><span id="__span-148-30"><a id="__codelineno-148-30" name="__codelineno-148-30" href="#__codelineno-148-30"></a>   AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-c56b3e04-08a9-4a59-b3f5-ee52d0ef0656-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71}),
</span><span id="__span-148-31"><a id="__codelineno-148-31" name="__codelineno-148-31" href="#__codelineno-148-31"></a>   ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;0644bf7b-4d1b-4ebe-afa1-d2169ccce582&#39;, tool_call_id=&#39;call_lJHMDYgfgRdiEAGfFsEhqqKV&#39;),
</span><span id="__span-148-32"><a id="__codelineno-148-32" name="__codelineno-148-32" href="#__codelineno-148-32"></a>   AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 10, &#39;prompt_tokens&#39;: 84, &#39;total_tokens&#39;: 94}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-1ed9b8d0-9b50-4b87-b3a2-9860f51e9fd1-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}}
</span><span id="__span-148-33"><a id="__codelineno-148-33" name="__codelineno-148-33" href="#__codelineno-148-33"></a>   ```
</span><span id="__span-148-34"><a id="__codelineno-148-34" name="__codelineno-148-34" href="#__codelineno-148-34"></a>
</span><span id="__span-148-35"><a id="__codelineno-148-35" name="__codelineno-148-35" href="#__codelineno-148-35"></a>   ## With a connection
</span><span id="__span-148-36"><a id="__codelineno-148-36" name="__codelineno-148-36" href="#__codelineno-148-36"></a>   This creates a single, dedicated connection to the database: - Advantages: Simple to use, suitable for longer transactions - Best for: Applications with fewer, longer-lived database operations
</span><span id="__span-148-37"><a id="__codelineno-148-37" name="__codelineno-148-37" href="#__codelineno-148-37"></a>
</span><span id="__span-148-38"><a id="__codelineno-148-38" name="__codelineno-148-38" href="#__codelineno-148-38"></a>   ```
</span><span id="__span-148-39"><a id="__codelineno-148-39" name="__codelineno-148-39" href="#__codelineno-148-39"></a>   from psycopg import Connection
</span><span id="__span-148-40"><a id="__codelineno-148-40" name="__codelineno-148-40" href="#__codelineno-148-40"></a>
</span><span id="__span-148-41"><a id="__codelineno-148-41" name="__codelineno-148-41" href="#__codelineno-148-41"></a>
</span><span id="__span-148-42"><a id="__codelineno-148-42" name="__codelineno-148-42" href="#__codelineno-148-42"></a>with Connection.connect(DB_URI, **connection_kwargs) as conn:
</span><span id="__span-148-43"><a id="__codelineno-148-43" name="__codelineno-148-43" href="#__codelineno-148-43"></a>    checkpointer = PostgresSaver(conn)
</span><span id="__span-148-44"><a id="__codelineno-148-44" name="__codelineno-148-44" href="#__codelineno-148-44"></a>    # NOTE: you need to call .setup() the first time you&#39;re using your checkpointer
</span><span id="__span-148-45"><a id="__codelineno-148-45" name="__codelineno-148-45" href="#__codelineno-148-45"></a>    # checkpointer.setup()
</span><span id="__span-148-46"><a id="__codelineno-148-46" name="__codelineno-148-46" href="#__codelineno-148-46"></a>    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
</span><span id="__span-148-47"><a id="__codelineno-148-47" name="__codelineno-148-47" href="#__codelineno-148-47"></a>    config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}}
</span><span id="__span-148-48"><a id="__codelineno-148-48" name="__codelineno-148-48" href="#__codelineno-148-48"></a>    res = graph.invoke({&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in sf&quot;)]}, config)
</span><span id="__span-148-49"><a id="__codelineno-148-49" name="__codelineno-148-49" href="#__codelineno-148-49"></a>
</span><span id="__span-148-50"><a id="__codelineno-148-50" name="__codelineno-148-50" href="#__codelineno-148-50"></a>    checkpoint_tuple = checkpointer.get_tuple(config)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-149-1"><a id="__codelineno-149-1" name="__codelineno-149-1" href="#__codelineno-149-1"></a>checkpoint_tuple
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-150-1"><a id="__codelineno-150-1" name="__codelineno-150-1" href="#__codelineno-150-1"></a>CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;2&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4650-6bfc-8003-1c5488f19318&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-4650-6bfc-8003-1c5488f19318&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:43.284551+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000005.&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000005.af9f229d2c4e14f4866eb37f72ec39f6&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;7a14f96c-2d88-454f-9520-0e0287a4abbb&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_NcL4dBTYu4kSPGMKdxztdpjN&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-39adbf2c-36ef-40f6-9cad-8e1f8167fc19-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_NcL4dBTYu4kSPGMKdxztdpjN&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71}), ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;c9f82354-3225-40a8-bf54-81f3e199043b&#39;, tool_call_id=&#39;call_NcL4dBTYu4kSPGMKdxztdpjN&#39;), AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 10, &#39;prompt_tokens&#39;: 84, &#39;total_tokens&#39;: 94}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-83888be3-d681-42ca-ad67-e2f5ee8550de-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}}, metadata={&#39;step&#39;: 3, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 94, &#39;prompt_tokens&#39;: 84, &#39;completion_tokens&#39;: 10}, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;}, id=&#39;run-83888be3-d681-42ca-ad67-e2f5ee8550de-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;2&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4087-681a-8002-88a5738f76f1&#39;}}, pending_writes=[])
</span></code></pre></div>
<h2 id="with-a-connection-string">With a connection string<a class="headerlink" href="#with-a-connection-string" title="Permanent link">#</a></h2>
<p>This creates a connection based on a connection string: - Advantages: Simplicity, encapsulates connection details - Best for: Quick setup or when connection details are provided as a string</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-151-1"><a id="__codelineno-151-1" name="__codelineno-151-1" href="#__codelineno-151-1"></a>with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
</span><span id="__span-151-2"><a id="__codelineno-151-2" name="__codelineno-151-2" href="#__codelineno-151-2"></a>    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
</span><span id="__span-151-3"><a id="__codelineno-151-3" name="__codelineno-151-3" href="#__codelineno-151-3"></a>    config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;3&quot;}}
</span><span id="__span-151-4"><a id="__codelineno-151-4" name="__codelineno-151-4" href="#__codelineno-151-4"></a>    res = graph.invoke({&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in sf&quot;)]}, config)
</span><span id="__span-151-5"><a id="__codelineno-151-5" name="__codelineno-151-5" href="#__codelineno-151-5"></a>
</span><span id="__span-151-6"><a id="__codelineno-151-6" name="__codelineno-151-6" href="#__codelineno-151-6"></a>    checkpoint_tuples = list(checkpointer.list(config))
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-152-1"><a id="__codelineno-152-1" name="__codelineno-152-1" href="#__codelineno-152-1"></a>checkpoint_tuples
</span></code></pre></div>
<p><div class="language-text highlight"><pre><span></span><code><span id="__span-153-1"><a id="__codelineno-153-1" name="__codelineno-153-1" href="#__codelineno-153-1"></a>[CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-5024-6476-8003-cf0a750e6b37&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-5024-6476-8003-cf0a750e6b37&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:44.314900+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000005.&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000005.3f8b8d9923575b911e17157008ab75ac&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;5bf79d15-6332-4bf5-89bd-ee192b31ed84&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_507c9469a1&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-2958adc7-f6a4-415d-ade1-5ee77e0b9276-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71}), ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;cac4f90a-dc3e-4bfa-940f-1c630289a583&#39;, tool_call_id=&#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;), AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 10, &#39;prompt_tokens&#39;: 84, &#39;total_tokens&#39;: 94}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-97d3fb7a-3d2e-4090-84f4-dafdfe44553f-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}}, metadata={&#39;step&#39;: 3, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;The weather in San Francisco is always sunny!&#39;, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 94, &#39;prompt_tokens&#39;: 84, &#39;completion_tokens&#39;: 10}, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;}, id=&#39;run-97d3fb7a-3d2e-4090-84f4-dafdfe44553f-0&#39;, usage_metadata={&#39;input_tokens&#39;: 84, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 94})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4b3d-6430-8002-b5c99d2eb4db&#39;}}, pending_writes=None),
</span><span id="__span-153-2"><a id="__codelineno-153-2" name="__codelineno-153-2" href="#__codelineno-153-2"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4b3d-6430-8002-b5c99d2eb4db&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-4b3d-6430-8002-b5c99d2eb4db&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:43.800857+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000004.&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000004.1195f50946feaedb0bae1fdbfadc806b&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;tools&#39;: &#39;tools&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;5bf79d15-6332-4bf5-89bd-ee192b31ed84&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_507c9469a1&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-2958adc7-f6a4-415d-ade1-5ee77e0b9276-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71}), ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;cac4f90a-dc3e-4bfa-940f-1c630289a583&#39;, tool_call_id=&#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;)]}}, metadata={&#39;step&#39;: 2, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;tools&#39;: {&#39;messages&#39;: [ToolMessage(content=&quot;It&#39;s always sunny in sf&quot;, name=&#39;get_weather&#39;, id=&#39;cac4f90a-dc3e-4bfa-940f-1c630289a583&#39;, tool_call_id=&#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;)]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4b30-6078-8001-eaf8c9bd8844&#39;}}, pending_writes=None),
</span><span id="__span-153-3"><a id="__codelineno-153-3" name="__codelineno-153-3" href="#__codelineno-153-3"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-4b30-6078-8001-eaf8c9bd8844&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-4b30-6078-8001-eaf8c9bd8844&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:43.795440+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000003.bab5fb3a70876f600f5f2fd46945ce5f&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;5bf79d15-6332-4bf5-89bd-ee192b31ed84&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 14, &#39;prompt_tokens&#39;: 57, &#39;total_tokens&#39;: 71}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_507c9469a1&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-2958adc7-f6a4-415d-ade1-5ee77e0b9276-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71})], &#39;branch:agent:should_continue:tools&#39;: &#39;agent&#39;}}, metadata={&#39;step&#39;: 1, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;type&#39;: &#39;function&#39;, &#39;function&#39;: {&#39;name&#39;: &#39;get_weather&#39;, &#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;sf&quot;}&#39;}}]}, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 71, &#39;prompt_tokens&#39;: 57, &#39;completion_tokens&#39;: 14}, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;system_fingerprint&#39;: &#39;fp_507c9469a1&#39;}, id=&#39;run-2958adc7-f6a4-415d-ade1-5ee77e0b9276-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;sf&#39;}, &#39;id&#39;: &#39;call_9y3q1BiwW7zGh2gk2faInTRk&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 57, &#39;output_tokens&#39;: 14, &#39;total_tokens&#39;: 71})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-46d7-6116-8000-8976b7c89a2f&#39;}}, pending_writes=None),
</span><span id="__span-153-4"><a id="__codelineno-153-4" name="__codelineno-153-4" href="#__codelineno-153-4"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-46d7-6116-8000-8976b7c89a2f&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-46d7-6116-8000-8976b7c89a2f&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:43.339573+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}}, &#39;channel_versions&#39;: {&#39;messages&#39;: &#39;00000000000000000000000000000002.ba0c90d32863686481f7fe5eab9ecdf0&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;channel_values&#39;: {&#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in sf&quot;, id=&#39;5bf79d15-6332-4bf5-89bd-ee192b31ed84&#39;)], &#39;start:agent&#39;: &#39;__start__&#39;}}, metadata={&#39;step&#39;: 0, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: None}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-46ce-6c64-bfff-ef7fe2663573&#39;}}, pending_writes=None),
</span><span id="__span-153-5"><a id="__codelineno-153-5" name="__codelineno-153-5" href="#__codelineno-153-5"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;3&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-46ce-6c64-bfff-ef7fe2663573&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-46ce-6c64-bfff-ef7fe2663573&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:43.336188+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;__input__&#39;: {}}, &#39;channel_versions&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033&#39;}, &#39;channel_values&#39;: {&#39;__start__&#39;: {&#39;messages&#39;: [[&#39;human&#39;, &quot;what&#39;s the weather in sf&quot;]]}}}, metadata={&#39;step&#39;: -1, &#39;source&#39;: &#39;input&#39;, &#39;writes&#39;: {&#39;messages&#39;: [[&#39;human&#39;, &quot;what&#39;s the weather in sf&quot;]]}}, parent_config=None, pending_writes=None)]
</span><span id="__span-153-6"><a id="__codelineno-153-6" name="__codelineno-153-6" href="#__codelineno-153-6"></a> ```
</span><span id="__span-153-7"><a id="__codelineno-153-7" name="__codelineno-153-7" href="#__codelineno-153-7"></a>
</span><span id="__span-153-8"><a id="__codelineno-153-8" name="__codelineno-153-8" href="#__codelineno-153-8"></a> ## Use async connection
</span><span id="__span-153-9"><a id="__codelineno-153-9" name="__codelineno-153-9" href="#__codelineno-153-9"></a> This sets up an asynchronous connection to the database.
</span><span id="__span-153-10"><a id="__codelineno-153-10" name="__codelineno-153-10" href="#__codelineno-153-10"></a>
</span><span id="__span-153-11"><a id="__codelineno-153-11" name="__codelineno-153-11" href="#__codelineno-153-11"></a>Async connections allow non-blocking database operations. This means other parts of your application can continue running while waiting for database operations to complete. It&#39;s particularly useful in high-concurrency scenarios or when dealing with I/O-bound operations.
</span><span id="__span-153-12"><a id="__codelineno-153-12" name="__codelineno-153-12" href="#__codelineno-153-12"></a>
</span><span id="__span-153-13"><a id="__codelineno-153-13" name="__codelineno-153-13" href="#__codelineno-153-13"></a>
</span><span id="__span-153-14"><a id="__codelineno-153-14" name="__codelineno-153-14" href="#__codelineno-153-14"></a>## With a connection pool
</span></code></pre></div>
from psycopg_pool import AsyncConnectionPool</p>
<p>async with AsyncConnectionPool(
    # Example configuration
    conninfo=DB_URI,
    max_size=20,
    kwargs=connection_kwargs,
) as pool:
    checkpointer = AsyncPostgresSaver(pool)</p>
<div class="language-text highlight"><pre><span></span><code># NOTE: you need to call .setup() the first time you&#39;re using your checkpointer
await checkpointer.setup()

graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;4&quot;}}
res = await graph.ainvoke(
    {&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in nyc&quot;)]}, config
)

checkpoint = await checkpointer.aget(config)
</code></pre></div>
<p><code></code>
checkpoint
<code></code>
{'v': 1,
 'id': '1ef559b7-5cc9-6460-8003-8655824c0944',
 'ts': '2024-08-08T15:32:45.640793+00:00',
 'current_tasks': {},
 'pending_sends': [],
 'versions_seen': {'agent': {'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8',
   'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc'},
  'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'},
  '<strong>input</strong>': {},
  '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}},
 'channel_versions': {'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af',
  'tools': '00000000000000000000000000000005.',
  'messages': '00000000000000000000000000000005.d869fc7231619df0db74feed624efe41',
  '<strong>start</strong>': '00000000000000000000000000000002.',
  'start:agent': '00000000000000000000000000000003.',
  'branch:agent:should_continue:tools': '00000000000000000000000000000004.'},
 'channel_values': {'agent': 'agent',
  'messages': [HumanMessage(content="what's the weather in nyc", id='d883b8a0-99de-486d-91a2-bcfa7f25dc05'),
   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_H6TAYfyd6AnaCrkQGs6Q2fVp', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6f542f84-ad73-444c-8ef7-b5ea75a2e09b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_H6TAYfyd6AnaCrkQGs6Q2fVp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}),
   ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='c0e52254-77a4-4ea9-a2b7-61dd2d65ec68', tool_call_id='call_H6TAYfyd6AnaCrkQGs6Q2fVp'),
   AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-977140d4-7582-40c3-b2b6-31b542c430a3-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}
   ```</p>
<h2 id="with-a-connection">With a connection<a class="headerlink" href="#with-a-connection" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-156-1"><a id="__codelineno-156-1" name="__codelineno-156-1" href="#__codelineno-156-1"></a>   from psycopg import AsyncConnection
</span><span id="__span-156-2"><a id="__codelineno-156-2" name="__codelineno-156-2" href="#__codelineno-156-2"></a>
</span><span id="__span-156-3"><a id="__codelineno-156-3" name="__codelineno-156-3" href="#__codelineno-156-3"></a>async with await AsyncConnection.connect(DB_URI, **connection_kwargs) as conn:
</span><span id="__span-156-4"><a id="__codelineno-156-4" name="__codelineno-156-4" href="#__codelineno-156-4"></a>    checkpointer = AsyncPostgresSaver(conn)
</span><span id="__span-156-5"><a id="__codelineno-156-5" name="__codelineno-156-5" href="#__codelineno-156-5"></a>    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
</span><span id="__span-156-6"><a id="__codelineno-156-6" name="__codelineno-156-6" href="#__codelineno-156-6"></a>    config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;5&quot;}}
</span><span id="__span-156-7"><a id="__codelineno-156-7" name="__codelineno-156-7" href="#__codelineno-156-7"></a>    res = await graph.ainvoke(
</span><span id="__span-156-8"><a id="__codelineno-156-8" name="__codelineno-156-8" href="#__codelineno-156-8"></a>        {&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in nyc&quot;)]}, config
</span><span id="__span-156-9"><a id="__codelineno-156-9" name="__codelineno-156-9" href="#__codelineno-156-9"></a>    )
</span><span id="__span-156-10"><a id="__codelineno-156-10" name="__codelineno-156-10" href="#__codelineno-156-10"></a>    checkpoint_tuple = await checkpointer.aget_tuple(config)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-157-1"><a id="__codelineno-157-1" name="__codelineno-157-1" href="#__codelineno-157-1"></a>checkpoint_tuple
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-158-1"><a id="__codelineno-158-1" name="__codelineno-158-1" href="#__codelineno-158-1"></a>CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;5&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-65b4-60ca-8003-1ef4b620559a&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-65b4-60ca-8003-1ef4b620559a&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:46.575814+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000005.&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000005.1557a6006d58f736d5cb2dd5c5f10111&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in nyc&quot;, id=&#39;935e7732-b288-49bd-9ec2-1f7610cc38cb&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_94KtjtPmsiaj7T8yXvL7Ef31&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;nyc&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 15, &#39;prompt_tokens&#39;: 58, &#39;total_tokens&#39;: 73}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-790c929a-7982-49e7-af67-2cbe4a86373b-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;nyc&#39;}, &#39;id&#39;: &#39;call_94KtjtPmsiaj7T8yXvL7Ef31&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 58, &#39;output_tokens&#39;: 15, &#39;total_tokens&#39;: 73}), ToolMessage(content=&#39;It might be cloudy in nyc&#39;, name=&#39;get_weather&#39;, id=&#39;b2dc1073-abc4-4492-8982-434a7e32e445&#39;, tool_call_id=&#39;call_94KtjtPmsiaj7T8yXvL7Ef31&#39;), AIMessage(content=&#39;The weather in NYC might be cloudy.&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 9, &#39;prompt_tokens&#39;: 88, &#39;total_tokens&#39;: 97}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-7e8a7f16-d8e1-457a-89f3-192102396449-0&#39;, usage_metadata={&#39;input_tokens&#39;: 88, &#39;output_tokens&#39;: 9, &#39;total_tokens&#39;: 97})]}}, metadata={&#39;step&#39;: 3, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;The weather in NYC might be cloudy.&#39;, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 97, &#39;prompt_tokens&#39;: 88, &#39;completion_tokens&#39;: 9}, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;}, id=&#39;run-7e8a7f16-d8e1-457a-89f3-192102396449-0&#39;, usage_metadata={&#39;input_tokens&#39;: 88, &#39;output_tokens&#39;: 9, &#39;total_tokens&#39;: 97})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;5&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-62ae-6128-8002-c04af82bcd41&#39;}}, pending_writes=[])
</span></code></pre></div>
<h2 id="with-a-connection-string_1">With a connection string<a class="headerlink" href="#with-a-connection-string_1" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-159-1"><a id="__codelineno-159-1" name="__codelineno-159-1" href="#__codelineno-159-1"></a>async with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:
</span><span id="__span-159-2"><a id="__codelineno-159-2" name="__codelineno-159-2" href="#__codelineno-159-2"></a>    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
</span><span id="__span-159-3"><a id="__codelineno-159-3" name="__codelineno-159-3" href="#__codelineno-159-3"></a>    config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;6&quot;}}
</span><span id="__span-159-4"><a id="__codelineno-159-4" name="__codelineno-159-4" href="#__codelineno-159-4"></a>    res = await graph.ainvoke(
</span><span id="__span-159-5"><a id="__codelineno-159-5" name="__codelineno-159-5" href="#__codelineno-159-5"></a>        {&quot;messages&quot;: [(&quot;human&quot;, &quot;what&#39;s the weather in nyc&quot;)]}, config
</span><span id="__span-159-6"><a id="__codelineno-159-6" name="__codelineno-159-6" href="#__codelineno-159-6"></a>    )
</span><span id="__span-159-7"><a id="__codelineno-159-7" name="__codelineno-159-7" href="#__codelineno-159-7"></a>    checkpoint_tuples = [c async for c in checkpointer.alist(config)]
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-160-1"><a id="__codelineno-160-1" name="__codelineno-160-1" href="#__codelineno-160-1"></a>checkpoint_tuples
</span></code></pre></div>
<p><div class="language-text highlight"><pre><span></span><code><span id="__span-161-1"><a id="__codelineno-161-1" name="__codelineno-161-1" href="#__codelineno-161-1"></a>[CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-723c-67de-8003-63bd4eab35af&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-723c-67de-8003-63bd4eab35af&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:47.890003+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000005.&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000005.b6fe2a26011590cfe8fd6a39151a9e92&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in nyc&quot;, id=&#39;977ddb90-9991-44cb-9f73-361c6dd21396&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;nyc&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 15, &#39;prompt_tokens&#39;: 58, &#39;total_tokens&#39;: 73}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-47b10c48-4db3-46d8-b4fa-e021818e01c5-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;nyc&#39;}, &#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 58, &#39;output_tokens&#39;: 15, &#39;total_tokens&#39;: 73}), ToolMessage(content=&#39;It might be cloudy in nyc&#39;, name=&#39;get_weather&#39;, id=&#39;798c520f-4f9a-4f6d-a389-da721eb4d4ce&#39;, tool_call_id=&#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;), AIMessage(content=&#39;The weather in NYC might be cloudy.&#39;, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 9, &#39;prompt_tokens&#39;: 88, &#39;total_tokens&#39;: 97}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;run-4a34e05d-8bcf-41ad-adc3-715919fde64c-0&#39;, usage_metadata={&#39;input_tokens&#39;: 88, &#39;output_tokens&#39;: 9, &#39;total_tokens&#39;: 97})]}}, metadata={&#39;step&#39;: 3, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;The weather in NYC might be cloudy.&#39;, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 97, &#39;prompt_tokens&#39;: 88, &#39;completion_tokens&#39;: 9}, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;}, id=&#39;run-4a34e05d-8bcf-41ad-adc3-715919fde64c-0&#39;, usage_metadata={&#39;input_tokens&#39;: 88, &#39;output_tokens&#39;: 9, &#39;total_tokens&#39;: 97})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6bf5-63c6-8002-ed990dbbc96e&#39;}}, pending_writes=None),
</span><span id="__span-161-2"><a id="__codelineno-161-2" name="__codelineno-161-2" href="#__codelineno-161-2"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6bf5-63c6-8002-ed990dbbc96e&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-6bf5-63c6-8002-ed990dbbc96e&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:47.231667+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;tools&#39;: {&#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000004.&#39;, &#39;tools&#39;: &#39;00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000004.c9074f2a41f05486b5efb86353dc75c0&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000004.&#39;}, &#39;channel_values&#39;: {&#39;tools&#39;: &#39;tools&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in nyc&quot;, id=&#39;977ddb90-9991-44cb-9f73-361c6dd21396&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;nyc&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 15, &#39;prompt_tokens&#39;: 58, &#39;total_tokens&#39;: 73}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-47b10c48-4db3-46d8-b4fa-e021818e01c5-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;nyc&#39;}, &#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 58, &#39;output_tokens&#39;: 15, &#39;total_tokens&#39;: 73}), ToolMessage(content=&#39;It might be cloudy in nyc&#39;, name=&#39;get_weather&#39;, id=&#39;798c520f-4f9a-4f6d-a389-da721eb4d4ce&#39;, tool_call_id=&#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;)]}}, metadata={&#39;step&#39;: 2, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;tools&#39;: {&#39;messages&#39;: [ToolMessage(content=&#39;It might be cloudy in nyc&#39;, name=&#39;get_weather&#39;, id=&#39;798c520f-4f9a-4f6d-a389-da721eb4d4ce&#39;, tool_call_id=&#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;)]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6be0-6926-8001-1a8ce73baf9e&#39;}}, pending_writes=None),
</span><span id="__span-161-3"><a id="__codelineno-161-3" name="__codelineno-161-3" href="#__codelineno-161-3"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6be0-6926-8001-1a8ce73baf9e&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-6be0-6926-8001-1a8ce73baf9e&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:47.223198+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;agent&#39;: {&#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}}, &#39;channel_versions&#39;: {&#39;agent&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;, &#39;messages&#39;: &#39;00000000000000000000000000000003.097b5407d709b297591f1ef5d50c8368&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000003.&#39;, &#39;branch:agent:should_continue:tools&#39;: &#39;00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af&#39;}, &#39;channel_values&#39;: {&#39;agent&#39;: &#39;agent&#39;, &#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in nyc&quot;, id=&#39;977ddb90-9991-44cb-9f73-361c6dd21396&#39;), AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;nyc&quot;}&#39;, &#39;name&#39;: &#39;get_weather&#39;}, &#39;type&#39;: &#39;function&#39;}]}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 15, &#39;prompt_tokens&#39;: 58, &#39;total_tokens&#39;: 73}, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;logprobs&#39;: None}, id=&#39;run-47b10c48-4db3-46d8-b4fa-e021818e01c5-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;nyc&#39;}, &#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 58, &#39;output_tokens&#39;: 15, &#39;total_tokens&#39;: 73})], &#39;branch:agent:should_continue:tools&#39;: &#39;agent&#39;}}, metadata={&#39;step&#39;: 1, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: {&#39;agent&#39;: {&#39;messages&#39;: [AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;type&#39;: &#39;function&#39;, &#39;function&#39;: {&#39;name&#39;: &#39;get_weather&#39;, &#39;arguments&#39;: &#39;{&quot;city&quot;:&quot;nyc&quot;}&#39;}}]}, response_metadata={&#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;gpt-4o-mini-2024-07-18&#39;, &#39;token_usage&#39;: {&#39;total_tokens&#39;: 73, &#39;prompt_tokens&#39;: 58, &#39;completion_tokens&#39;: 15}, &#39;finish_reason&#39;: &#39;tool_calls&#39;, &#39;system_fingerprint&#39;: &#39;fp_48196bc67a&#39;}, id=&#39;run-47b10c48-4db3-46d8-b4fa-e021818e01c5-0&#39;, tool_calls=[{&#39;name&#39;: &#39;get_weather&#39;, &#39;args&#39;: {&#39;city&#39;: &#39;nyc&#39;}, &#39;id&#39;: &#39;call_QIFCuh4zfP9owpjToycJiZf7&#39;, &#39;type&#39;: &#39;tool_call&#39;}], usage_metadata={&#39;input_tokens&#39;: 58, &#39;output_tokens&#39;: 15, &#39;total_tokens&#39;: 73})]}}}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-663d-60b4-8000-10a8922bffbf&#39;}}, pending_writes=None),
</span><span id="__span-161-4"><a id="__codelineno-161-4" name="__codelineno-161-4" href="#__codelineno-161-4"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-663d-60b4-8000-10a8922bffbf&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-663d-60b4-8000-10a8922bffbf&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:46.631935+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;__input__&#39;: {}, &#39;__start__&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}}, &#39;channel_versions&#39;: {&#39;messages&#39;: &#39;00000000000000000000000000000002.2a79db8da664e437bdb25ea804457ca7&#39;, &#39;__start__&#39;: &#39;00000000000000000000000000000002.&#39;, &#39;start:agent&#39;: &#39;00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc&#39;}, &#39;channel_values&#39;: {&#39;messages&#39;: [HumanMessage(content=&quot;what&#39;s the weather in nyc&quot;, id=&#39;977ddb90-9991-44cb-9f73-361c6dd21396&#39;)], &#39;start:agent&#39;: &#39;__start__&#39;}}, metadata={&#39;step&#39;: 0, &#39;source&#39;: &#39;loop&#39;, &#39;writes&#39;: None}, parent_config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6637-6d4e-bfff-6cecf690c3cb&#39;}}, pending_writes=None),
</span><span id="__span-161-5"><a id="__codelineno-161-5" name="__codelineno-161-5" href="#__codelineno-161-5"></a> CheckpointTuple(config={&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;6&#39;, &#39;checkpoint_ns&#39;: &#39;&#39;, &#39;checkpoint_id&#39;: &#39;1ef559b7-6637-6d4e-bfff-6cecf690c3cb&#39;}}, checkpoint={&#39;v&#39;: 1, &#39;id&#39;: &#39;1ef559b7-6637-6d4e-bfff-6cecf690c3cb&#39;, &#39;ts&#39;: &#39;2024-08-08T15:32:46.629806+00:00&#39;, &#39;current_tasks&#39;: {}, &#39;pending_sends&#39;: [], &#39;versions_seen&#39;: {&#39;__input__&#39;: {}}, &#39;channel_versions&#39;: {&#39;__start__&#39;: &#39;00000000000000000000000000000001.0e148ae3debe753278387e84f786e863&#39;}, &#39;channel_values&#39;: {&#39;__start__&#39;: {&#39;messages&#39;: [[&#39;human&#39;, &quot;what&#39;s the weather in nyc&quot;]]}}}, metadata={&#39;step&#39;: -1, &#39;source&#39;: &#39;input&#39;, &#39;writes&#39;: {&#39;messages&#39;: [[&#39;human&#39;, &quot;what&#39;s the weather in nyc&quot;]]}}, parent_config=None, pending_writes=None)]
</span><span id="__span-161-6"><a id="__codelineno-161-6" name="__codelineno-161-6" href="#__codelineno-161-6"></a> ```
</span><span id="__span-161-7"><a id="__codelineno-161-7" name="__codelineno-161-7" href="#__codelineno-161-7"></a>
</span><span id="__span-161-8"><a id="__codelineno-161-8" name="__codelineno-161-8" href="#__codelineno-161-8"></a> # How to use MongoDB checkpointer for persistence
</span><span id="__span-161-9"><a id="__codelineno-161-9" name="__codelineno-161-9" href="#__codelineno-161-9"></a>
</span><span id="__span-161-10"><a id="__codelineno-161-10" name="__codelineno-161-10" href="#__codelineno-161-10"></a> When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions.
</span><span id="__span-161-11"><a id="__codelineno-161-11" name="__codelineno-161-11" href="#__codelineno-161-11"></a>
</span><span id="__span-161-12"><a id="__codelineno-161-12" name="__codelineno-161-12" href="#__codelineno-161-12"></a>This reference implementation shows how to use MongoDB as the backend for persisting checkpoint state using the langgraph-checkpoint-mongodb library.
</span><span id="__span-161-13"><a id="__codelineno-161-13" name="__codelineno-161-13" href="#__codelineno-161-13"></a>
</span><span id="__span-161-14"><a id="__codelineno-161-14" name="__codelineno-161-14" href="#__codelineno-161-14"></a>For demonstration purposes we add persistence to a prebuilt ReAct agent.
</span><span id="__span-161-15"><a id="__codelineno-161-15" name="__codelineno-161-15" href="#__codelineno-161-15"></a>
</span><span id="__span-161-16"><a id="__codelineno-161-16" name="__codelineno-161-16" href="#__codelineno-161-16"></a>In general, you can add a checkpointer to any custom graph that you build like this:
</span></code></pre></div>
from langgraph.graph import StateGraph</p>
<p>builder = StateGraph(...)</p>
<h1 id="define-the-graph_2">... define the graph<a class="headerlink" href="#define-the-graph_2" title="Permanent link">#</a></h1>
<p>checkpointer = # mongodb checkpointer (see examples below)
graph = builder.compile(checkpointer=checkpointer)
...
<div class="language-text highlight"><pre><span></span><code><span id="__span-162-1"><a id="__codelineno-162-1" name="__codelineno-162-1" href="#__codelineno-162-1"></a>## Setup
</span><span id="__span-162-2"><a id="__codelineno-162-2" name="__codelineno-162-2" href="#__codelineno-162-2"></a>To use the MongoDB checkpointer, you will need a MongoDB cluster. Follow this guide to create a cluster if you don&#39;t already have one.
</span><span id="__span-162-3"><a id="__codelineno-162-3" name="__codelineno-162-3" href="#__codelineno-162-3"></a>
</span><span id="__span-162-4"><a id="__codelineno-162-4" name="__codelineno-162-4" href="#__codelineno-162-4"></a>Next, let&#39;s install the required packages and set our API keys
</span></code></pre></div>
%%capture --no-stderr
%pip install -U pymongo langgraph langgraph-checkpoint-mongodb
<div class="language-text highlight"><pre><span></span><code><span id="__span-163-1"><a id="__codelineno-163-1" name="__codelineno-163-1" href="#__codelineno-163-1"></a>
</span></code></pre></div>
import getpass
import os</p>
<p>def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")</p>
<p>_set_env("OPENAI_API_KEY")
<div class="language-text highlight"><pre><span></span><code><span id="__span-164-1"><a id="__codelineno-164-1" name="__codelineno-164-1" href="#__codelineno-164-1"></a>
</span></code></pre></div>
OPENAI_API_KEY:  ········
<div class="language-text highlight"><pre><span></span><code><span id="__span-165-1"><a id="__codelineno-165-1" name="__codelineno-165-1" href="#__codelineno-165-1"></a>## Define model and tools for the graph
</span></code></pre></div>
from typing import Literal</p>
<p>from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent</p>
<p>@tool
def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in nyc"
    elif city == "sf":
        return "It's always sunny in sf"
    else:
        raise AssertionError("Unknown city")</p>
<p>tools = [get_weather]
model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
<div class="language-text highlight"><pre><span></span><code><span id="__span-166-1"><a id="__codelineno-166-1" name="__codelineno-166-1" href="#__codelineno-166-1"></a>## MongoDB checkpointer usage
</span><span id="__span-166-2"><a id="__codelineno-166-2" name="__codelineno-166-2" href="#__codelineno-166-2"></a>## With a connection string
</span><span id="__span-166-3"><a id="__codelineno-166-3" name="__codelineno-166-3" href="#__codelineno-166-3"></a>
</span><span id="__span-166-4"><a id="__codelineno-166-4" name="__codelineno-166-4" href="#__codelineno-166-4"></a>This creates a connection to MongoDB directly using the connection string of your cluster. This is ideal for use in scripts, one-off operations and short-lived applications.
</span></code></pre></div>
from langgraph.checkpoint.mongodb import MongoDBSaver</p>
<p>MONGODB_URI = "localhost:27017"  # replace this with your connection string</p>
<p>with MongoDBSaver.from_conn_string(MONGODB_URI) as checkpointer:
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "1"}}
    response = graph.invoke(
        {"messages": [("human", "what's the weather in sf")]}, config
    )
<div class="language-text highlight"><pre><span></span><code><span id="__span-167-1"><a id="__codelineno-167-1" name="__codelineno-167-1" href="#__codelineno-167-1"></a>
</span></code></pre></div>
response
<div class="language-text highlight"><pre><span></span><code><span id="__span-168-1"><a id="__codelineno-168-1" name="__codelineno-168-1" href="#__codelineno-168-1"></a>
</span></code></pre></div>
{'messages': [HumanMessage(content="what's the weather in sf", additional_kwargs={}, response_metadata={}, id='729afd6a-fdc0-4192-a255-1dac065c79b2'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YqaO8oU3BhGmIz9VHTxqGyyN', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b45c0c12-c68e-4392-92dd-5d325d0a9f60-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_YqaO8oU3BhGmIz9VHTxqGyyN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),
  ToolMessage(content="It's always sunny in sf", name='get_weather', id='0c72eb29-490b-44df-898f-8454c314eac1', tool_call_id='call_YqaO8oU3BhGmIz9VHTxqGyyN'),
  AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None}, id='run-33f54c91-0ba9-48b7-9b25-5a972bbdeea9-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
  <div class="language-text highlight"><pre><span></span><code><span id="__span-169-1"><a id="__codelineno-169-1" name="__codelineno-169-1" href="#__codelineno-169-1"></a>## Using the MongoDB client
</span><span id="__span-169-2"><a id="__codelineno-169-2" name="__codelineno-169-2" href="#__codelineno-169-2"></a>This creates a connection to MongoDB using the MongoDB client. This is ideal for long-running applications since it allows you to reuse the client instance for multiple database operations without needing to reinitialize the connection each time.
</span></code></pre></div>
  from pymongo import MongoClient</p>
<p>mongodb_client = MongoClient(MONGODB_URI)</p>
<p>checkpointer = MongoDBSaver(mongodb_client)
graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
config = {"configurable": {"thread_id": "2"}}
response = graph.invoke({"messages": [("user", "What's the weather in sf?")]}, config)
<div class="language-text highlight"><pre><span></span><code><span id="__span-170-1"><a id="__codelineno-170-1" name="__codelineno-170-1" href="#__codelineno-170-1"></a>
</span></code></pre></div>
response
<div class="language-text highlight"><pre><span></span><code><span id="__span-171-1"><a id="__codelineno-171-1" name="__codelineno-171-1" href="#__codelineno-171-1"></a>
</span></code></pre></div>
{'messages': [HumanMessage(content="What's the weather in sf?", additional_kwargs={}, response_metadata={}, id='4ce68bee-a843-4b08-9c02-7a0e3b010110'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MvGxq9IU9wvW9mfYKSALHtGu', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9712c5a4-376c-4812-a0c4-1b522334a59d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_MvGxq9IU9wvW9mfYKSALHtGu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),
  ToolMessage(content="It's always sunny in sf", name='get_weather', id='b4eed38d-bcaf-4497-ad08-f21ccd6a8c30', tool_call_id='call_MvGxq9IU9wvW9mfYKSALHtGu'),
  AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-c6c4ad75-89ef-4b4f-9ca4-bd52ccb0729b-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-172-1"><a id="__codelineno-172-1" name="__codelineno-172-1" href="#__codelineno-172-1"></a>
</span></code></pre></div></p>
<h1 id="retrieve-the-latest-checkpoint-for-the-given-thread-id">Retrieve the latest checkpoint for the given thread ID<a class="headerlink" href="#retrieve-the-latest-checkpoint-for-the-given-thread-id" title="Permanent link">#</a></h1>
<h1 id="to-retrieve-a-specific-checkpoint-pass-the-checkpoint_id-in-the-config">To retrieve a specific checkpoint, pass the checkpoint_id in the config<a class="headerlink" href="#to-retrieve-a-specific-checkpoint-pass-the-checkpoint_id-in-the-config" title="Permanent link">#</a></h1>
<p>checkpointer.get_tuple(config)
<div class="language-text highlight"><pre><span></span><code><span id="__span-173-1"><a id="__codelineno-173-1" name="__codelineno-173-1" href="#__codelineno-173-1"></a>
</span></code></pre></div>
CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efb8c75-9262-68b4-8003-1ac1ef198757'}}, checkpoint={'v': 1, 'ts': '2024-12-12T20:26:20.545003+00:00', 'id': '1efb8c75-9262-68b4-8003-1ac1ef198757', 'channel_values': {'messages': [HumanMessage(content="What's the weather in sf?", additional_kwargs={}, response_metadata={}, id='4ce68bee-a843-4b08-9c02-7a0e3b010110'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MvGxq9IU9wvW9mfYKSALHtGu', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9712c5a4-376c-4812-a0c4-1b522334a59d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_MvGxq9IU9wvW9mfYKSALHtGu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content="It's always sunny in sf", name='get_weather', id='b4eed38d-bcaf-4497-ad08-f21ccd6a8c30', tool_call_id='call_MvGxq9IU9wvW9mfYKSALHtGu'), AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-c6c4ad75-89ef-4b4f-9ca4-bd52ccb0729b-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'agent': 'agent'}, 'channel_versions': {'<strong>start</strong>': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-c6c4ad75-89ef-4b4f-9ca4-bd52ccb0729b-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '2', 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1efb8c75-8d89-6ffe-8002-84a4312c4fed'}}, pending_writes=[])
<div class="language-text highlight"><pre><span></span><code><span id="__span-174-1"><a id="__codelineno-174-1" name="__codelineno-174-1" href="#__codelineno-174-1"></a>
</span></code></pre></div></p>
<h1 id="remember-to-close-the-connection-after-youre-done">Remember to close the connection after you're done<a class="headerlink" href="#remember-to-close-the-connection-after-youre-done" title="Permanent link">#</a></h1>
<p>mongodb_client.close()
<div class="language-text highlight"><pre><span></span><code><span id="__span-175-1"><a id="__codelineno-175-1" name="__codelineno-175-1" href="#__codelineno-175-1"></a>## Using an async connection
</span><span id="__span-175-2"><a id="__codelineno-175-2" name="__codelineno-175-2" href="#__codelineno-175-2"></a>This creates a short-lived asynchronous connection to MongoDB.
</span><span id="__span-175-3"><a id="__codelineno-175-3" name="__codelineno-175-3" href="#__codelineno-175-3"></a>
</span><span id="__span-175-4"><a id="__codelineno-175-4" name="__codelineno-175-4" href="#__codelineno-175-4"></a>Async connections allow non-blocking database operations. This means other parts of your application can continue running while waiting for database operations to complete. It&#39;s particularly useful in high-concurrency scenarios or when dealing with I/O-bound operations.
</span></code></pre></div>
from langgraph.checkpoint.mongodb.aio import AsyncMongoDBSaver</p>
<p>async with AsyncMongoDBSaver.from_conn_string(MONGODB_URI) as checkpointer:
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "3"}}
    response = await graph.ainvoke(
        {"messages": [("user", "What's the weather in sf?")]}, config
    )
<div class="language-text highlight"><pre><span></span><code><span id="__span-176-1"><a id="__codelineno-176-1" name="__codelineno-176-1" href="#__codelineno-176-1"></a>
</span></code></pre></div>
response
<div class="language-text highlight"><pre><span></span><code><span id="__span-177-1"><a id="__codelineno-177-1" name="__codelineno-177-1" href="#__codelineno-177-1"></a>
</span></code></pre></div>
{'messages': [HumanMessage(content="What's the weather in sf?", additional_kwargs={}, response_metadata={}, id='fed70fe6-1b2e-4481-9bfc-063df3b587dc'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_miRiF3vPQv98wlDHl6CeRxBy', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7f2d5153-973e-4a9e-8b71-a77625c342cf-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_miRiF3vPQv98wlDHl6CeRxBy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),
  ToolMessage(content="It's always sunny in sf", name='get_weather', id='49035e8e-8aee-4d9d-88ab-9a1bc10ecbd3', tool_call_id='call_miRiF3vPQv98wlDHl6CeRxBy'),
  AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-9403d502-391e-4407-99fd-eec8ed184e50-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-178-1"><a id="__codelineno-178-1" name="__codelineno-178-1" href="#__codelineno-178-1"></a>## Using the async MongoDB client
</span><span id="__span-178-2"><a id="__codelineno-178-2" name="__codelineno-178-2" href="#__codelineno-178-2"></a>This routes connections to MongoDB through an asynchronous MongoDB client.
</span></code></pre></div>
from pymongo import AsyncMongoClient</p>
<p>async_mongodb_client = AsyncMongoClient(MONGODB_URI)</p>
<p>checkpointer = AsyncMongoDBSaver(async_mongodb_client)
graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
config = {"configurable": {"thread_id": "4"}}
response = await graph.ainvoke(
    {"messages": [("user", "What's the weather in sf?")]}, config
)
<div class="language-text highlight"><pre><span></span><code><span id="__span-179-1"><a id="__codelineno-179-1" name="__codelineno-179-1" href="#__codelineno-179-1"></a>
</span></code></pre></div>
response
<div class="language-text highlight"><pre><span></span><code><span id="__span-180-1"><a id="__codelineno-180-1" name="__codelineno-180-1" href="#__codelineno-180-1"></a>
</span></code></pre></div>
{'messages': [HumanMessage(content="What's the weather in sf?", additional_kwargs={}, response_metadata={}, id='58282e2b-4cc1-40a1-8e65-420a2177bbd6'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SJFViVHl1tYTZDoZkNN3ePhJ', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-131af8c1-d388-4d7f-9137-da59ebd5fefd-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_SJFViVHl1tYTZDoZkNN3ePhJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),
  ToolMessage(content="It's always sunny in sf", name='get_weather', id='6090a56f-177b-4d3f-b16a-9c05f23800e3', tool_call_id='call_SJFViVHl1tYTZDoZkNN3ePhJ'),
  AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ff5ddf5-6e13-4126-8df9-81c8638355fc-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-181-1"><a id="__codelineno-181-1" name="__codelineno-181-1" href="#__codelineno-181-1"></a>
</span></code></pre></div></p>
<h1 id="retrieve-the-latest-checkpoint-for-the-given-thread-id_1">Retrieve the latest checkpoint for the given thread ID<a class="headerlink" href="#retrieve-the-latest-checkpoint-for-the-given-thread-id_1" title="Permanent link">#</a></h1>
<h1 id="to-retrieve-a-specific-checkpoint-pass-the-checkpoint_id-in-the-config_1">To retrieve a specific checkpoint, pass the checkpoint_id in the config<a class="headerlink" href="#to-retrieve-a-specific-checkpoint-pass-the-checkpoint_id-in-the-config_1" title="Permanent link">#</a></h1>
<p>latest_checkpoint = await checkpointer.aget_tuple(config)
print(latest_checkpoint)
<div class="language-text highlight"><pre><span></span><code><span id="__span-182-1"><a id="__codelineno-182-1" name="__codelineno-182-1" href="#__codelineno-182-1"></a>
</span></code></pre></div>
CheckpointTuple(config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1efb8c76-21f4-6d10-8003-9496e1754e93'}}, checkpoint={'v': 1, 'ts': '2024-12-12T20:26:35.599560+00:00', 'id': '1efb8c76-21f4-6d10-8003-9496e1754e93', 'channel_values': {'messages': [HumanMessage(content="What's the weather in sf?", additional_kwargs={}, response_metadata={}, id='58282e2b-4cc1-40a1-8e65-420a2177bbd6'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SJFViVHl1tYTZDoZkNN3ePhJ', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-131af8c1-d388-4d7f-9137-da59ebd5fefd-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_SJFViVHl1tYTZDoZkNN3ePhJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content="It's always sunny in sf", name='get_weather', id='6090a56f-177b-4d3f-b16a-9c05f23800e3', tool_call_id='call_SJFViVHl1tYTZDoZkNN3ePhJ'), AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ff5ddf5-6e13-4126-8df9-81c8638355fc-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'agent': 'agent'}, 'channel_versions': {'<strong>start</strong>': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ff5ddf5-6e13-4126-8df9-81c8638355fc-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '4', 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1efb8c76-1c6c-6474-8002-9c2595cd481c'}}, pending_writes=[])
<div class="language-text highlight"><pre><span></span><code><span id="__span-183-1"><a id="__codelineno-183-1" name="__codelineno-183-1" href="#__codelineno-183-1"></a>
</span></code></pre></div></p>
<h1 id="remember-to-close-the-connection-after-youre-done_1">Remember to close the connection after you're done<a class="headerlink" href="#remember-to-close-the-connection-after-youre-done_1" title="Permanent link">#</a></h1>
<p>await async_mongodb_client.close()
<div class="language-text highlight"><pre><span></span><code><span id="__span-184-1"><a id="__codelineno-184-1" name="__codelineno-184-1" href="#__codelineno-184-1"></a>## How to create a custom checkpointer using Redis
</span><span id="__span-184-2"><a id="__codelineno-184-2" name="__codelineno-184-2" href="#__codelineno-184-2"></a>When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions.
</span><span id="__span-184-3"><a id="__codelineno-184-3" name="__codelineno-184-3" href="#__codelineno-184-3"></a>
</span><span id="__span-184-4"><a id="__codelineno-184-4" name="__codelineno-184-4" href="#__codelineno-184-4"></a>This reference implementation shows how to use Redis as the backend for persisting checkpoint state. Make sure that you have Redis running on port 6379 for going through this guide.
</span><span id="__span-184-5"><a id="__codelineno-184-5" name="__codelineno-184-5" href="#__codelineno-184-5"></a>
</span><span id="__span-184-6"><a id="__codelineno-184-6" name="__codelineno-184-6" href="#__codelineno-184-6"></a>For demonstration purposes we add persistence to the pre-built create react agent.
</span><span id="__span-184-7"><a id="__codelineno-184-7" name="__codelineno-184-7" href="#__codelineno-184-7"></a>
</span><span id="__span-184-8"><a id="__codelineno-184-8" name="__codelineno-184-8" href="#__codelineno-184-8"></a>In general, you can add a checkpointer to any custom graph that you build like this:
</span></code></pre></div>
from langgraph.graph import StateGraph</p>
<p>builder = StateGraph(....)</p>
<h1 id="define-the-graph_3">... define the graph<a class="headerlink" href="#define-the-graph_3" title="Permanent link">#</a></h1>
<p>checkpointer = # redis checkpointer (see examples below)
graph = builder.compile(checkpointer=checkpointer)
...
<div class="language-text highlight"><pre><span></span><code><span id="__span-185-1"><a id="__codelineno-185-1" name="__codelineno-185-1" href="#__codelineno-185-1"></a>## Setup
</span><span id="__span-185-2"><a id="__codelineno-185-2" name="__codelineno-185-2" href="#__codelineno-185-2"></a>First, let&#39;s install the required packages and set our API keys
</span></code></pre></div>
%%capture --no-stderr
%pip install -U redis langgraph langchain_openai
<div class="language-text highlight"><pre><span></span><code><span id="__span-186-1"><a id="__codelineno-186-1" name="__codelineno-186-1" href="#__codelineno-186-1"></a>
</span></code></pre></div>
import getpass
import os</p>
<p>def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")</p>
<p>_set_env("OPENAI_API_KEY")
<div class="language-text highlight"><pre><span></span><code><span id="__span-187-1"><a id="__codelineno-187-1" name="__codelineno-187-1" href="#__codelineno-187-1"></a>## Checkpointer implementation
</span><span id="__span-187-2"><a id="__codelineno-187-2" name="__codelineno-187-2" href="#__codelineno-187-2"></a>## Define imports and helper functions
</span><span id="__span-187-3"><a id="__codelineno-187-3" name="__codelineno-187-3" href="#__codelineno-187-3"></a>
</span><span id="__span-187-4"><a id="__codelineno-187-4" name="__codelineno-187-4" href="#__codelineno-187-4"></a>First, let&#39;s define some imports and shared utilities for both RedisSaver and AsyncRedisSaver
</span></code></pre></div>
"""Implementation of a langgraph checkpoint saver using Redis."""
from contextlib import asynccontextmanager, contextmanager
from typing import (
    Any,
    AsyncGenerator,
    AsyncIterator,
    Iterator,
    List,
    Optional,
    Tuple,
)</p>
<p>from langchain_core.runnables import RunnableConfig</p>
<p>from langgraph.checkpoint.base import (
    WRITES_IDX_MAP,
    BaseCheckpointSaver,
    ChannelVersions,
    Checkpoint,
    CheckpointMetadata,
    CheckpointTuple,
    PendingWrite,
    get_checkpoint_id,
)
from langgraph.checkpoint.serde.base import SerializerProtocol
from redis import Redis
from redis.asyncio import Redis as AsyncRedis</p>
<p>REDIS_KEY_SEPARATOR = "$"</p>
<h1 id="utilities-shared-by-both-redissaver-and-asyncredissaver">Utilities shared by both RedisSaver and AsyncRedisSaver<a class="headerlink" href="#utilities-shared-by-both-redissaver-and-asyncredissaver" title="Permanent link">#</a></h1>
<p>def _make_redis_checkpoint_key(
    thread_id: str, checkpoint_ns: str, checkpoint_id: str
) -&gt; str:
    return REDIS_KEY_SEPARATOR.join(
        ["checkpoint", thread_id, checkpoint_ns, checkpoint_id]
    )</p>
<p>def _make_redis_checkpoint_writes_key(
    thread_id: str,
    checkpoint_ns: str,
    checkpoint_id: str,
    task_id: str,
    idx: Optional[int],
) -&gt; str:
    if idx is None:
        return REDIS_KEY_SEPARATOR.join(
            ["writes", thread_id, checkpoint_ns, checkpoint_id, task_id]
        )</p>
<div class="language-text highlight"><pre><span></span><code>return REDIS_KEY_SEPARATOR.join(
    [&quot;writes&quot;, thread_id, checkpoint_ns, checkpoint_id, task_id, str(idx)]
)
</code></pre></div>
<p>def _parse_redis_checkpoint_key(redis_key: str) -&gt; dict:
    namespace, thread_id, checkpoint_ns, checkpoint_id = redis_key.split(
        REDIS_KEY_SEPARATOR
    )
    if namespace != "checkpoint":
        raise ValueError("Expected checkpoint key to start with 'checkpoint'")</p>
<div class="language-text highlight"><pre><span></span><code>return {
    &quot;thread_id&quot;: thread_id,
    &quot;checkpoint_ns&quot;: checkpoint_ns,
    &quot;checkpoint_id&quot;: checkpoint_id,
}
</code></pre></div>
<p>def _parse_redis_checkpoint_writes_key(redis_key: str) -&gt; dict:
    namespace, thread_id, checkpoint_ns, checkpoint_id, task_id, idx = redis_key.split(
        REDIS_KEY_SEPARATOR
    )
    if namespace != "writes":
        raise ValueError("Expected checkpoint key to start with 'checkpoint'")</p>
<div class="language-text highlight"><pre><span></span><code>return {
    &quot;thread_id&quot;: thread_id,
    &quot;checkpoint_ns&quot;: checkpoint_ns,
    &quot;checkpoint_id&quot;: checkpoint_id,
    &quot;task_id&quot;: task_id,
    &quot;idx&quot;: idx,
}
</code></pre></div>
<p>def _filter_keys(
    keys: List[str], before: Optional[RunnableConfig], limit: Optional[int]
) -&gt; list:
    """Filter and sort Redis keys based on optional criteria."""
    if before:
        keys = [
            k
            for k in keys
            if _parse_redis_checkpoint_key(k.decode())["checkpoint_id"]
            &lt; before["configurable"]["checkpoint_id"]
        ]</p>
<div class="language-text highlight"><pre><span></span><code>keys = sorted(
    keys,
    key=lambda k: _parse_redis_checkpoint_key(k.decode())[&quot;checkpoint_id&quot;],
    reverse=True,
)
if limit:
    keys = keys[:limit]
return keys
</code></pre></div>
<p>def <em>load_writes(
    serde: SerializerProtocol, task_id_to_data: dict[tuple[str, str], dict]
) -&gt; list[PendingWrite]:
    """Deserialize pending writes."""
    writes = [
        (
            task_id,
            data[b"channel"].decode(),
            serde.loads_typed((data[b"type"].decode(), data[b"value"])),
        )
        for (task_id, </em>), data in task_id_to_data.items()
    ]
    return writes</p>
<p>def _parse_redis_checkpoint_data(
    serde: SerializerProtocol,
    key: str,
    data: dict,
    pending_writes: Optional[List[PendingWrite]] = None,
) -&gt; Optional[CheckpointTuple]:
    """Parse checkpoint data retrieved from Redis."""
    if not data:
        return None</p>
<div class="language-text highlight"><pre><span></span><code>parsed_key = _parse_redis_checkpoint_key(key)
thread_id = parsed_key[&quot;thread_id&quot;]
checkpoint_ns = parsed_key[&quot;checkpoint_ns&quot;]
checkpoint_id = parsed_key[&quot;checkpoint_id&quot;]
config = {
    &quot;configurable&quot;: {
        &quot;thread_id&quot;: thread_id,
        &quot;checkpoint_ns&quot;: checkpoint_ns,
        &quot;checkpoint_id&quot;: checkpoint_id,
    }
}

checkpoint = serde.loads_typed((data[b&quot;type&quot;].decode(), data[b&quot;checkpoint&quot;]))
metadata = serde.loads(data[b&quot;metadata&quot;].decode())
parent_checkpoint_id = data.get(b&quot;parent_checkpoint_id&quot;, b&quot;&quot;).decode()
parent_config = (
    {
        &quot;configurable&quot;: {
            &quot;thread_id&quot;: thread_id,
            &quot;checkpoint_ns&quot;: checkpoint_ns,
            &quot;checkpoint_id&quot;: parent_checkpoint_id,
        }
    }
    if parent_checkpoint_id
    else None
)
return CheckpointTuple(
    config=config,
    checkpoint=checkpoint,
    metadata=metadata,
    parent_config=parent_config,
    pending_writes=pending_writes,
)
</code></pre></div>
<p>```
</p>
<h2 id="redissaver">RedisSaver<a class="headerlink" href="#redissaver" title="Permanent link">#</a></h2>
<p>Below is an implementation of RedisSaver (for synchronous use of graph, i.e. .invoke(), .stream()). RedisSaver implements four methods that are required for any checkpointer:

- .put - Store a checkpoint with its configuration and metadata.
- .put_writes - Store intermediate writes linked to a checkpoint (i.e. pending writes).
- .get_tuple - Fetch a checkpoint tuple using for a given configuration (thread_id and checkpoint_id).
- .list - List checkpoints that match a given configuration and filter criteria.


```
class RedisSaver(BaseCheckpointSaver):
    """Redis-based checkpoint saver implementation."""</p>
<div class="language-text highlight"><pre><span></span><code>conn: Redis

def __init__(self, conn: Redis):
    super().__init__()
    self.conn = conn

@classmethod
@contextmanager
def from_conn_info(cls, *, host: str, port: int, db: int) -&gt; Iterator[&quot;RedisSaver&quot;]:
    conn = None
    try:
        conn = Redis(host=host, port=port, db=db)
        yield RedisSaver(conn)
    finally:
        if conn:
            conn.close()

def put(
    self,
    config: RunnableConfig,
    checkpoint: Checkpoint,
    metadata: CheckpointMetadata,
    new_versions: ChannelVersions,
) -&gt; RunnableConfig:
    &quot;&quot;&quot;Save a checkpoint to Redis.

    Args:
        config (RunnableConfig): The config to associate with the checkpoint.
        checkpoint (Checkpoint): The checkpoint to save.
        metadata (CheckpointMetadata): Additional metadata to save with the checkpoint.
        new_versions (ChannelVersions): New channel versions as of this write.

    Returns:
        RunnableConfig: Updated configuration after storing the checkpoint.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;][&quot;checkpoint_ns&quot;]
    checkpoint_id = checkpoint[&quot;id&quot;]
    parent_checkpoint_id = config[&quot;configurable&quot;].get(&quot;checkpoint_id&quot;)
    key = _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

    type_, serialized_checkpoint = self.serde.dumps_typed(checkpoint)
    serialized_metadata = self.serde.dumps(metadata)
    data = {
        &quot;checkpoint&quot;: serialized_checkpoint,
        &quot;type&quot;: type_,
        &quot;metadata&quot;: serialized_metadata,
        &quot;parent_checkpoint_id&quot;: parent_checkpoint_id
        if parent_checkpoint_id
        else &quot;&quot;,
    }
    self.conn.hset(key, mapping=data)
    return {
        &quot;configurable&quot;: {
            &quot;thread_id&quot;: thread_id,
            &quot;checkpoint_ns&quot;: checkpoint_ns,
            &quot;checkpoint_id&quot;: checkpoint_id,
        }
    }

def put_writes(
    self,
    config: RunnableConfig,
    writes: List[Tuple[str, Any]],
    task_id: str,
) -&gt; None:
    &quot;&quot;&quot;Store intermediate writes linked to a checkpoint.

    Args:
        config (RunnableConfig): Configuration of the related checkpoint.
        writes (Sequence[Tuple[str, Any]]): List of writes to store, each as (channel, value) pair.
        task_id (str): Identifier for the task creating the writes.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;][&quot;checkpoint_ns&quot;]
    checkpoint_id = config[&quot;configurable&quot;][&quot;checkpoint_id&quot;]

    for idx, (channel, value) in enumerate(writes):
        key = _make_redis_checkpoint_writes_key(
            thread_id,
            checkpoint_ns,
            checkpoint_id,
            task_id,
            WRITES_IDX_MAP.get(channel, idx),
        )
        type_, serialized_value = self.serde.dumps_typed(value)
        data = {&quot;channel&quot;: channel, &quot;type&quot;: type_, &quot;value&quot;: serialized_value}
        if all(w[0] in WRITES_IDX_MAP for w in writes):
            # Use HSET which will overwrite existing values
            self.conn.hset(key, mapping=data)
        else:
            # Use HSETNX which will not overwrite existing values
            for field, value in data.items():
                self.conn.hsetnx(key, field, value)

def get_tuple(self, config: RunnableConfig) -&gt; Optional[CheckpointTuple]:
    &quot;&quot;&quot;Get a checkpoint tuple from Redis.

    This method retrieves a checkpoint tuple from Redis based on the
    provided config. If the config contains a &quot;checkpoint_id&quot; key, the checkpoint with
    the matching thread ID and checkpoint ID is retrieved. Otherwise, the latest checkpoint
    for the given thread ID is retrieved.

    Args:
        config (RunnableConfig): The config to use for retrieving the checkpoint.

    Returns:
        Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_id = get_checkpoint_id(config)
    checkpoint_ns = config[&quot;configurable&quot;].get(&quot;checkpoint_ns&quot;, &quot;&quot;)

    checkpoint_key = self._get_checkpoint_key(
        self.conn, thread_id, checkpoint_ns, checkpoint_id
    )
    if not checkpoint_key:
        return None

    checkpoint_data = self.conn.hgetall(checkpoint_key)

    # load pending writes
    checkpoint_id = (
        checkpoint_id
        or _parse_redis_checkpoint_key(checkpoint_key)[&quot;checkpoint_id&quot;]
    )
    pending_writes = self._load_pending_writes(
        thread_id, checkpoint_ns, checkpoint_id
    )
    return _parse_redis_checkpoint_data(
        self.serde, checkpoint_key, checkpoint_data, pending_writes=pending_writes
    )

def list(
    self,
    config: Optional[RunnableConfig],
    *,
    # TODO: implement filtering
    filter: Optional[dict[str, Any]] = None,
    before: Optional[RunnableConfig] = None,
    limit: Optional[int] = None,
) -&gt; Iterator[CheckpointTuple]:
    &quot;&quot;&quot;List checkpoints from the database.

    This method retrieves a list of checkpoint tuples from Redis based
    on the provided config. The checkpoints are ordered by checkpoint ID in descending order (newest first).

    Args:
        config (RunnableConfig): The config to use for listing the checkpoints.
        filter (Optional[Dict[str, Any]]): Additional filtering criteria for metadata. Defaults to None.
        before (Optional[RunnableConfig]): If provided, only checkpoints before the specified checkpoint ID are returned. Defaults to None.
        limit (Optional[int]): The maximum number of checkpoints to return. Defaults to None.

    Yields:
        Iterator[CheckpointTuple]: An iterator of checkpoint tuples.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;].get(&quot;checkpoint_ns&quot;, &quot;&quot;)
    pattern = _make_redis_checkpoint_key(thread_id, checkpoint_ns, &quot;*&quot;)

    keys = _filter_keys(self.conn.keys(pattern), before, limit)
    for key in keys:
        data = self.conn.hgetall(key)
        if data and b&quot;checkpoint&quot; in data and b&quot;metadata&quot; in data:
            # load pending writes
            checkpoint_id = _parse_redis_checkpoint_key(key.decode())[
                &quot;checkpoint_id&quot;
            ]
            pending_writes = self._load_pending_writes(
                thread_id, checkpoint_ns, checkpoint_id
            )
            yield _parse_redis_checkpoint_data(
                self.serde, key.decode(), data, pending_writes=pending_writes
            )

def _load_pending_writes(
    self, thread_id: str, checkpoint_ns: str, checkpoint_id: str
) -&gt; List[PendingWrite]:
    writes_key = _make_redis_checkpoint_writes_key(
        thread_id, checkpoint_ns, checkpoint_id, &quot;*&quot;, None
    )
    matching_keys = self.conn.keys(pattern=writes_key)
    parsed_keys = [
        _parse_redis_checkpoint_writes_key(key.decode()) for key in matching_keys
    ]
    pending_writes = _load_writes(
        self.serde,
        {
            (parsed_key[&quot;task_id&quot;], parsed_key[&quot;idx&quot;]): self.conn.hgetall(key)
            for key, parsed_key in sorted(
                zip(matching_keys, parsed_keys), key=lambda x: x[1][&quot;idx&quot;]
            )
        },
    )
    return pending_writes

def _get_checkpoint_key(
    self, conn, thread_id: str, checkpoint_ns: str, checkpoint_id: Optional[str]
) -&gt; Optional[str]:
    &quot;&quot;&quot;Determine the Redis key for a checkpoint.&quot;&quot;&quot;
    if checkpoint_id:
        return _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

    all_keys = conn.keys(_make_redis_checkpoint_key(thread_id, checkpoint_ns, &quot;*&quot;))
    if not all_keys:
        return None

    latest_key = max(
        all_keys,
        key=lambda k: _parse_redis_checkpoint_key(k.decode())[&quot;checkpoint_id&quot;],
    )
    return latest_key.decode()
</code></pre></div>
<p>```
</p>
<h2 id="asyncredis">AsyncRedis<a class="headerlink" href="#asyncredis" title="Permanent link">#</a></h2>
<p>Below is a reference implementation of AsyncRedisSaver (for asynchronous use of graph, i.e. .ainvoke(), .astream()). AsyncRedisSaver implements four methods that are required for any async checkpointer:

- .aput - Store a checkpoint with its configuration and metadata.
- .aput_writes - Store intermediate writes linked to a checkpoint (i.e. pending writes).
- .aget_tuple - Fetch a checkpoint tuple using for a given configuration (thread_id and checkpoint_id).
- .alist - List checkpoints that match a given configuration and filter criteria.

```
class AsyncRedisSaver(BaseCheckpointSaver):
    """Async redis-based checkpoint saver implementation."""</p>
<div class="language-text highlight"><pre><span></span><code>conn: AsyncRedis

def __init__(self, conn: AsyncRedis):
    super().__init__()
    self.conn = conn

@classmethod
@asynccontextmanager
async def from_conn_info(
    cls, *, host: str, port: int, db: int
) -&gt; AsyncIterator[&quot;AsyncRedisSaver&quot;]:
    conn = None
    try:
        conn = AsyncRedis(host=host, port=port, db=db)
        yield AsyncRedisSaver(conn)
    finally:
        if conn:
            await conn.aclose()

async def aput(
    self,
    config: RunnableConfig,
    checkpoint: Checkpoint,
    metadata: CheckpointMetadata,
    new_versions: ChannelVersions,
) -&gt; RunnableConfig:
    &quot;&quot;&quot;Save a checkpoint to the database asynchronously.

    This method saves a checkpoint to Redis. The checkpoint is associated
    with the provided config and its parent config (if any).

    Args:
        config (RunnableConfig): The config to associate with the checkpoint.
        checkpoint (Checkpoint): The checkpoint to save.
        metadata (CheckpointMetadata): Additional metadata to save with the checkpoint.
        new_versions (ChannelVersions): New channel versions as of this write.

    Returns:
        RunnableConfig: Updated configuration after storing the checkpoint.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;][&quot;checkpoint_ns&quot;]
    checkpoint_id = checkpoint[&quot;id&quot;]
    parent_checkpoint_id = config[&quot;configurable&quot;].get(&quot;checkpoint_id&quot;)
    key = _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

    type_, serialized_checkpoint = self.serde.dumps_typed(checkpoint)
    serialized_metadata = self.serde.dumps(metadata)
    data = {
        &quot;checkpoint&quot;: serialized_checkpoint,
        &quot;type&quot;: type_,
        &quot;checkpoint_id&quot;: checkpoint_id,
        &quot;metadata&quot;: serialized_metadata,
        &quot;parent_checkpoint_id&quot;: parent_checkpoint_id
        if parent_checkpoint_id
        else &quot;&quot;,
    }

    await self.conn.hset(key, mapping=data)
    return {
        &quot;configurable&quot;: {
            &quot;thread_id&quot;: thread_id,
            &quot;checkpoint_ns&quot;: checkpoint_ns,
            &quot;checkpoint_id&quot;: checkpoint_id,
        }
    }

async def aput_writes(
    self,
    config: RunnableConfig,
    writes: List[Tuple[str, Any]],
    task_id: str,
) -&gt; None:
    &quot;&quot;&quot;Store intermediate writes linked to a checkpoint asynchronously.

    This method saves intermediate writes associated with a checkpoint to the database.

    Args:
        config (RunnableConfig): Configuration of the related checkpoint.
        writes (Sequence[Tuple[str, Any]]): List of writes to store, each as (channel, value) pair.
        task_id (str): Identifier for the task creating the writes.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;][&quot;checkpoint_ns&quot;]
    checkpoint_id = config[&quot;configurable&quot;][&quot;checkpoint_id&quot;]

    for idx, (channel, value) in enumerate(writes):
        key = _make_redis_checkpoint_writes_key(
            thread_id,
            checkpoint_ns,
            checkpoint_id,
            task_id,
            WRITES_IDX_MAP.get(channel, idx),
        )
        type_, serialized_value = self.serde.dumps_typed(value)
        data = {&quot;channel&quot;: channel, &quot;type&quot;: type_, &quot;value&quot;: serialized_value}
        if all(w[0] in WRITES_IDX_MAP for w in writes):
            # Use HSET which will overwrite existing values
            await self.conn.hset(key, mapping=data)
        else:
            # Use HSETNX which will not overwrite existing values
            for field, value in data.items():
                await self.conn.hsetnx(key, field, value)

async def aget_tuple(self, config: RunnableConfig) -&gt; Optional[CheckpointTuple]:
    &quot;&quot;&quot;Get a checkpoint tuple from Redis asynchronously.

    This method retrieves a checkpoint tuple from Redis based on the
    provided config. If the config contains a &quot;checkpoint_id&quot; key, the checkpoint with
    the matching thread ID and checkpoint ID is retrieved. Otherwise, the latest checkpoint
    for the given thread ID is retrieved.

    Args:
        config (RunnableConfig): The config to use for retrieving the checkpoint.

    Returns:
        Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_id = get_checkpoint_id(config)
    checkpoint_ns = config[&quot;configurable&quot;].get(&quot;checkpoint_ns&quot;, &quot;&quot;)

    checkpoint_key = await self._aget_checkpoint_key(
        self.conn, thread_id, checkpoint_ns, checkpoint_id
    )
    if not checkpoint_key:
        return None
    checkpoint_data = await self.conn.hgetall(checkpoint_key)

    # load pending writes
    checkpoint_id = (
        checkpoint_id
        or _parse_redis_checkpoint_key(checkpoint_key)[&quot;checkpoint_id&quot;]
    )
    pending_writes = await self._aload_pending_writes(
        thread_id, checkpoint_ns, checkpoint_id
    )
    return _parse_redis_checkpoint_data(
        self.serde, checkpoint_key, checkpoint_data, pending_writes=pending_writes
    )

async def alist(
    self,
    config: Optional[RunnableConfig],
    *,
    # TODO: implement filtering
    filter: Optional[dict[str, Any]] = None,
    before: Optional[RunnableConfig] = None,
    limit: Optional[int] = None,
) -&gt; AsyncGenerator[CheckpointTuple, None]:
    &quot;&quot;&quot;List checkpoints from Redis asynchronously.

    This method retrieves a list of checkpoint tuples from Redis based
    on the provided config. The checkpoints are ordered by checkpoint ID in descending order (newest first).

    Args:
        config (Optional[RunnableConfig]): Base configuration for filtering checkpoints.
        filter (Optional[Dict[str, Any]]): Additional filtering criteria for metadata.
        before (Optional[RunnableConfig]): If provided, only checkpoints before the specified checkpoint ID are returned. Defaults to None.
        limit (Optional[int]): Maximum number of checkpoints to return.

    Yields:
        AsyncIterator[CheckpointTuple]: An asynchronous iterator of matching checkpoint tuples.
    &quot;&quot;&quot;
    thread_id = config[&quot;configurable&quot;][&quot;thread_id&quot;]
    checkpoint_ns = config[&quot;configurable&quot;].get(&quot;checkpoint_ns&quot;, &quot;&quot;)
    pattern = _make_redis_checkpoint_key(thread_id, checkpoint_ns, &quot;*&quot;)
    keys = _filter_keys(await self.conn.keys(pattern), before, limit)
    for key in keys:
        data = await self.conn.hgetall(key)
        if data and b&quot;checkpoint&quot; in data and b&quot;metadata&quot; in data:
            checkpoint_id = _parse_redis_checkpoint_key(key.decode())[
                &quot;checkpoint_id&quot;
            ]
            pending_writes = await self._aload_pending_writes(
                thread_id, checkpoint_ns, checkpoint_id
            )
            yield _parse_redis_checkpoint_data(
                self.serde, key.decode(), data, pending_writes=pending_writes
            )

async def _aload_pending_writes(
    self, thread_id: str, checkpoint_ns: str, checkpoint_id: str
) -&gt; List[PendingWrite]:
    writes_key = _make_redis_checkpoint_writes_key(
        thread_id, checkpoint_ns, checkpoint_id, &quot;*&quot;, None
    )
    matching_keys = await self.conn.keys(pattern=writes_key)
    parsed_keys = [
        _parse_redis_checkpoint_writes_key(key.decode()) for key in matching_keys
    ]
    pending_writes = _load_writes(
        self.serde,
        {
            (parsed_key[&quot;task_id&quot;], parsed_key[&quot;idx&quot;]): await self.conn.hgetall(key)
            for key, parsed_key in sorted(
                zip(matching_keys, parsed_keys), key=lambda x: x[1][&quot;idx&quot;]
            )
        },
    )
    return pending_writes

async def _aget_checkpoint_key(
    self, conn, thread_id: str, checkpoint_ns: str, checkpoint_id: Optional[str]
) -&gt; Optional[str]:
    &quot;&quot;&quot;Asynchronously determine the Redis key for a checkpoint.&quot;&quot;&quot;
    if checkpoint_id:
        return _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

    all_keys = await conn.keys(
        _make_redis_checkpoint_key(thread_id, checkpoint_ns, &quot;*&quot;)
    )
    if not all_keys:
        return None

    latest_key = max(
        all_keys,
        key=lambda k: _parse_redis_checkpoint_key(k.decode())[&quot;checkpoint_id&quot;],
    )
    return latest_key.decode()
</code></pre></div>
<p>```
</p>
<h2 id="setup-model-and-tools-for-the-graph">Setup model and tools for the graph<a class="headerlink" href="#setup-model-and-tools-for-the-graph" title="Permanent link">#</a></h2>
<p>```
from typing import Literal
from langchain_core.runnables import ConfigurableField
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent</p>
<p>@tool
def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in nyc"
    elif city == "sf":
        return "It's always sunny in sf"
    else:
        raise AssertionError("Unknown city")</p>
<p>tools = [get_weather]
model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
<div class="language-text highlight"><pre><span></span><code><span id="__span-191-1"><a id="__codelineno-191-1" name="__codelineno-191-1" href="#__codelineno-191-1"></a>## Use sync connection
</span></code></pre></div>
with RedisSaver.from_conn_info(host="localhost", port=6379, db=0) as checkpointer:
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "1"}}
    res = graph.invoke({"messages": [("human", "what's the weather in sf")]}, config)</p>
<div class="language-text highlight"><pre><span></span><code>latest_checkpoint = checkpointer.get(config)
latest_checkpoint_tuple = checkpointer.get_tuple(config)
checkpoint_tuples = list(checkpointer.list(config))
</code></pre></div>
<p><code></code>
latest_checkpoint
<code></code>
{'v': 1,
 'ts': '2024-08-09T01:56:48.328315+00:00',
 'id': '1ef55f2a-3614-69b4-8003-2181cff935cc',
 'channel_values': {'messages': [HumanMessage(content="what's the weather in sf", id='f911e000-75a1-41f6-8e38-77bb086c2ecf'),
   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_l5e5YcTJDJYOdvi4scBy9n2I', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4f1531f1-067c-4e16-8b62-7a6b663e93bd-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_l5e5YcTJDJYOdvi4scBy9n2I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),
   ToolMessage(content="It's always sunny in sf", name='get_weather', id='e27bb3a1-1798-494a-b4ad-2deadda8b2bf', tool_call_id='call_l5e5YcTJDJYOdvi4scBy9n2I'),
   AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-ad546b5a-70ce-404e-9656-dcc6ecd482d3-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})],
  'agent': 'agent'},
 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.',
  'messages': '00000000000000000000000000000005.16e98d6f7ece7598829eddf1b33a33c4',
  'start:agent': '00000000000000000000000000000003.',
  'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af',
  'branch:agent:should_continue:tools': '00000000000000000000000000000004.',
  'tools': '00000000000000000000000000000005.'},
 'versions_seen': {'<strong>input</strong>': {},
  '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033'},
  'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc',
   'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'},
  'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}},
 'pending_sends': [],
 'current_tasks': {}}
<code></code>
latest_checkpoint_tuple
<code></code>
CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3614-69b4-8003-2181cff935cc'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:48.328315+00:00', 'id': '1ef55f2a-3614-69b4-8003-2181cff935cc', 'channel_values': {'messages': [HumanMessage(content="what's the weather in sf", id='f911e000-75a1-41f6-8e38-77bb086c2ecf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_l5e5YcTJDJYOdvi4scBy9n2I', 'function': {'arguments': '{"city":"sf"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4f1531f1-067c-4e16-8b62-7a6b663e93bd-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_l5e5YcTJDJYOdvi4scBy9n2I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content="It's always sunny in sf", name='get_weather', id='e27bb3a1-1798-494a-b4ad-2deadda8b2bf', tool_call_id='call_l5e5YcTJDJYOdvi4scBy9n2I'), AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-ad546b5a-70ce-404e-9656-dcc6ecd482d3-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'agent': 'agent'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000005.16e98d6f7ece7598829eddf1b33a33c4', 'start:agent': '00000000000000000000000000000003.', 'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af', 'branch:agent:should_continue:tools': '00000000000000000000000000000004.', 'tools': '00000000000000000000000000000005.'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.ab89befb52cc0e91e106ef7f500ea033'}, 'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc', 'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'}, 'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-ad546b5a-70ce-404e-9656-dcc6ecd482d3-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}, 'step': 3}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-306f-6252-8002-47c2374ec1f2'}}, pending_writes=[])
```
</p>
<h2 id="use-async-connection">Use async connection<a class="headerlink" href="#use-async-connection" title="Permanent link">#</a></h2>
<p>```
async with AsyncRedisSaver.from_conn_info(
    host="localhost", port=6379, db=0
) as checkpointer:
    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)
    config = {"configurable": {"thread_id": "2"}}
    res = await graph.ainvoke(
        {"messages": [("human", "what's the weather in nyc")]}, config
    )</p>
<div class="language-text highlight"><pre><span></span><code>latest_checkpoint = await checkpointer.aget(config)
latest_checkpoint_tuple = await checkpointer.aget_tuple(config)
checkpoint_tuples = [c async for c in checkpointer.alist(config)]
</code></pre></div>
<p><code></code>
latest_checkpoint
<code></code>
{'v': 1,
 'ts': '2024-08-09T01:56:49.503241+00:00',
 'id': '1ef55f2a-4149-61ea-8003-dc5506862287',
 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a'),
   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}),
   ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='922124bd-d3b0-4929-a996-a75d842b8b44', tool_call_id='call_TvPLLyhuQQN99EcZc8SzL8x9'),
   AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-69a10e66-d61f-475e-b7de-a1ecd08a6c3a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})],
  'agent': 'agent'},
 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.',
  'messages': '00000000000000000000000000000005.2cb29d082da6435a7528b4c917fd0c28',
  'start:agent': '00000000000000000000000000000003.',
  'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af',
  'branch:agent:should_continue:tools': '00000000000000000000000000000004.',
  'tools': '00000000000000000000000000000005.'},
 'versions_seen': {'<strong>input</strong>': {},
  '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'},
  'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc',
   'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'},
  'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}},
 'pending_sends': [],
 'current_tasks': {}}
 <code></code>
 latest_checkpoint_tuple
 <code></code>
 CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-4149-61ea-8003-dc5506862287'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:49.503241+00:00', 'id': '1ef55f2a-4149-61ea-8003-dc5506862287', 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='922124bd-d3b0-4929-a996-a75d842b8b44', tool_call_id='call_TvPLLyhuQQN99EcZc8SzL8x9'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-69a10e66-d61f-475e-b7de-a1ecd08a6c3a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000005.2cb29d082da6435a7528b4c917fd0c28', 'start:agent': '00000000000000000000000000000003.', 'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af', 'branch:agent:should_continue:tools': '00000000000000000000000000000004.', 'tools': '00000000000000000000000000000005.'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}, 'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc', 'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'}, 'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-69a10e66-d61f-475e-b7de-a1ecd08a6c3a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}, 'step': 3}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3d07-647e-8002-b5e4d28c00c9'}}, pending_writes=[])
 <code></code>
 checkpoint_tuples
 <code></code>
 [CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-4149-61ea-8003-dc5506862287'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:49.503241+00:00', 'id': '1ef55f2a-4149-61ea-8003-dc5506862287', 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='922124bd-d3b0-4929-a996-a75d842b8b44', tool_call_id='call_TvPLLyhuQQN99EcZc8SzL8x9'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-69a10e66-d61f-475e-b7de-a1ecd08a6c3a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000005.2cb29d082da6435a7528b4c917fd0c28', 'start:agent': '00000000000000000000000000000003.', 'agent': '00000000000000000000000000000005.065d90dd7f7cd091f0233855210bb2af', 'branch:agent:should_continue:tools': '00000000000000000000000000000004.', 'tools': '00000000000000000000000000000005.'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}, 'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc', 'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'}, 'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-69a10e66-d61f-475e-b7de-a1ecd08a6c3a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}, 'step': 3}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3d07-647e-8002-b5e4d28c00c9'}}, pending_writes=None),
 CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3d07-647e-8002-b5e4d28c00c9'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:49.056860+00:00', 'id': '1ef55f2a-3d07-647e-8002-b5e4d28c00c9', 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='922124bd-d3b0-4929-a996-a75d842b8b44', tool_call_id='call_TvPLLyhuQQN99EcZc8SzL8x9')], 'tools': 'tools'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000004.07964a3a545f9ff95545db45a9753d11', 'start:agent': '00000000000000000000000000000003.', 'agent': '00000000000000000000000000000004.', 'branch:agent:should_continue:tools': '00000000000000000000000000000004.', 'tools': '00000000000000000000000000000004.022986cd20ae85c77ea298a383f69ba8'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}, 'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc'}, 'tools': {'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'tools': {'messages': [ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='922124bd-d3b0-4929-a996-a75d842b8b44', tool_call_id='call_TvPLLyhuQQN99EcZc8SzL8x9')]}}, 'step': 2}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3cf9-6996-8001-88dab066840d'}}, pending_writes=None),
 CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-3cf9-6996-8001-88dab066840d'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:49.051234+00:00', 'id': '1ef55f2a-3cf9-6996-8001-88dab066840d', 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000003.cc96d93b1afbd1b69d53851320670b97', 'start:agent': '00000000000000000000000000000003.', 'agent': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af', 'branch:agent:should_continue:tools': '00000000000000000000000000000003.065d90dd7f7cd091f0233855210bb2af'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}, 'agent': {'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'function': {'arguments': '{"city":"nyc"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d6fa3b4-cace-41a8-b025-d01d16f6bbe9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_TvPLLyhuQQN99EcZc8SzL8x9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})]}}, 'step': 1}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-36a6-6788-8000-9efe1769f8c1'}}, pending_writes=None),
 CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-36a6-6788-8000-9efe1769f8c1'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:48.388067+00:00', 'id': '1ef55f2a-36a6-6788-8000-9efe1769f8c1', 'channel_values': {'messages': [HumanMessage(content="what's the weather in nyc", id='5a106e79-a617-4707-839f-134d4e4b762a')], 'start:agent': '<strong>start</strong>'}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000002.', 'messages': '00000000000000000000000000000002.a6994b785a651d88df51020401745af8', 'start:agent': '00000000000000000000000000000002.d6f25946c3108fc12f27abbcf9b4cedc'}, 'versions_seen': {'<strong>input</strong>': {}, '<strong>start</strong>': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': None, 'step': 0}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-36a3-6614-bfff-05dafa02b4d7'}}, pending_writes=None),
 CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef55f2a-36a3-6614-bfff-05dafa02b4d7'}}, checkpoint={'v': 1, 'ts': '2024-08-09T01:56:48.386807+00:00', 'id': '1ef55f2a-36a3-6614-bfff-05dafa02b4d7', 'channel_values': {'messages': [], '<strong>start</strong>': {'messages': [['human', "what's the weather in nyc"]]}}, 'channel_versions': {'<strong>start</strong>': '00000000000000000000000000000001.0e148ae3debe753278387e84f786e863'}, 'versions_seen': {'<strong>input</strong>': {}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'input', 'writes': {'messages': [['human', "what's the weather in nyc"]]}, 'step': -1}, parent_config=None, pending_writes=None)]
 ```</p>
<p># How to add thread-level persistence (functional API)
 Many AI applications need memory to share context across multiple interactions on the same thread (e.g., multiple turns of a conversation). In LangGraph functional API, this kind of memory can be added to any entrypoint() workflow using thread-level persistence.</p>
<p>When creating a LangGraph workflow, you can set it up to persist its results by using a checkpointer:</p>
<ol>
<li>Create an instance of a checkpointer:</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-203-1"><a id="__codelineno-203-1" name="__codelineno-203-1" href="#__codelineno-203-1"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-203-2"><a id="__codelineno-203-2" name="__codelineno-203-2" href="#__codelineno-203-2"></a>
</span><span id="__span-203-3"><a id="__codelineno-203-3" name="__codelineno-203-3" href="#__codelineno-203-3"></a>checkpointer = MemorySaver()
</span></code></pre></div>
<ol>
<li>Pass checkpointer instance to the entrypoint() decorator:</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-204-1"><a id="__codelineno-204-1" name="__codelineno-204-1" href="#__codelineno-204-1"></a>from langgraph.func import entrypoint
</span><span id="__span-204-2"><a id="__codelineno-204-2" name="__codelineno-204-2" href="#__codelineno-204-2"></a>
</span><span id="__span-204-3"><a id="__codelineno-204-3" name="__codelineno-204-3" href="#__codelineno-204-3"></a>@entrypoint(checkpointer=checkpointer)
</span><span id="__span-204-4"><a id="__codelineno-204-4" name="__codelineno-204-4" href="#__codelineno-204-4"></a>def workflow(inputs)
</span><span id="__span-204-5"><a id="__codelineno-204-5" name="__codelineno-204-5" href="#__codelineno-204-5"></a>    ...
</span></code></pre></div>
<ol>
<li>Optionally expose previous parameter in the workflow function signature:</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-205-1"><a id="__codelineno-205-1" name="__codelineno-205-1" href="#__codelineno-205-1"></a>@entrypoint(checkpointer=checkpointer)
</span><span id="__span-205-2"><a id="__codelineno-205-2" name="__codelineno-205-2" href="#__codelineno-205-2"></a>def workflow(
</span><span id="__span-205-3"><a id="__codelineno-205-3" name="__codelineno-205-3" href="#__codelineno-205-3"></a>    inputs,
</span><span id="__span-205-4"><a id="__codelineno-205-4" name="__codelineno-205-4" href="#__codelineno-205-4"></a>    *,
</span><span id="__span-205-5"><a id="__codelineno-205-5" name="__codelineno-205-5" href="#__codelineno-205-5"></a>    # you can optionally specify `previous` in the workflow function signature
</span><span id="__span-205-6"><a id="__codelineno-205-6" name="__codelineno-205-6" href="#__codelineno-205-6"></a>    # to access the return value from the workflow as of the last execution
</span><span id="__span-205-7"><a id="__codelineno-205-7" name="__codelineno-205-7" href="#__codelineno-205-7"></a>    previous
</span><span id="__span-205-8"><a id="__codelineno-205-8" name="__codelineno-205-8" href="#__codelineno-205-8"></a>):
</span><span id="__span-205-9"><a id="__codelineno-205-9" name="__codelineno-205-9" href="#__codelineno-205-9"></a>    previous = previous or []
</span><span id="__span-205-10"><a id="__codelineno-205-10" name="__codelineno-205-10" href="#__codelineno-205-10"></a>    combined_inputs = previous + inputs
</span><span id="__span-205-11"><a id="__codelineno-205-11" name="__codelineno-205-11" href="#__codelineno-205-11"></a>    result = do_something(combined_inputs)
</span><span id="__span-205-12"><a id="__codelineno-205-12" name="__codelineno-205-12" href="#__codelineno-205-12"></a>    ...
</span></code></pre></div>
<ol>
<li>Optionally choose which values will be returned from the workflow and which will be saved by the checkpointer as previous:</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-206-1"><a id="__codelineno-206-1" name="__codelineno-206-1" href="#__codelineno-206-1"></a>@entrypoint(checkpointer=checkpointer)
</span><span id="__span-206-2"><a id="__codelineno-206-2" name="__codelineno-206-2" href="#__codelineno-206-2"></a>def workflow(inputs, *, previous):
</span><span id="__span-206-3"><a id="__codelineno-206-3" name="__codelineno-206-3" href="#__codelineno-206-3"></a>    ...
</span><span id="__span-206-4"><a id="__codelineno-206-4" name="__codelineno-206-4" href="#__codelineno-206-4"></a>    result = do_something(...)
</span><span id="__span-206-5"><a id="__codelineno-206-5" name="__codelineno-206-5" href="#__codelineno-206-5"></a>    return entrypoint.final(value=result, save=combine(inputs, result))
</span></code></pre></div>
<h2 id="setup_2">Setup<a class="headerlink" href="#setup_2" title="Permanent link">#</a></h2>
<p>First we need to install the packages required</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-207-1"><a id="__codelineno-207-1" name="__codelineno-207-1" href="#__codelineno-207-1"></a>%%capture --no-stderr
</span><span id="__span-207-2"><a id="__codelineno-207-2" name="__codelineno-207-2" href="#__codelineno-207-2"></a>%pip install --quiet -U langgraph langchain_anthropic
</span></code></pre></div>
<p>Next, we need to set API key for Anthropic (the LLM we will use).</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-208-1"><a id="__codelineno-208-1" name="__codelineno-208-1" href="#__codelineno-208-1"></a>import getpass
</span><span id="__span-208-2"><a id="__codelineno-208-2" name="__codelineno-208-2" href="#__codelineno-208-2"></a>import os
</span><span id="__span-208-3"><a id="__codelineno-208-3" name="__codelineno-208-3" href="#__codelineno-208-3"></a>
</span><span id="__span-208-4"><a id="__codelineno-208-4" name="__codelineno-208-4" href="#__codelineno-208-4"></a>
</span><span id="__span-208-5"><a id="__codelineno-208-5" name="__codelineno-208-5" href="#__codelineno-208-5"></a>def _set_env(var: str):
</span><span id="__span-208-6"><a id="__codelineno-208-6" name="__codelineno-208-6" href="#__codelineno-208-6"></a>    if not os.environ.get(var):
</span><span id="__span-208-7"><a id="__codelineno-208-7" name="__codelineno-208-7" href="#__codelineno-208-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-208-8"><a id="__codelineno-208-8" name="__codelineno-208-8" href="#__codelineno-208-8"></a>
</span><span id="__span-208-9"><a id="__codelineno-208-9" name="__codelineno-208-9" href="#__codelineno-208-9"></a>
</span><span id="__span-208-10"><a id="__codelineno-208-10" name="__codelineno-208-10" href="#__codelineno-208-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span></code></pre></div>
<h2 id="example-simple-chatbot-with-short-term-memory">Example: simple chatbot with short-term memory<a class="headerlink" href="#example-simple-chatbot-with-short-term-memory" title="Permanent link">#</a></h2>
<p>We will be using a workflow with a single task that calls a chat model.</p>
<p>Let's first define the model we'll be using:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-209-1"><a id="__codelineno-209-1" name="__codelineno-209-1" href="#__codelineno-209-1"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-209-2"><a id="__codelineno-209-2" name="__codelineno-209-2" href="#__codelineno-209-2"></a>
</span><span id="__span-209-3"><a id="__codelineno-209-3" name="__codelineno-209-3" href="#__codelineno-209-3"></a>model = ChatAnthropic(model=&quot;claude-3-5-sonnet-latest&quot;)
</span></code></pre></div>
<p>API Reference: ChatAnthropic</p>
<p>Now we can define our task and workflow. To add in persistence, we need to pass in a Checkpointer to the entrypoint() decorator.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-210-1"><a id="__codelineno-210-1" name="__codelineno-210-1" href="#__codelineno-210-1"></a>from langchain_core.messages import BaseMessage
</span><span id="__span-210-2"><a id="__codelineno-210-2" name="__codelineno-210-2" href="#__codelineno-210-2"></a>from langgraph.graph import add_messages
</span><span id="__span-210-3"><a id="__codelineno-210-3" name="__codelineno-210-3" href="#__codelineno-210-3"></a>from langgraph.func import entrypoint, task
</span><span id="__span-210-4"><a id="__codelineno-210-4" name="__codelineno-210-4" href="#__codelineno-210-4"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-210-5"><a id="__codelineno-210-5" name="__codelineno-210-5" href="#__codelineno-210-5"></a>
</span><span id="__span-210-6"><a id="__codelineno-210-6" name="__codelineno-210-6" href="#__codelineno-210-6"></a>
</span><span id="__span-210-7"><a id="__codelineno-210-7" name="__codelineno-210-7" href="#__codelineno-210-7"></a>@task
</span><span id="__span-210-8"><a id="__codelineno-210-8" name="__codelineno-210-8" href="#__codelineno-210-8"></a>def call_model(messages: list[BaseMessage]):
</span><span id="__span-210-9"><a id="__codelineno-210-9" name="__codelineno-210-9" href="#__codelineno-210-9"></a>    response = model.invoke(messages)
</span><span id="__span-210-10"><a id="__codelineno-210-10" name="__codelineno-210-10" href="#__codelineno-210-10"></a>    return response
</span><span id="__span-210-11"><a id="__codelineno-210-11" name="__codelineno-210-11" href="#__codelineno-210-11"></a>
</span><span id="__span-210-12"><a id="__codelineno-210-12" name="__codelineno-210-12" href="#__codelineno-210-12"></a>
</span><span id="__span-210-13"><a id="__codelineno-210-13" name="__codelineno-210-13" href="#__codelineno-210-13"></a>checkpointer = MemorySaver()
</span><span id="__span-210-14"><a id="__codelineno-210-14" name="__codelineno-210-14" href="#__codelineno-210-14"></a>
</span><span id="__span-210-15"><a id="__codelineno-210-15" name="__codelineno-210-15" href="#__codelineno-210-15"></a>
</span><span id="__span-210-16"><a id="__codelineno-210-16" name="__codelineno-210-16" href="#__codelineno-210-16"></a>@entrypoint(checkpointer=checkpointer)
</span><span id="__span-210-17"><a id="__codelineno-210-17" name="__codelineno-210-17" href="#__codelineno-210-17"></a>def workflow(inputs: list[BaseMessage], *, previous: list[BaseMessage]):
</span><span id="__span-210-18"><a id="__codelineno-210-18" name="__codelineno-210-18" href="#__codelineno-210-18"></a>    if previous:
</span><span id="__span-210-19"><a id="__codelineno-210-19" name="__codelineno-210-19" href="#__codelineno-210-19"></a>        inputs = add_messages(previous, inputs)
</span><span id="__span-210-20"><a id="__codelineno-210-20" name="__codelineno-210-20" href="#__codelineno-210-20"></a>
</span><span id="__span-210-21"><a id="__codelineno-210-21" name="__codelineno-210-21" href="#__codelineno-210-21"></a>    response = call_model(inputs).result()
</span><span id="__span-210-22"><a id="__codelineno-210-22" name="__codelineno-210-22" href="#__codelineno-210-22"></a>    return entrypoint.final(value=response, save=add_messages(inputs, response))
</span></code></pre></div>
<p>If we try to use this workflow, the context of the conversation will be persisted across interactions:</p>
<p>We can now interact with the agent and see that it remembers previous messages!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-211-1"><a id="__codelineno-211-1" name="__codelineno-211-1" href="#__codelineno-211-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;}}
</span><span id="__span-211-2"><a id="__codelineno-211-2" name="__codelineno-211-2" href="#__codelineno-211-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi! I&#39;m bob&quot;}
</span><span id="__span-211-3"><a id="__codelineno-211-3" name="__codelineno-211-3" href="#__codelineno-211-3"></a>for chunk in workflow.stream([input_message], config, stream_mode=&quot;values&quot;):
</span><span id="__span-211-4"><a id="__codelineno-211-4" name="__codelineno-211-4" href="#__codelineno-211-4"></a>    chunk.pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-212-1"><a id="__codelineno-212-1" name="__codelineno-212-1" href="#__codelineno-212-1"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-212-2"><a id="__codelineno-212-2" name="__codelineno-212-2" href="#__codelineno-212-2"></a>
</span><span id="__span-212-3"><a id="__codelineno-212-3" name="__codelineno-212-3" href="#__codelineno-212-3"></a>Hi Bob! I&#39;m Claude. Nice to meet you! How are you today?
</span></code></pre></div>
<p>You can always resume previous threads:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-213-1"><a id="__codelineno-213-1" name="__codelineno-213-1" href="#__codelineno-213-1"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#39;s my name?&quot;}
</span><span id="__span-213-2"><a id="__codelineno-213-2" name="__codelineno-213-2" href="#__codelineno-213-2"></a>for chunk in workflow.stream([input_message], config, stream_mode=&quot;values&quot;):
</span><span id="__span-213-3"><a id="__codelineno-213-3" name="__codelineno-213-3" href="#__codelineno-213-3"></a>    chunk.pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-214-1"><a id="__codelineno-214-1" name="__codelineno-214-1" href="#__codelineno-214-1"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-214-2"><a id="__codelineno-214-2" name="__codelineno-214-2" href="#__codelineno-214-2"></a>
</span><span id="__span-214-3"><a id="__codelineno-214-3" name="__codelineno-214-3" href="#__codelineno-214-3"></a>Your name is Bob.
</span></code></pre></div>
<p>If we want to start a new conversation, we can pass in a different thread_id. Poof! All the memories are gone!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-215-1"><a id="__codelineno-215-1" name="__codelineno-215-1" href="#__codelineno-215-1"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#39;s my name?&quot;}
</span><span id="__span-215-2"><a id="__codelineno-215-2" name="__codelineno-215-2" href="#__codelineno-215-2"></a>for chunk in workflow.stream(
</span><span id="__span-215-3"><a id="__codelineno-215-3" name="__codelineno-215-3" href="#__codelineno-215-3"></a>    [input_message],
</span><span id="__span-215-4"><a id="__codelineno-215-4" name="__codelineno-215-4" href="#__codelineno-215-4"></a>    {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}},
</span><span id="__span-215-5"><a id="__codelineno-215-5" name="__codelineno-215-5" href="#__codelineno-215-5"></a>    stream_mode=&quot;values&quot;,
</span><span id="__span-215-6"><a id="__codelineno-215-6" name="__codelineno-215-6" href="#__codelineno-215-6"></a>):
</span><span id="__span-215-7"><a id="__codelineno-215-7" name="__codelineno-215-7" href="#__codelineno-215-7"></a>    chunk.pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-216-1"><a id="__codelineno-216-1" name="__codelineno-216-1" href="#__codelineno-216-1"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-216-2"><a id="__codelineno-216-2" name="__codelineno-216-2" href="#__codelineno-216-2"></a>
</span><span id="__span-216-3"><a id="__codelineno-216-3" name="__codelineno-216-3" href="#__codelineno-216-3"></a>I don&#39;t know your name unless you tell me. Each conversation I have starts fresh, so I don&#39;t have access to any previous interactions or personal information unless you share it with me.
</span></code></pre></div>
<h2 id="how-to-add-cross-thread-persistence-functional-api">How to add cross-thread persistence (functional API)<a class="headerlink" href="#how-to-add-cross-thread-persistence-functional-api" title="Permanent link">#</a></h2>
<p>LangGraph allows you to persist data across different threads. For instance, you can store information about users (their names or preferences) in a shared (cross-thread) memory and reuse them in the new threads (e.g., new conversations).</p>
<p>When using the functional API, you can set it up to store and retrieve memories by using the Store interface:</p>
<ol>
<li>Create an instance of a Store</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-217-1"><a id="__codelineno-217-1" name="__codelineno-217-1" href="#__codelineno-217-1"></a>from langgraph.store.memory import InMemoryStore, BaseStore
</span><span id="__span-217-2"><a id="__codelineno-217-2" name="__codelineno-217-2" href="#__codelineno-217-2"></a>
</span><span id="__span-217-3"><a id="__codelineno-217-3" name="__codelineno-217-3" href="#__codelineno-217-3"></a>store = InMemoryStore()
</span></code></pre></div>
<ol>
<li>Pass the store instance to the entrypoint() decorator and expose store parameter in the function signature:</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-218-1"><a id="__codelineno-218-1" name="__codelineno-218-1" href="#__codelineno-218-1"></a>from langgraph.func import entrypoint
</span><span id="__span-218-2"><a id="__codelineno-218-2" name="__codelineno-218-2" href="#__codelineno-218-2"></a>
</span><span id="__span-218-3"><a id="__codelineno-218-3" name="__codelineno-218-3" href="#__codelineno-218-3"></a>@entrypoint(store=store)
</span><span id="__span-218-4"><a id="__codelineno-218-4" name="__codelineno-218-4" href="#__codelineno-218-4"></a>def workflow(inputs: dict, store: BaseStore):
</span><span id="__span-218-5"><a id="__codelineno-218-5" name="__codelineno-218-5" href="#__codelineno-218-5"></a>    my_task(inputs).result()
</span><span id="__span-218-6"><a id="__codelineno-218-6" name="__codelineno-218-6" href="#__codelineno-218-6"></a>    ...
</span></code></pre></div>
<h2 id="setup_3">Setup<a class="headerlink" href="#setup_3" title="Permanent link">#</a></h2>
<p>First, let's install the required packages and set our API keys</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-219-1"><a id="__codelineno-219-1" name="__codelineno-219-1" href="#__codelineno-219-1"></a>%%capture --no-stderr
</span><span id="__span-219-2"><a id="__codelineno-219-2" name="__codelineno-219-2" href="#__codelineno-219-2"></a>%pip install -U langchain_anthropic langchain_openai langgraph
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-220-1"><a id="__codelineno-220-1" name="__codelineno-220-1" href="#__codelineno-220-1"></a>import getpass
</span><span id="__span-220-2"><a id="__codelineno-220-2" name="__codelineno-220-2" href="#__codelineno-220-2"></a>import os
</span><span id="__span-220-3"><a id="__codelineno-220-3" name="__codelineno-220-3" href="#__codelineno-220-3"></a>
</span><span id="__span-220-4"><a id="__codelineno-220-4" name="__codelineno-220-4" href="#__codelineno-220-4"></a>
</span><span id="__span-220-5"><a id="__codelineno-220-5" name="__codelineno-220-5" href="#__codelineno-220-5"></a>def _set_env(var: str):
</span><span id="__span-220-6"><a id="__codelineno-220-6" name="__codelineno-220-6" href="#__codelineno-220-6"></a>    if not os.environ.get(var):
</span><span id="__span-220-7"><a id="__codelineno-220-7" name="__codelineno-220-7" href="#__codelineno-220-7"></a>        os.environ[var] = getpass.getpass(f&quot;{var}: &quot;)
</span><span id="__span-220-8"><a id="__codelineno-220-8" name="__codelineno-220-8" href="#__codelineno-220-8"></a>
</span><span id="__span-220-9"><a id="__codelineno-220-9" name="__codelineno-220-9" href="#__codelineno-220-9"></a>
</span><span id="__span-220-10"><a id="__codelineno-220-10" name="__codelineno-220-10" href="#__codelineno-220-10"></a>_set_env(&quot;ANTHROPIC_API_KEY&quot;)
</span><span id="__span-220-11"><a id="__codelineno-220-11" name="__codelineno-220-11" href="#__codelineno-220-11"></a>_set_env(&quot;OPENAI_API_KEY&quot;)
</span></code></pre></div>
<h2 id="example-simple-chatbot-with-long-term-memory">Example: simple chatbot with long-term memory<a class="headerlink" href="#example-simple-chatbot-with-long-term-memory" title="Permanent link">#</a></h2>
<h2 id="define-store_1">Define store<a class="headerlink" href="#define-store_1" title="Permanent link">#</a></h2>
<p>In this example we will create a workflow that will be able to retrieve information about a user's preferences. We will do so by defining an InMemoryStore - an object that can store data in memory and query that data.</p>
<p>When storing objects using the Store interface you define two things:</p>
<ul>
<li>the namespace for the object, a tuple (similar to directories)</li>
<li>the object key (similar to filenames)</li>
</ul>
<p>In our example, we'll be using ("memories", <user_id>) as namespace and random UUID as key for each new memory.</p>
<p>Importantly, to determine the user, we will be passing user_id via the config keyword argument of the node function.</p>
<p>Let's first define our store!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-221-1"><a id="__codelineno-221-1" name="__codelineno-221-1" href="#__codelineno-221-1"></a>from langgraph.store.memory import InMemoryStore
</span><span id="__span-221-2"><a id="__codelineno-221-2" name="__codelineno-221-2" href="#__codelineno-221-2"></a>from langchain_openai import OpenAIEmbeddings
</span><span id="__span-221-3"><a id="__codelineno-221-3" name="__codelineno-221-3" href="#__codelineno-221-3"></a>
</span><span id="__span-221-4"><a id="__codelineno-221-4" name="__codelineno-221-4" href="#__codelineno-221-4"></a>in_memory_store = InMemoryStore(
</span><span id="__span-221-5"><a id="__codelineno-221-5" name="__codelineno-221-5" href="#__codelineno-221-5"></a>    index={
</span><span id="__span-221-6"><a id="__codelineno-221-6" name="__codelineno-221-6" href="#__codelineno-221-6"></a>        &quot;embed&quot;: OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;),
</span><span id="__span-221-7"><a id="__codelineno-221-7" name="__codelineno-221-7" href="#__codelineno-221-7"></a>        &quot;dims&quot;: 1536,
</span><span id="__span-221-8"><a id="__codelineno-221-8" name="__codelineno-221-8" href="#__codelineno-221-8"></a>    }
</span><span id="__span-221-9"><a id="__codelineno-221-9" name="__codelineno-221-9" href="#__codelineno-221-9"></a>)
</span></code></pre></div>
<h2 id="create-workflow">Create workflow<a class="headerlink" href="#create-workflow" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-222-1"><a id="__codelineno-222-1" name="__codelineno-222-1" href="#__codelineno-222-1"></a>import uuid
</span><span id="__span-222-2"><a id="__codelineno-222-2" name="__codelineno-222-2" href="#__codelineno-222-2"></a>
</span><span id="__span-222-3"><a id="__codelineno-222-3" name="__codelineno-222-3" href="#__codelineno-222-3"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-222-4"><a id="__codelineno-222-4" name="__codelineno-222-4" href="#__codelineno-222-4"></a>from langchain_core.runnables import RunnableConfig
</span><span id="__span-222-5"><a id="__codelineno-222-5" name="__codelineno-222-5" href="#__codelineno-222-5"></a>from langchain_core.messages import BaseMessage
</span><span id="__span-222-6"><a id="__codelineno-222-6" name="__codelineno-222-6" href="#__codelineno-222-6"></a>from langgraph.func import entrypoint, task
</span><span id="__span-222-7"><a id="__codelineno-222-7" name="__codelineno-222-7" href="#__codelineno-222-7"></a>from langgraph.graph import add_messages
</span><span id="__span-222-8"><a id="__codelineno-222-8" name="__codelineno-222-8" href="#__codelineno-222-8"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-222-9"><a id="__codelineno-222-9" name="__codelineno-222-9" href="#__codelineno-222-9"></a>from langgraph.store.base import BaseStore
</span><span id="__span-222-10"><a id="__codelineno-222-10" name="__codelineno-222-10" href="#__codelineno-222-10"></a>
</span><span id="__span-222-11"><a id="__codelineno-222-11" name="__codelineno-222-11" href="#__codelineno-222-11"></a>
</span><span id="__span-222-12"><a id="__codelineno-222-12" name="__codelineno-222-12" href="#__codelineno-222-12"></a>model = ChatAnthropic(model=&quot;claude-3-5-sonnet-latest&quot;)
</span><span id="__span-222-13"><a id="__codelineno-222-13" name="__codelineno-222-13" href="#__codelineno-222-13"></a>
</span><span id="__span-222-14"><a id="__codelineno-222-14" name="__codelineno-222-14" href="#__codelineno-222-14"></a>
</span><span id="__span-222-15"><a id="__codelineno-222-15" name="__codelineno-222-15" href="#__codelineno-222-15"></a>@task
</span><span id="__span-222-16"><a id="__codelineno-222-16" name="__codelineno-222-16" href="#__codelineno-222-16"></a>def call_model(messages: list[BaseMessage], memory_store: BaseStore, user_id: str):
</span><span id="__span-222-17"><a id="__codelineno-222-17" name="__codelineno-222-17" href="#__codelineno-222-17"></a>    namespace = (&quot;memories&quot;, user_id)
</span><span id="__span-222-18"><a id="__codelineno-222-18" name="__codelineno-222-18" href="#__codelineno-222-18"></a>    last_message = messages[-1]
</span><span id="__span-222-19"><a id="__codelineno-222-19" name="__codelineno-222-19" href="#__codelineno-222-19"></a>    memories = memory_store.search(namespace, query=str(last_message.content))
</span><span id="__span-222-20"><a id="__codelineno-222-20" name="__codelineno-222-20" href="#__codelineno-222-20"></a>    info = &quot;\n&quot;.join([d.value[&quot;data&quot;] for d in memories])
</span><span id="__span-222-21"><a id="__codelineno-222-21" name="__codelineno-222-21" href="#__codelineno-222-21"></a>    system_msg = f&quot;You are a helpful assistant talking to the user. User info: {info}&quot;
</span><span id="__span-222-22"><a id="__codelineno-222-22" name="__codelineno-222-22" href="#__codelineno-222-22"></a>
</span><span id="__span-222-23"><a id="__codelineno-222-23" name="__codelineno-222-23" href="#__codelineno-222-23"></a>    # Store new memories if the user asks the model to remember
</span><span id="__span-222-24"><a id="__codelineno-222-24" name="__codelineno-222-24" href="#__codelineno-222-24"></a>    if &quot;remember&quot; in last_message.content.lower():
</span><span id="__span-222-25"><a id="__codelineno-222-25" name="__codelineno-222-25" href="#__codelineno-222-25"></a>        memory = &quot;User name is Bob&quot;
</span><span id="__span-222-26"><a id="__codelineno-222-26" name="__codelineno-222-26" href="#__codelineno-222-26"></a>        memory_store.put(namespace, str(uuid.uuid4()), {&quot;data&quot;: memory})
</span><span id="__span-222-27"><a id="__codelineno-222-27" name="__codelineno-222-27" href="#__codelineno-222-27"></a>
</span><span id="__span-222-28"><a id="__codelineno-222-28" name="__codelineno-222-28" href="#__codelineno-222-28"></a>    response = model.invoke([{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_msg}] + messages)
</span><span id="__span-222-29"><a id="__codelineno-222-29" name="__codelineno-222-29" href="#__codelineno-222-29"></a>    return response
</span><span id="__span-222-30"><a id="__codelineno-222-30" name="__codelineno-222-30" href="#__codelineno-222-30"></a>
</span><span id="__span-222-31"><a id="__codelineno-222-31" name="__codelineno-222-31" href="#__codelineno-222-31"></a>
</span><span id="__span-222-32"><a id="__codelineno-222-32" name="__codelineno-222-32" href="#__codelineno-222-32"></a># NOTE: we&#39;re passing the store object here when creating a workflow via entrypoint()
</span><span id="__span-222-33"><a id="__codelineno-222-33" name="__codelineno-222-33" href="#__codelineno-222-33"></a>@entrypoint(checkpointer=MemorySaver(), store=in_memory_store)
</span><span id="__span-222-34"><a id="__codelineno-222-34" name="__codelineno-222-34" href="#__codelineno-222-34"></a>def workflow(
</span><span id="__span-222-35"><a id="__codelineno-222-35" name="__codelineno-222-35" href="#__codelineno-222-35"></a>    inputs: list[BaseMessage],
</span><span id="__span-222-36"><a id="__codelineno-222-36" name="__codelineno-222-36" href="#__codelineno-222-36"></a>    *,
</span><span id="__span-222-37"><a id="__codelineno-222-37" name="__codelineno-222-37" href="#__codelineno-222-37"></a>    previous: list[BaseMessage],
</span><span id="__span-222-38"><a id="__codelineno-222-38" name="__codelineno-222-38" href="#__codelineno-222-38"></a>    config: RunnableConfig,
</span><span id="__span-222-39"><a id="__codelineno-222-39" name="__codelineno-222-39" href="#__codelineno-222-39"></a>    store: BaseStore,
</span><span id="__span-222-40"><a id="__codelineno-222-40" name="__codelineno-222-40" href="#__codelineno-222-40"></a>):
</span><span id="__span-222-41"><a id="__codelineno-222-41" name="__codelineno-222-41" href="#__codelineno-222-41"></a>    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]
</span><span id="__span-222-42"><a id="__codelineno-222-42" name="__codelineno-222-42" href="#__codelineno-222-42"></a>    previous = previous or []
</span><span id="__span-222-43"><a id="__codelineno-222-43" name="__codelineno-222-43" href="#__codelineno-222-43"></a>    inputs = add_messages(previous, inputs)
</span><span id="__span-222-44"><a id="__codelineno-222-44" name="__codelineno-222-44" href="#__codelineno-222-44"></a>    response = call_model(inputs, store, user_id).result()
</span><span id="__span-222-45"><a id="__codelineno-222-45" name="__codelineno-222-45" href="#__codelineno-222-45"></a>    return entrypoint.final(value=response, save=add_messages(inputs, response))
</span></code></pre></div>
<h2 id="run-the-workflow">Run the workflow!<a class="headerlink" href="#run-the-workflow" title="Permanent link">#</a></h2>
<p>Now let's specify a user ID in the config and tell the model our name:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-223-1"><a id="__codelineno-223-1" name="__codelineno-223-1" href="#__codelineno-223-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;}}
</span><span id="__span-223-2"><a id="__codelineno-223-2" name="__codelineno-223-2" href="#__codelineno-223-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi! Remember: my name is Bob&quot;}
</span><span id="__span-223-3"><a id="__codelineno-223-3" name="__codelineno-223-3" href="#__codelineno-223-3"></a>for chunk in workflow.stream([input_message], config, stream_mode=&quot;values&quot;):
</span><span id="__span-223-4"><a id="__codelineno-223-4" name="__codelineno-223-4" href="#__codelineno-223-4"></a>    chunk.pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-224-1"><a id="__codelineno-224-1" name="__codelineno-224-1" href="#__codelineno-224-1"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-224-2"><a id="__codelineno-224-2" name="__codelineno-224-2" href="#__codelineno-224-2"></a>
</span><span id="__span-224-3"><a id="__codelineno-224-3" name="__codelineno-224-3" href="#__codelineno-224-3"></a>Hello Bob! Nice to meet you. I&#39;ll remember that your name is Bob. How can I help you today?
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-225-1"><a id="__codelineno-225-1" name="__codelineno-225-1" href="#__codelineno-225-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;}}
</span><span id="__span-225-2"><a id="__codelineno-225-2" name="__codelineno-225-2" href="#__codelineno-225-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is my name?&quot;}
</span><span id="__span-225-3"><a id="__codelineno-225-3" name="__codelineno-225-3" href="#__codelineno-225-3"></a>for chunk in workflow.stream([input_message], config, stream_mode=&quot;values&quot;):
</span><span id="__span-225-4"><a id="__codelineno-225-4" name="__codelineno-225-4" href="#__codelineno-225-4"></a>    chunk.pretty_print()
</span></code></pre></div>
<p>We can now inspect our in-memory store and verify that we have in fact saved the memories for the user:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-226-1"><a id="__codelineno-226-1" name="__codelineno-226-1" href="#__codelineno-226-1"></a>for memory in in_memory_store.search((&quot;memories&quot;, &quot;1&quot;)):
</span><span id="__span-226-2"><a id="__codelineno-226-2" name="__codelineno-226-2" href="#__codelineno-226-2"></a>    print(memory.value)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-227-1"><a id="__codelineno-227-1" name="__codelineno-227-1" href="#__codelineno-227-1"></a>{&#39;data&#39;: &#39;User name is Bob&#39;}
</span></code></pre></div>
<p>Let's now run the workflow for another user to verify that the memories about the first user are self contained:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-228-1"><a id="__codelineno-228-1" name="__codelineno-228-1" href="#__codelineno-228-1"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;3&quot;, &quot;user_id&quot;: &quot;2&quot;}}
</span><span id="__span-228-2"><a id="__codelineno-228-2" name="__codelineno-228-2" href="#__codelineno-228-2"></a>input_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is my name?&quot;}
</span><span id="__span-228-3"><a id="__codelineno-228-3" name="__codelineno-228-3" href="#__codelineno-228-3"></a>for chunk in workflow.stream([input_message], config, stream_mode=&quot;values&quot;):
</span><span id="__span-228-4"><a id="__codelineno-228-4" name="__codelineno-228-4" href="#__codelineno-228-4"></a>    chunk.pretty_print()
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-229-1"><a id="__codelineno-229-1" name="__codelineno-229-1" href="#__codelineno-229-1"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-229-2"><a id="__codelineno-229-2" name="__codelineno-229-2" href="#__codelineno-229-2"></a>
</span><span id="__span-229-3"><a id="__codelineno-229-3" name="__codelineno-229-3" href="#__codelineno-229-3"></a>I don&#39;t have any information about your name. I can only see our current conversation without any prior context or personal details about you. If you&#39;d like me to know your name, feel free to tell me!
</span></code></pre></div>
<h1 id="how-to-manage-conversation-history">How to manage conversation history<a class="headerlink" href="#how-to-manage-conversation-history" title="Permanent link">#</a></h1>
<p>One of the most common use cases for persistence is to use it to keep track of conversation history. This is great - it makes it easy to continue conversations. As conversations get longer and longer, however, this conversation history can build up and take up more and more of the context window. This can often be undesirable as it leads to more expensive and longer calls to the LLM, and potentially ones that error. In order to prevent this from happening, you need to properly manage the conversation history.</p>
<p>Note: this guide focuses on how to do this in LangGraph, where you can fully customize how this is done. If you want a more off-the-shelf solution, you can look into functionality provided in LangChain:</p>
<ul>
<li>How to filter messages</li>
<li>How to trim messages</li>
</ul>
<h2 id="build-the-agent">Build the agent<a class="headerlink" href="#build-the-agent" title="Permanent link">#</a></h2>
<p>Let's now build a simple ReAct style agent.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-230-1"><a id="__codelineno-230-1" name="__codelineno-230-1" href="#__codelineno-230-1"></a>from typing import Literal
</span><span id="__span-230-2"><a id="__codelineno-230-2" name="__codelineno-230-2" href="#__codelineno-230-2"></a>
</span><span id="__span-230-3"><a id="__codelineno-230-3" name="__codelineno-230-3" href="#__codelineno-230-3"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-230-4"><a id="__codelineno-230-4" name="__codelineno-230-4" href="#__codelineno-230-4"></a>from langchain_core.tools import tool
</span><span id="__span-230-5"><a id="__codelineno-230-5" name="__codelineno-230-5" href="#__codelineno-230-5"></a>
</span><span id="__span-230-6"><a id="__codelineno-230-6" name="__codelineno-230-6" href="#__codelineno-230-6"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-230-7"><a id="__codelineno-230-7" name="__codelineno-230-7" href="#__codelineno-230-7"></a>from langgraph.graph import MessagesState, StateGraph, START, END
</span><span id="__span-230-8"><a id="__codelineno-230-8" name="__codelineno-230-8" href="#__codelineno-230-8"></a>from langgraph.prebuilt import ToolNode
</span><span id="__span-230-9"><a id="__codelineno-230-9" name="__codelineno-230-9" href="#__codelineno-230-9"></a>
</span><span id="__span-230-10"><a id="__codelineno-230-10" name="__codelineno-230-10" href="#__codelineno-230-10"></a>memory = MemorySaver()
</span><span id="__span-230-11"><a id="__codelineno-230-11" name="__codelineno-230-11" href="#__codelineno-230-11"></a>
</span><span id="__span-230-12"><a id="__codelineno-230-12" name="__codelineno-230-12" href="#__codelineno-230-12"></a>
</span><span id="__span-230-13"><a id="__codelineno-230-13" name="__codelineno-230-13" href="#__codelineno-230-13"></a>@tool
</span><span id="__span-230-14"><a id="__codelineno-230-14" name="__codelineno-230-14" href="#__codelineno-230-14"></a>def search(query: str):
</span><span id="__span-230-15"><a id="__codelineno-230-15" name="__codelineno-230-15" href="#__codelineno-230-15"></a>    &quot;&quot;&quot;Call to surf the web.&quot;&quot;&quot;
</span><span id="__span-230-16"><a id="__codelineno-230-16" name="__codelineno-230-16" href="#__codelineno-230-16"></a>    # This is a placeholder for the actual implementation
</span><span id="__span-230-17"><a id="__codelineno-230-17" name="__codelineno-230-17" href="#__codelineno-230-17"></a>    # Don&#39;t let the LLM know this though 😊
</span><span id="__span-230-18"><a id="__codelineno-230-18" name="__codelineno-230-18" href="#__codelineno-230-18"></a>    return &quot;It&#39;s sunny in San Francisco, but you better look out if you&#39;re a Gemini 😈.&quot;
</span><span id="__span-230-19"><a id="__codelineno-230-19" name="__codelineno-230-19" href="#__codelineno-230-19"></a>
</span><span id="__span-230-20"><a id="__codelineno-230-20" name="__codelineno-230-20" href="#__codelineno-230-20"></a>
</span><span id="__span-230-21"><a id="__codelineno-230-21" name="__codelineno-230-21" href="#__codelineno-230-21"></a>tools = [search]
</span><span id="__span-230-22"><a id="__codelineno-230-22" name="__codelineno-230-22" href="#__codelineno-230-22"></a>tool_node = ToolNode(tools)
</span><span id="__span-230-23"><a id="__codelineno-230-23" name="__codelineno-230-23" href="#__codelineno-230-23"></a>model = ChatAnthropic(model_name=&quot;claude-3-haiku-20240307&quot;)
</span><span id="__span-230-24"><a id="__codelineno-230-24" name="__codelineno-230-24" href="#__codelineno-230-24"></a>bound_model = model.bind_tools(tools)
</span><span id="__span-230-25"><a id="__codelineno-230-25" name="__codelineno-230-25" href="#__codelineno-230-25"></a>
</span><span id="__span-230-26"><a id="__codelineno-230-26" name="__codelineno-230-26" href="#__codelineno-230-26"></a>
</span><span id="__span-230-27"><a id="__codelineno-230-27" name="__codelineno-230-27" href="#__codelineno-230-27"></a>def should_continue(state: MessagesState):
</span><span id="__span-230-28"><a id="__codelineno-230-28" name="__codelineno-230-28" href="#__codelineno-230-28"></a>    &quot;&quot;&quot;Return the next node to execute.&quot;&quot;&quot;
</span><span id="__span-230-29"><a id="__codelineno-230-29" name="__codelineno-230-29" href="#__codelineno-230-29"></a>    last_message = state[&quot;messages&quot;][-1]
</span><span id="__span-230-30"><a id="__codelineno-230-30" name="__codelineno-230-30" href="#__codelineno-230-30"></a>    # If there is no function call, then we finish
</span><span id="__span-230-31"><a id="__codelineno-230-31" name="__codelineno-230-31" href="#__codelineno-230-31"></a>    if not last_message.tool_calls:
</span><span id="__span-230-32"><a id="__codelineno-230-32" name="__codelineno-230-32" href="#__codelineno-230-32"></a>        return END
</span><span id="__span-230-33"><a id="__codelineno-230-33" name="__codelineno-230-33" href="#__codelineno-230-33"></a>    # Otherwise if there is, we continue
</span><span id="__span-230-34"><a id="__codelineno-230-34" name="__codelineno-230-34" href="#__codelineno-230-34"></a>    return &quot;action&quot;
</span><span id="__span-230-35"><a id="__codelineno-230-35" name="__codelineno-230-35" href="#__codelineno-230-35"></a>
</span><span id="__span-230-36"><a id="__codelineno-230-36" name="__codelineno-230-36" href="#__codelineno-230-36"></a>
</span><span id="__span-230-37"><a id="__codelineno-230-37" name="__codelineno-230-37" href="#__codelineno-230-37"></a># Define the function that calls the model
</span><span id="__span-230-38"><a id="__codelineno-230-38" name="__codelineno-230-38" href="#__codelineno-230-38"></a>def call_model(state: MessagesState):
</span><span id="__span-230-39"><a id="__codelineno-230-39" name="__codelineno-230-39" href="#__codelineno-230-39"></a>    response = bound_model.invoke(state[&quot;messages&quot;])
</span><span id="__span-230-40"><a id="__codelineno-230-40" name="__codelineno-230-40" href="#__codelineno-230-40"></a>    # We return a list, because this will get added to the existing list
</span><span id="__span-230-41"><a id="__codelineno-230-41" name="__codelineno-230-41" href="#__codelineno-230-41"></a>    return {&quot;messages&quot;: response}
</span><span id="__span-230-42"><a id="__codelineno-230-42" name="__codelineno-230-42" href="#__codelineno-230-42"></a>
</span><span id="__span-230-43"><a id="__codelineno-230-43" name="__codelineno-230-43" href="#__codelineno-230-43"></a>
</span><span id="__span-230-44"><a id="__codelineno-230-44" name="__codelineno-230-44" href="#__codelineno-230-44"></a># Define a new graph
</span><span id="__span-230-45"><a id="__codelineno-230-45" name="__codelineno-230-45" href="#__codelineno-230-45"></a>workflow = StateGraph(MessagesState)
</span><span id="__span-230-46"><a id="__codelineno-230-46" name="__codelineno-230-46" href="#__codelineno-230-46"></a>
</span><span id="__span-230-47"><a id="__codelineno-230-47" name="__codelineno-230-47" href="#__codelineno-230-47"></a># Define the two nodes we will cycle between
</span><span id="__span-230-48"><a id="__codelineno-230-48" name="__codelineno-230-48" href="#__codelineno-230-48"></a>workflow.add_node(&quot;agent&quot;, call_model)
</span><span id="__span-230-49"><a id="__codelineno-230-49" name="__codelineno-230-49" href="#__codelineno-230-49"></a>workflow.add_node(&quot;action&quot;, tool_node)
</span><span id="__span-230-50"><a id="__codelineno-230-50" name="__codelineno-230-50" href="#__codelineno-230-50"></a>
</span><span id="__span-230-51"><a id="__codelineno-230-51" name="__codelineno-230-51" href="#__codelineno-230-51"></a># Set the entrypoint as `agent`
</span><span id="__span-230-52"><a id="__codelineno-230-52" name="__codelineno-230-52" href="#__codelineno-230-52"></a># This means that this node is the first one called
</span><span id="__span-230-53"><a id="__codelineno-230-53" name="__codelineno-230-53" href="#__codelineno-230-53"></a>workflow.add_edge(START, &quot;agent&quot;)
</span><span id="__span-230-54"><a id="__codelineno-230-54" name="__codelineno-230-54" href="#__codelineno-230-54"></a>
</span><span id="__span-230-55"><a id="__codelineno-230-55" name="__codelineno-230-55" href="#__codelineno-230-55"></a># We now add a conditional edge
</span><span id="__span-230-56"><a id="__codelineno-230-56" name="__codelineno-230-56" href="#__codelineno-230-56"></a>workflow.add_conditional_edges(
</span><span id="__span-230-57"><a id="__codelineno-230-57" name="__codelineno-230-57" href="#__codelineno-230-57"></a>    # First, we define the start node. We use `agent`.
</span><span id="__span-230-58"><a id="__codelineno-230-58" name="__codelineno-230-58" href="#__codelineno-230-58"></a>    # This means these are the edges taken after the `agent` node is called.
</span><span id="__span-230-59"><a id="__codelineno-230-59" name="__codelineno-230-59" href="#__codelineno-230-59"></a>    &quot;agent&quot;,
</span><span id="__span-230-60"><a id="__codelineno-230-60" name="__codelineno-230-60" href="#__codelineno-230-60"></a>    # Next, we pass in the function that will determine which node is called next.
</span><span id="__span-230-61"><a id="__codelineno-230-61" name="__codelineno-230-61" href="#__codelineno-230-61"></a>    should_continue,
</span><span id="__span-230-62"><a id="__codelineno-230-62" name="__codelineno-230-62" href="#__codelineno-230-62"></a>    # Next, we pass in the path map - all the possible nodes this edge could go to
</span><span id="__span-230-63"><a id="__codelineno-230-63" name="__codelineno-230-63" href="#__codelineno-230-63"></a>    [&quot;action&quot;, END],
</span><span id="__span-230-64"><a id="__codelineno-230-64" name="__codelineno-230-64" href="#__codelineno-230-64"></a>)
</span><span id="__span-230-65"><a id="__codelineno-230-65" name="__codelineno-230-65" href="#__codelineno-230-65"></a>
</span><span id="__span-230-66"><a id="__codelineno-230-66" name="__codelineno-230-66" href="#__codelineno-230-66"></a># We now add a normal edge from `tools` to `agent`.
</span><span id="__span-230-67"><a id="__codelineno-230-67" name="__codelineno-230-67" href="#__codelineno-230-67"></a># This means that after `tools` is called, `agent` node is called next.
</span><span id="__span-230-68"><a id="__codelineno-230-68" name="__codelineno-230-68" href="#__codelineno-230-68"></a>workflow.add_edge(&quot;action&quot;, &quot;agent&quot;)
</span><span id="__span-230-69"><a id="__codelineno-230-69" name="__codelineno-230-69" href="#__codelineno-230-69"></a>
</span><span id="__span-230-70"><a id="__codelineno-230-70" name="__codelineno-230-70" href="#__codelineno-230-70"></a># Finally, we compile it!
</span><span id="__span-230-71"><a id="__codelineno-230-71" name="__codelineno-230-71" href="#__codelineno-230-71"></a># This compiles it into a LangChain Runnable,
</span><span id="__span-230-72"><a id="__codelineno-230-72" name="__codelineno-230-72" href="#__codelineno-230-72"></a># meaning you can use it as you would any other runnable
</span><span id="__span-230-73"><a id="__codelineno-230-73" name="__codelineno-230-73" href="#__codelineno-230-73"></a>app = workflow.compile(checkpointer=memory)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-231-1"><a id="__codelineno-231-1" name="__codelineno-231-1" href="#__codelineno-231-1"></a>from langchain_core.messages import HumanMessage
</span><span id="__span-231-2"><a id="__codelineno-231-2" name="__codelineno-231-2" href="#__codelineno-231-2"></a>
</span><span id="__span-231-3"><a id="__codelineno-231-3" name="__codelineno-231-3" href="#__codelineno-231-3"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}}
</span><span id="__span-231-4"><a id="__codelineno-231-4" name="__codelineno-231-4" href="#__codelineno-231-4"></a>input_message = HumanMessage(content=&quot;hi! I&#39;m bob&quot;)
</span><span id="__span-231-5"><a id="__codelineno-231-5" name="__codelineno-231-5" href="#__codelineno-231-5"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-231-6"><a id="__codelineno-231-6" name="__codelineno-231-6" href="#__codelineno-231-6"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span><span id="__span-231-7"><a id="__codelineno-231-7" name="__codelineno-231-7" href="#__codelineno-231-7"></a>
</span><span id="__span-231-8"><a id="__codelineno-231-8" name="__codelineno-231-8" href="#__codelineno-231-8"></a>
</span><span id="__span-231-9"><a id="__codelineno-231-9" name="__codelineno-231-9" href="#__codelineno-231-9"></a>input_message = HumanMessage(content=&quot;what&#39;s my name?&quot;)
</span><span id="__span-231-10"><a id="__codelineno-231-10" name="__codelineno-231-10" href="#__codelineno-231-10"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-231-11"><a id="__codelineno-231-11" name="__codelineno-231-11" href="#__codelineno-231-11"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<p>API Reference: HumanMessage</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-232-1"><a id="__codelineno-232-1" name="__codelineno-232-1" href="#__codelineno-232-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-232-2"><a id="__codelineno-232-2" name="__codelineno-232-2" href="#__codelineno-232-2"></a>
</span><span id="__span-232-3"><a id="__codelineno-232-3" name="__codelineno-232-3" href="#__codelineno-232-3"></a>hi! I&#39;m bob
</span><span id="__span-232-4"><a id="__codelineno-232-4" name="__codelineno-232-4" href="#__codelineno-232-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-232-5"><a id="__codelineno-232-5" name="__codelineno-232-5" href="#__codelineno-232-5"></a>
</span><span id="__span-232-6"><a id="__codelineno-232-6" name="__codelineno-232-6" href="#__codelineno-232-6"></a>Nice to meet you, Bob! As an AI assistant, I don&#39;t have a physical form, but I&#39;m happy to chat with you and try my best to help out however I can. Please feel free to ask me anything, and I&#39;ll do my best to provide useful information or assistance.
</span><span id="__span-232-7"><a id="__codelineno-232-7" name="__codelineno-232-7" href="#__codelineno-232-7"></a>================================[1m Human Message [0m=================================
</span><span id="__span-232-8"><a id="__codelineno-232-8" name="__codelineno-232-8" href="#__codelineno-232-8"></a>
</span><span id="__span-232-9"><a id="__codelineno-232-9" name="__codelineno-232-9" href="#__codelineno-232-9"></a>what&#39;s my name?
</span><span id="__span-232-10"><a id="__codelineno-232-10" name="__codelineno-232-10" href="#__codelineno-232-10"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-232-11"><a id="__codelineno-232-11" name="__codelineno-232-11" href="#__codelineno-232-11"></a>
</span><span id="__span-232-12"><a id="__codelineno-232-12" name="__codelineno-232-12" href="#__codelineno-232-12"></a>You said your name is Bob, so that is the name I have for you.
</span></code></pre></div>
<h2 id="filtering-messages">Filtering messages<a class="headerlink" href="#filtering-messages" title="Permanent link">#</a></h2>
<p>The most straight-forward thing to do to prevent conversation history from blowing up is to filter the list of messages before they get passed to the LLM. This involves two parts: defining a function to filter messages, and then adding it to the graph. See the example below which defines a really simple filter_messages function and then uses it.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-233-1"><a id="__codelineno-233-1" name="__codelineno-233-1" href="#__codelineno-233-1"></a>from typing import Literal
</span><span id="__span-233-2"><a id="__codelineno-233-2" name="__codelineno-233-2" href="#__codelineno-233-2"></a>
</span><span id="__span-233-3"><a id="__codelineno-233-3" name="__codelineno-233-3" href="#__codelineno-233-3"></a>from langchain_anthropic import ChatAnthropic
</span><span id="__span-233-4"><a id="__codelineno-233-4" name="__codelineno-233-4" href="#__codelineno-233-4"></a>from langchain_core.tools import tool
</span><span id="__span-233-5"><a id="__codelineno-233-5" name="__codelineno-233-5" href="#__codelineno-233-5"></a>
</span><span id="__span-233-6"><a id="__codelineno-233-6" name="__codelineno-233-6" href="#__codelineno-233-6"></a>from langgraph.checkpoint.memory import MemorySaver
</span><span id="__span-233-7"><a id="__codelineno-233-7" name="__codelineno-233-7" href="#__codelineno-233-7"></a>from langgraph.graph import MessagesState, StateGraph, START
</span><span id="__span-233-8"><a id="__codelineno-233-8" name="__codelineno-233-8" href="#__codelineno-233-8"></a>from langgraph.prebuilt import ToolNode
</span><span id="__span-233-9"><a id="__codelineno-233-9" name="__codelineno-233-9" href="#__codelineno-233-9"></a>
</span><span id="__span-233-10"><a id="__codelineno-233-10" name="__codelineno-233-10" href="#__codelineno-233-10"></a>memory = MemorySaver()
</span><span id="__span-233-11"><a id="__codelineno-233-11" name="__codelineno-233-11" href="#__codelineno-233-11"></a>
</span><span id="__span-233-12"><a id="__codelineno-233-12" name="__codelineno-233-12" href="#__codelineno-233-12"></a>
</span><span id="__span-233-13"><a id="__codelineno-233-13" name="__codelineno-233-13" href="#__codelineno-233-13"></a>@tool
</span><span id="__span-233-14"><a id="__codelineno-233-14" name="__codelineno-233-14" href="#__codelineno-233-14"></a>def search(query: str):
</span><span id="__span-233-15"><a id="__codelineno-233-15" name="__codelineno-233-15" href="#__codelineno-233-15"></a>    &quot;&quot;&quot;Call to surf the web.&quot;&quot;&quot;
</span><span id="__span-233-16"><a id="__codelineno-233-16" name="__codelineno-233-16" href="#__codelineno-233-16"></a>    # This is a placeholder for the actual implementation
</span><span id="__span-233-17"><a id="__codelineno-233-17" name="__codelineno-233-17" href="#__codelineno-233-17"></a>    # Don&#39;t let the LLM know this though 😊
</span><span id="__span-233-18"><a id="__codelineno-233-18" name="__codelineno-233-18" href="#__codelineno-233-18"></a>    return &quot;It&#39;s sunny in San Francisco, but you better look out if you&#39;re a Gemini 😈.&quot;
</span><span id="__span-233-19"><a id="__codelineno-233-19" name="__codelineno-233-19" href="#__codelineno-233-19"></a>
</span><span id="__span-233-20"><a id="__codelineno-233-20" name="__codelineno-233-20" href="#__codelineno-233-20"></a>
</span><span id="__span-233-21"><a id="__codelineno-233-21" name="__codelineno-233-21" href="#__codelineno-233-21"></a>tools = [search]
</span><span id="__span-233-22"><a id="__codelineno-233-22" name="__codelineno-233-22" href="#__codelineno-233-22"></a>tool_node = ToolNode(tools)
</span><span id="__span-233-23"><a id="__codelineno-233-23" name="__codelineno-233-23" href="#__codelineno-233-23"></a>model = ChatAnthropic(model_name=&quot;claude-3-haiku-20240307&quot;)
</span><span id="__span-233-24"><a id="__codelineno-233-24" name="__codelineno-233-24" href="#__codelineno-233-24"></a>bound_model = model.bind_tools(tools)
</span><span id="__span-233-25"><a id="__codelineno-233-25" name="__codelineno-233-25" href="#__codelineno-233-25"></a>
</span><span id="__span-233-26"><a id="__codelineno-233-26" name="__codelineno-233-26" href="#__codelineno-233-26"></a>
</span><span id="__span-233-27"><a id="__codelineno-233-27" name="__codelineno-233-27" href="#__codelineno-233-27"></a>def should_continue(state: MessagesState):
</span><span id="__span-233-28"><a id="__codelineno-233-28" name="__codelineno-233-28" href="#__codelineno-233-28"></a>    &quot;&quot;&quot;Return the next node to execute.&quot;&quot;&quot;
</span><span id="__span-233-29"><a id="__codelineno-233-29" name="__codelineno-233-29" href="#__codelineno-233-29"></a>    last_message = state[&quot;messages&quot;][-1]
</span><span id="__span-233-30"><a id="__codelineno-233-30" name="__codelineno-233-30" href="#__codelineno-233-30"></a>    # If there is no function call, then we finish
</span><span id="__span-233-31"><a id="__codelineno-233-31" name="__codelineno-233-31" href="#__codelineno-233-31"></a>    if not last_message.tool_calls:
</span><span id="__span-233-32"><a id="__codelineno-233-32" name="__codelineno-233-32" href="#__codelineno-233-32"></a>        return END
</span><span id="__span-233-33"><a id="__codelineno-233-33" name="__codelineno-233-33" href="#__codelineno-233-33"></a>    # Otherwise if there is, we continue
</span><span id="__span-233-34"><a id="__codelineno-233-34" name="__codelineno-233-34" href="#__codelineno-233-34"></a>    return &quot;action&quot;
</span><span id="__span-233-35"><a id="__codelineno-233-35" name="__codelineno-233-35" href="#__codelineno-233-35"></a>
</span><span id="__span-233-36"><a id="__codelineno-233-36" name="__codelineno-233-36" href="#__codelineno-233-36"></a>
</span><span id="__span-233-37"><a id="__codelineno-233-37" name="__codelineno-233-37" href="#__codelineno-233-37"></a>def filter_messages(messages: list):
</span><span id="__span-233-38"><a id="__codelineno-233-38" name="__codelineno-233-38" href="#__codelineno-233-38"></a>    # This is very simple helper function which only ever uses the last message
</span><span id="__span-233-39"><a id="__codelineno-233-39" name="__codelineno-233-39" href="#__codelineno-233-39"></a>    return messages[-1:]
</span><span id="__span-233-40"><a id="__codelineno-233-40" name="__codelineno-233-40" href="#__codelineno-233-40"></a>
</span><span id="__span-233-41"><a id="__codelineno-233-41" name="__codelineno-233-41" href="#__codelineno-233-41"></a>
</span><span id="__span-233-42"><a id="__codelineno-233-42" name="__codelineno-233-42" href="#__codelineno-233-42"></a># Define the function that calls the model
</span><span id="__span-233-43"><a id="__codelineno-233-43" name="__codelineno-233-43" href="#__codelineno-233-43"></a>def call_model(state: MessagesState):
</span><span id="__span-233-44"><a id="__codelineno-233-44" name="__codelineno-233-44" href="#__codelineno-233-44"></a>    messages = filter_messages(state[&quot;messages&quot;])
</span><span id="__span-233-45"><a id="__codelineno-233-45" name="__codelineno-233-45" href="#__codelineno-233-45"></a>    response = bound_model.invoke(messages)
</span><span id="__span-233-46"><a id="__codelineno-233-46" name="__codelineno-233-46" href="#__codelineno-233-46"></a>    # We return a list, because this will get added to the existing list
</span><span id="__span-233-47"><a id="__codelineno-233-47" name="__codelineno-233-47" href="#__codelineno-233-47"></a>    return {&quot;messages&quot;: response}
</span><span id="__span-233-48"><a id="__codelineno-233-48" name="__codelineno-233-48" href="#__codelineno-233-48"></a>
</span><span id="__span-233-49"><a id="__codelineno-233-49" name="__codelineno-233-49" href="#__codelineno-233-49"></a>
</span><span id="__span-233-50"><a id="__codelineno-233-50" name="__codelineno-233-50" href="#__codelineno-233-50"></a># Define a new graph
</span><span id="__span-233-51"><a id="__codelineno-233-51" name="__codelineno-233-51" href="#__codelineno-233-51"></a>workflow = StateGraph(MessagesState)
</span><span id="__span-233-52"><a id="__codelineno-233-52" name="__codelineno-233-52" href="#__codelineno-233-52"></a>
</span><span id="__span-233-53"><a id="__codelineno-233-53" name="__codelineno-233-53" href="#__codelineno-233-53"></a># Define the two nodes we will cycle between
</span><span id="__span-233-54"><a id="__codelineno-233-54" name="__codelineno-233-54" href="#__codelineno-233-54"></a>workflow.add_node(&quot;agent&quot;, call_model)
</span><span id="__span-233-55"><a id="__codelineno-233-55" name="__codelineno-233-55" href="#__codelineno-233-55"></a>workflow.add_node(&quot;action&quot;, tool_node)
</span><span id="__span-233-56"><a id="__codelineno-233-56" name="__codelineno-233-56" href="#__codelineno-233-56"></a>
</span><span id="__span-233-57"><a id="__codelineno-233-57" name="__codelineno-233-57" href="#__codelineno-233-57"></a># Set the entrypoint as `agent`
</span><span id="__span-233-58"><a id="__codelineno-233-58" name="__codelineno-233-58" href="#__codelineno-233-58"></a># This means that this node is the first one called
</span><span id="__span-233-59"><a id="__codelineno-233-59" name="__codelineno-233-59" href="#__codelineno-233-59"></a>workflow.add_edge(START, &quot;agent&quot;)
</span><span id="__span-233-60"><a id="__codelineno-233-60" name="__codelineno-233-60" href="#__codelineno-233-60"></a>
</span><span id="__span-233-61"><a id="__codelineno-233-61" name="__codelineno-233-61" href="#__codelineno-233-61"></a># We now add a conditional edge
</span><span id="__span-233-62"><a id="__codelineno-233-62" name="__codelineno-233-62" href="#__codelineno-233-62"></a>workflow.add_conditional_edges(
</span><span id="__span-233-63"><a id="__codelineno-233-63" name="__codelineno-233-63" href="#__codelineno-233-63"></a>    # First, we define the start node. We use `agent`.
</span><span id="__span-233-64"><a id="__codelineno-233-64" name="__codelineno-233-64" href="#__codelineno-233-64"></a>    # This means these are the edges taken after the `agent` node is called.
</span><span id="__span-233-65"><a id="__codelineno-233-65" name="__codelineno-233-65" href="#__codelineno-233-65"></a>    &quot;agent&quot;,
</span><span id="__span-233-66"><a id="__codelineno-233-66" name="__codelineno-233-66" href="#__codelineno-233-66"></a>    # Next, we pass in the function that will determine which node is called next.
</span><span id="__span-233-67"><a id="__codelineno-233-67" name="__codelineno-233-67" href="#__codelineno-233-67"></a>    should_continue,
</span><span id="__span-233-68"><a id="__codelineno-233-68" name="__codelineno-233-68" href="#__codelineno-233-68"></a>    # Next, we pass in the pathmap - all the possible nodes this edge could go to
</span><span id="__span-233-69"><a id="__codelineno-233-69" name="__codelineno-233-69" href="#__codelineno-233-69"></a>    [&quot;action&quot;, END],
</span><span id="__span-233-70"><a id="__codelineno-233-70" name="__codelineno-233-70" href="#__codelineno-233-70"></a>)
</span><span id="__span-233-71"><a id="__codelineno-233-71" name="__codelineno-233-71" href="#__codelineno-233-71"></a>
</span><span id="__span-233-72"><a id="__codelineno-233-72" name="__codelineno-233-72" href="#__codelineno-233-72"></a># We now add a normal edge from `tools` to `agent`.
</span><span id="__span-233-73"><a id="__codelineno-233-73" name="__codelineno-233-73" href="#__codelineno-233-73"></a># This means that after `tools` is called, `agent` node is called next.
</span><span id="__span-233-74"><a id="__codelineno-233-74" name="__codelineno-233-74" href="#__codelineno-233-74"></a>workflow.add_edge(&quot;action&quot;, &quot;agent&quot;)
</span><span id="__span-233-75"><a id="__codelineno-233-75" name="__codelineno-233-75" href="#__codelineno-233-75"></a>
</span><span id="__span-233-76"><a id="__codelineno-233-76" name="__codelineno-233-76" href="#__codelineno-233-76"></a># Finally, we compile it!
</span><span id="__span-233-77"><a id="__codelineno-233-77" name="__codelineno-233-77" href="#__codelineno-233-77"></a># This compiles it into a LangChain Runnable,
</span><span id="__span-233-78"><a id="__codelineno-233-78" name="__codelineno-233-78" href="#__codelineno-233-78"></a># meaning you can use it as you would any other runnable
</span><span id="__span-233-79"><a id="__codelineno-233-79" name="__codelineno-233-79" href="#__codelineno-233-79"></a>app = workflow.compile(checkpointer=memory)
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-234-1"><a id="__codelineno-234-1" name="__codelineno-234-1" href="#__codelineno-234-1"></a>from langchain_core.messages import HumanMessage
</span><span id="__span-234-2"><a id="__codelineno-234-2" name="__codelineno-234-2" href="#__codelineno-234-2"></a>
</span><span id="__span-234-3"><a id="__codelineno-234-3" name="__codelineno-234-3" href="#__codelineno-234-3"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}}
</span><span id="__span-234-4"><a id="__codelineno-234-4" name="__codelineno-234-4" href="#__codelineno-234-4"></a>input_message = HumanMessage(content=&quot;hi! I&#39;m bob&quot;)
</span><span id="__span-234-5"><a id="__codelineno-234-5" name="__codelineno-234-5" href="#__codelineno-234-5"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-234-6"><a id="__codelineno-234-6" name="__codelineno-234-6" href="#__codelineno-234-6"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span><span id="__span-234-7"><a id="__codelineno-234-7" name="__codelineno-234-7" href="#__codelineno-234-7"></a>
</span><span id="__span-234-8"><a id="__codelineno-234-8" name="__codelineno-234-8" href="#__codelineno-234-8"></a># This will now not remember the previous messages
</span><span id="__span-234-9"><a id="__codelineno-234-9" name="__codelineno-234-9" href="#__codelineno-234-9"></a># (because we set `messages[-1:]` in the filter messages argument)
</span><span id="__span-234-10"><a id="__codelineno-234-10" name="__codelineno-234-10" href="#__codelineno-234-10"></a>input_message = HumanMessage(content=&quot;what&#39;s my name?&quot;)
</span><span id="__span-234-11"><a id="__codelineno-234-11" name="__codelineno-234-11" href="#__codelineno-234-11"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-234-12"><a id="__codelineno-234-12" name="__codelineno-234-12" href="#__codelineno-234-12"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<p>API Reference: HumanMessage</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-235-1"><a id="__codelineno-235-1" name="__codelineno-235-1" href="#__codelineno-235-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-235-2"><a id="__codelineno-235-2" name="__codelineno-235-2" href="#__codelineno-235-2"></a>
</span><span id="__span-235-3"><a id="__codelineno-235-3" name="__codelineno-235-3" href="#__codelineno-235-3"></a>hi! I&#39;m bob
</span><span id="__span-235-4"><a id="__codelineno-235-4" name="__codelineno-235-4" href="#__codelineno-235-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-235-5"><a id="__codelineno-235-5" name="__codelineno-235-5" href="#__codelineno-235-5"></a>
</span><span id="__span-235-6"><a id="__codelineno-235-6" name="__codelineno-235-6" href="#__codelineno-235-6"></a>Nice to meet you, Bob! I&#39;m Claude, an AI assistant created by Anthropic. It&#39;s a pleasure to chat with you. Feel free to ask me anything, I&#39;m here to help!
</span><span id="__span-235-7"><a id="__codelineno-235-7" name="__codelineno-235-7" href="#__codelineno-235-7"></a>================================[1m Human Message [0m=================================
</span><span id="__span-235-8"><a id="__codelineno-235-8" name="__codelineno-235-8" href="#__codelineno-235-8"></a>
</span><span id="__span-235-9"><a id="__codelineno-235-9" name="__codelineno-235-9" href="#__codelineno-235-9"></a>what&#39;s my name?
</span><span id="__span-235-10"><a id="__codelineno-235-10" name="__codelineno-235-10" href="#__codelineno-235-10"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-235-11"><a id="__codelineno-235-11" name="__codelineno-235-11" href="#__codelineno-235-11"></a>
</span><span id="__span-235-12"><a id="__codelineno-235-12" name="__codelineno-235-12" href="#__codelineno-235-12"></a>I&#39;m afraid I don&#39;t actually know your name. As an AI assistant, I don&#39;t have information about the specific identities of the people I talk to. I only know what is provided to me during our conversation.
</span></code></pre></div>
<h1 id="how-to-delete-messages">How to delete messages<a class="headerlink" href="#how-to-delete-messages" title="Permanent link">#</a></h1>
<p>One of the common states for a graph is a list of messages. Usually you only add messages to that state. However, sometimes you may want to remove messages (either by directly modifying the state or as part of the graph). To do that, you can use the RemoveMessage modifier. In this guide, we will cover how to do that.</p>
<p>The key idea is that each state key has a reducer key. This key specifies how to combine updates to the state. The default MessagesState has a messages key, and the reducer for that key accepts these RemoveMessage modifiers. That reducer then uses these RemoveMessage to delete messages from the key.</p>
<p>So note that just because your graph state has a key that is a list of messages, it doesn't mean that that this RemoveMessage modifier will work. You also have to have a reducer defined that knows how to work with this.</p>
<p>NOTE: Many models expect certain rules around lists of messages. For example, some expect them to start with a user message, others expect all messages with tool calls to be followed by a tool message. When deleting messages, you will want to make sure you don't violate these rules.</p>
<h2 id="build-the-agent_1">Build the agent<a class="headerlink" href="#build-the-agent_1" title="Permanent link">#</a></h2>
<p>Let's now build a simple ReAct style agent.</p>
<p>from typing import Literal</p>
<p>from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool</p>
<p>from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState, StateGraph, START, END
from langgraph.prebuilt import ToolNode</p>
<p>memory = MemorySaver()</p>
<p>@tool
def search(query: str):
    """Call to surf the web."""
    # This is a placeholder for the actual implementation
    # Don't let the LLM know this though 😊
    return "It's sunny in San Francisco, but you better look out if you're a Gemini 😈."</p>
<p>tools = [search]
tool_node = ToolNode(tools)
model = ChatAnthropic(model_name="claude-3-haiku-20240307")
bound_model = model.bind_tools(tools)</p>
<p>def should_continue(state: MessagesState):
    """Return the next node to execute."""
    last_message = state["messages"][-1]
    # If there is no function call, then we finish
    if not last_message.tool_calls:
        return END
    # Otherwise if there is, we continue
    return "action"</p>
<h1 id="define-the-function-that-calls-the-model">Define the function that calls the model<a class="headerlink" href="#define-the-function-that-calls-the-model" title="Permanent link">#</a></h1>
<p>def call_model(state: MessagesState):
    response = model.invoke(state["messages"])
    # We return a list, because this will get added to the existing list
    return {"messages": response}</p>
<h1 id="define-a-new-graph">Define a new graph<a class="headerlink" href="#define-a-new-graph" title="Permanent link">#</a></h1>
<p>workflow = StateGraph(MessagesState)</p>
<h1 id="define-the-two-nodes-we-will-cycle-between">Define the two nodes we will cycle between<a class="headerlink" href="#define-the-two-nodes-we-will-cycle-between" title="Permanent link">#</a></h1>
<p>workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)</p>
<h1 id="set-the-entrypoint-as-agent">Set the entrypoint as <code>agent</code><a class="headerlink" href="#set-the-entrypoint-as-agent" title="Permanent link">#</a></h1>
<h1 id="this-means-that-this-node-is-the-first-one-called">This means that this node is the first one called<a class="headerlink" href="#this-means-that-this-node-is-the-first-one-called" title="Permanent link">#</a></h1>
<p>workflow.add_edge(START, "agent")</p>
<h1 id="we-now-add-a-conditional-edge">We now add a conditional edge<a class="headerlink" href="#we-now-add-a-conditional-edge" title="Permanent link">#</a></h1>
<p>workflow.add_conditional_edges(
    # First, we define the start node. We use <code>agent</code>.
    # This means these are the edges taken after the <code>agent</code> node is called.
    "agent",
    # Next, we pass in the function that will determine which node is called next.
    should_continue,
    # Next, we pass in the path map - all the possible nodes this edge could go to
    ["action", END],
)</p>
<h1 id="we-now-add-a-normal-edge-from-tools-to-agent">We now add a normal edge from <code>tools</code> to <code>agent</code>.<a class="headerlink" href="#we-now-add-a-normal-edge-from-tools-to-agent" title="Permanent link">#</a></h1>
<h1 id="this-means-that-after-tools-is-called-agent-node-is-called-next">This means that after <code>tools</code> is called, <code>agent</code> node is called next.<a class="headerlink" href="#this-means-that-after-tools-is-called-agent-node-is-called-next" title="Permanent link">#</a></h1>
<p>workflow.add_edge("action", "agent")</p>
<h1 id="finally-we-compile-it">Finally, we compile it!<a class="headerlink" href="#finally-we-compile-it" title="Permanent link">#</a></h1>
<h1 id="this-compiles-it-into-a-langchain-runnable">This compiles it into a LangChain Runnable,<a class="headerlink" href="#this-compiles-it-into-a-langchain-runnable" title="Permanent link">#</a></h1>
<h1 id="meaning-you-can-use-it-as-you-would-any-other-runnable">meaning you can use it as you would any other runnable<a class="headerlink" href="#meaning-you-can-use-it-as-you-would-any-other-runnable" title="Permanent link">#</a></h1>
<p>app = workflow.compile(checkpointer=memory)</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-236-1"><a id="__codelineno-236-1" name="__codelineno-236-1" href="#__codelineno-236-1"></a>from langchain_core.messages import HumanMessage
</span><span id="__span-236-2"><a id="__codelineno-236-2" name="__codelineno-236-2" href="#__codelineno-236-2"></a>
</span><span id="__span-236-3"><a id="__codelineno-236-3" name="__codelineno-236-3" href="#__codelineno-236-3"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;2&quot;}}
</span><span id="__span-236-4"><a id="__codelineno-236-4" name="__codelineno-236-4" href="#__codelineno-236-4"></a>input_message = HumanMessage(content=&quot;hi! I&#39;m bob&quot;)
</span><span id="__span-236-5"><a id="__codelineno-236-5" name="__codelineno-236-5" href="#__codelineno-236-5"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-236-6"><a id="__codelineno-236-6" name="__codelineno-236-6" href="#__codelineno-236-6"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span><span id="__span-236-7"><a id="__codelineno-236-7" name="__codelineno-236-7" href="#__codelineno-236-7"></a>
</span><span id="__span-236-8"><a id="__codelineno-236-8" name="__codelineno-236-8" href="#__codelineno-236-8"></a>
</span><span id="__span-236-9"><a id="__codelineno-236-9" name="__codelineno-236-9" href="#__codelineno-236-9"></a>input_message = HumanMessage(content=&quot;what&#39;s my name?&quot;)
</span><span id="__span-236-10"><a id="__codelineno-236-10" name="__codelineno-236-10" href="#__codelineno-236-10"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-236-11"><a id="__codelineno-236-11" name="__codelineno-236-11" href="#__codelineno-236-11"></a>    event[&quot;messages&quot;][-1].pretty_print()
</span></code></pre></div>
<p>API Reference: HumanMessage</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-237-1"><a id="__codelineno-237-1" name="__codelineno-237-1" href="#__codelineno-237-1"></a>================================[1m Human Message [0m=================================
</span><span id="__span-237-2"><a id="__codelineno-237-2" name="__codelineno-237-2" href="#__codelineno-237-2"></a>
</span><span id="__span-237-3"><a id="__codelineno-237-3" name="__codelineno-237-3" href="#__codelineno-237-3"></a>hi! I&#39;m bob
</span><span id="__span-237-4"><a id="__codelineno-237-4" name="__codelineno-237-4" href="#__codelineno-237-4"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-237-5"><a id="__codelineno-237-5" name="__codelineno-237-5" href="#__codelineno-237-5"></a>
</span><span id="__span-237-6"><a id="__codelineno-237-6" name="__codelineno-237-6" href="#__codelineno-237-6"></a>It&#39;s nice to meet you, Bob! I&#39;m an AI assistant created by Anthropic. I&#39;m here to help out with any questions or tasks you might have. Please let me know if there&#39;s anything I can assist you with.
</span><span id="__span-237-7"><a id="__codelineno-237-7" name="__codelineno-237-7" href="#__codelineno-237-7"></a>================================[1m Human Message [0m=================================
</span><span id="__span-237-8"><a id="__codelineno-237-8" name="__codelineno-237-8" href="#__codelineno-237-8"></a>
</span><span id="__span-237-9"><a id="__codelineno-237-9" name="__codelineno-237-9" href="#__codelineno-237-9"></a>what&#39;s my name?
</span><span id="__span-237-10"><a id="__codelineno-237-10" name="__codelineno-237-10" href="#__codelineno-237-10"></a>==================================[1m Ai Message [0m==================================
</span><span id="__span-237-11"><a id="__codelineno-237-11" name="__codelineno-237-11" href="#__codelineno-237-11"></a>
</span><span id="__span-237-12"><a id="__codelineno-237-12" name="__codelineno-237-12" href="#__codelineno-237-12"></a>You said your name is Bob.
</span></code></pre></div>
<h2 id="manually-deleting-messages">Manually deleting messages<a class="headerlink" href="#manually-deleting-messages" title="Permanent link">#</a></h2>
<p>First, we will cover how to manually delete messages. Let's take a look at the current state of the thread:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-238-1"><a id="__codelineno-238-1" name="__codelineno-238-1" href="#__codelineno-238-1"></a>messages = app.get_state(config).values[&quot;messages&quot;]
</span><span id="__span-238-2"><a id="__codelineno-238-2" name="__codelineno-238-2" href="#__codelineno-238-2"></a>messages
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-239-1"><a id="__codelineno-239-1" name="__codelineno-239-1" href="#__codelineno-239-1"></a>[HumanMessage(content=&quot;hi! I&#39;m bob&quot;, additional_kwargs={}, response_metadata={}, id=&#39;db576005-3a60-4b3b-8925-dc602ac1c571&#39;),
</span><span id="__span-239-2"><a id="__codelineno-239-2" name="__codelineno-239-2" href="#__codelineno-239-2"></a> AIMessage(content=&quot;It&#39;s nice to meet you, Bob! I&#39;m an AI assistant created by Anthropic. I&#39;m here to help out with any questions or tasks you might have. Please let me know if there&#39;s anything I can assist you with.&quot;, additional_kwargs={}, response_metadata={&#39;id&#39;: &#39;msg_01BKAnYxmoC6bQ9PpCuHk8ZT&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 52}}, id=&#39;run-3a60c536-b207-4c56-98f3-03f94d49a9e4-0&#39;, usage_metadata={&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 52, &#39;total_tokens&#39;: 64}),
</span><span id="__span-239-3"><a id="__codelineno-239-3" name="__codelineno-239-3" href="#__codelineno-239-3"></a> HumanMessage(content=&quot;what&#39;s my name?&quot;, additional_kwargs={}, response_metadata={}, id=&#39;2088c465-400b-430b-ad80-fad47dc1f2d6&#39;),
</span><span id="__span-239-4"><a id="__codelineno-239-4" name="__codelineno-239-4" href="#__codelineno-239-4"></a> AIMessage(content=&#39;You said your name is Bob.&#39;, additional_kwargs={}, response_metadata={&#39;id&#39;: &#39;msg_013UWTLTzwZi81vke8mMQ2KP&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 72, &#39;output_tokens&#39;: 10}}, id=&#39;run-3a6883be-0c52-4938-af98-e9e7476659eb-0&#39;, usage_metadata={&#39;input_tokens&#39;: 72, &#39;output_tokens&#39;: 10, &#39;total_tokens&#39;: 82})]
</span><span id="__span-239-5"><a id="__codelineno-239-5" name="__codelineno-239-5" href="#__codelineno-239-5"></a> ```
</span><span id="__span-239-6"><a id="__codelineno-239-6" name="__codelineno-239-6" href="#__codelineno-239-6"></a>
</span><span id="__span-239-7"><a id="__codelineno-239-7" name="__codelineno-239-7" href="#__codelineno-239-7"></a> We can call update_state and pass in the id of the first message. This will delete that message.
</span><span id="__span-239-8"><a id="__codelineno-239-8" name="__codelineno-239-8" href="#__codelineno-239-8"></a>
</span><span id="__span-239-9"><a id="__codelineno-239-9" name="__codelineno-239-9" href="#__codelineno-239-9"></a> ```
</span><span id="__span-239-10"><a id="__codelineno-239-10" name="__codelineno-239-10" href="#__codelineno-239-10"></a> from langchain_core.messages import RemoveMessage
</span><span id="__span-239-11"><a id="__codelineno-239-11" name="__codelineno-239-11" href="#__codelineno-239-11"></a>
</span><span id="__span-239-12"><a id="__codelineno-239-12" name="__codelineno-239-12" href="#__codelineno-239-12"></a>app.update_state(config, {&quot;messages&quot;: RemoveMessage(id=messages[0].id)})
</span></code></pre></div>
<p>API Reference: RemoveMessage</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-240-1"><a id="__codelineno-240-1" name="__codelineno-240-1" href="#__codelineno-240-1"></a>{&#39;configurable&#39;: {&#39;thread_id&#39;: &#39;2&#39;,
</span><span id="__span-240-2"><a id="__codelineno-240-2" name="__codelineno-240-2" href="#__codelineno-240-2"></a>  &#39;checkpoint_ns&#39;: &#39;&#39;,
</span><span id="__span-240-3"><a id="__codelineno-240-3" name="__codelineno-240-3" href="#__codelineno-240-3"></a>  &#39;checkpoint_id&#39;: &#39;1ef75157-f251-6a2a-8005-82a86a6593a0&#39;}}
</span></code></pre></div>
<p>If we now look at the messages, we can verify that the first one was deleted.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-241-1"><a id="__codelineno-241-1" name="__codelineno-241-1" href="#__codelineno-241-1"></a>messages = app.get_state(config).values[&quot;messages&quot;]
</span><span id="__span-241-2"><a id="__codelineno-241-2" name="__codelineno-241-2" href="#__codelineno-241-2"></a>messages
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-242-1"><a id="__codelineno-242-1" name="__codelineno-242-1" href="#__codelineno-242-1"></a>[AIMessage(content=&quot;It&#39;s nice to meet you, Bob! I&#39;m Claude, an AI assistant created by Anthropic. How can I assist you today?&quot;, response_metadata={&#39;id&#39;: &#39;msg_01XPSAenmSqK8rX2WgPZHfz7&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 32}}, id=&#39;run-1c69af09-adb1-412d-9010-2456e5a555fb-0&#39;, usage_metadata={&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 32, &#39;total_tokens&#39;: 44}),
</span><span id="__span-242-2"><a id="__codelineno-242-2" name="__codelineno-242-2" href="#__codelineno-242-2"></a> HumanMessage(content=&quot;what&#39;s my name?&quot;, id=&#39;f3c71afe-8ce2-4ed0-991e-65021f03b0a5&#39;),
</span><span id="__span-242-3"><a id="__codelineno-242-3" name="__codelineno-242-3" href="#__codelineno-242-3"></a> AIMessage(content=&#39;Your name is Bob, as you introduced yourself at the beginning of our conversation.&#39;, response_metadata={&#39;id&#39;: &#39;msg_01BPZdwsjuMAbC1YAkqawXaF&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 52, &#39;output_tokens&#39;: 19}}, id=&#39;run-b2eb9137-2f4e-446f-95f5-3d5f621a2cf8-0&#39;, usage_metadata={&#39;input_tokens&#39;: 52, &#39;output_tokens&#39;: 19, &#39;total_tokens&#39;: 71})]
</span><span id="__span-242-4"><a id="__codelineno-242-4" name="__codelineno-242-4" href="#__codelineno-242-4"></a> ```
</span><span id="__span-242-5"><a id="__codelineno-242-5" name="__codelineno-242-5" href="#__codelineno-242-5"></a>
</span><span id="__span-242-6"><a id="__codelineno-242-6" name="__codelineno-242-6" href="#__codelineno-242-6"></a> ## Programmatically deleting messages
</span><span id="__span-242-7"><a id="__codelineno-242-7" name="__codelineno-242-7" href="#__codelineno-242-7"></a>
</span><span id="__span-242-8"><a id="__codelineno-242-8" name="__codelineno-242-8" href="#__codelineno-242-8"></a> We can also delete messages programmatically from inside the graph. Here we&#39;ll modify the graph to delete any old messages (longer than 3 messages ago) at the end of a graph run.
</span><span id="__span-242-9"><a id="__codelineno-242-9" name="__codelineno-242-9" href="#__codelineno-242-9"></a>
</span><span id="__span-242-10"><a id="__codelineno-242-10" name="__codelineno-242-10" href="#__codelineno-242-10"></a> ```
</span><span id="__span-242-11"><a id="__codelineno-242-11" name="__codelineno-242-11" href="#__codelineno-242-11"></a> from langchain_core.messages import RemoveMessage
</span><span id="__span-242-12"><a id="__codelineno-242-12" name="__codelineno-242-12" href="#__codelineno-242-12"></a>from langgraph.graph import END
</span><span id="__span-242-13"><a id="__codelineno-242-13" name="__codelineno-242-13" href="#__codelineno-242-13"></a>
</span><span id="__span-242-14"><a id="__codelineno-242-14" name="__codelineno-242-14" href="#__codelineno-242-14"></a>
</span><span id="__span-242-15"><a id="__codelineno-242-15" name="__codelineno-242-15" href="#__codelineno-242-15"></a>def delete_messages(state):
</span><span id="__span-242-16"><a id="__codelineno-242-16" name="__codelineno-242-16" href="#__codelineno-242-16"></a>    messages = state[&quot;messages&quot;]
</span><span id="__span-242-17"><a id="__codelineno-242-17" name="__codelineno-242-17" href="#__codelineno-242-17"></a>    if len(messages) &gt; 3:
</span><span id="__span-242-18"><a id="__codelineno-242-18" name="__codelineno-242-18" href="#__codelineno-242-18"></a>        return {&quot;messages&quot;: [RemoveMessage(id=m.id) for m in messages[:-3]]}
</span><span id="__span-242-19"><a id="__codelineno-242-19" name="__codelineno-242-19" href="#__codelineno-242-19"></a>
</span><span id="__span-242-20"><a id="__codelineno-242-20" name="__codelineno-242-20" href="#__codelineno-242-20"></a>
</span><span id="__span-242-21"><a id="__codelineno-242-21" name="__codelineno-242-21" href="#__codelineno-242-21"></a># We need to modify the logic to call delete_messages rather than end right away
</span><span id="__span-242-22"><a id="__codelineno-242-22" name="__codelineno-242-22" href="#__codelineno-242-22"></a>def should_continue(state: MessagesState) -&gt; Literal[&quot;action&quot;, &quot;delete_messages&quot;]:
</span><span id="__span-242-23"><a id="__codelineno-242-23" name="__codelineno-242-23" href="#__codelineno-242-23"></a>    &quot;&quot;&quot;Return the next node to execute.&quot;&quot;&quot;
</span><span id="__span-242-24"><a id="__codelineno-242-24" name="__codelineno-242-24" href="#__codelineno-242-24"></a>    last_message = state[&quot;messages&quot;][-1]
</span><span id="__span-242-25"><a id="__codelineno-242-25" name="__codelineno-242-25" href="#__codelineno-242-25"></a>    # If there is no function call, then we call our delete_messages function
</span><span id="__span-242-26"><a id="__codelineno-242-26" name="__codelineno-242-26" href="#__codelineno-242-26"></a>    if not last_message.tool_calls:
</span><span id="__span-242-27"><a id="__codelineno-242-27" name="__codelineno-242-27" href="#__codelineno-242-27"></a>        return &quot;delete_messages&quot;
</span><span id="__span-242-28"><a id="__codelineno-242-28" name="__codelineno-242-28" href="#__codelineno-242-28"></a>    # Otherwise if there is, we continue
</span><span id="__span-242-29"><a id="__codelineno-242-29" name="__codelineno-242-29" href="#__codelineno-242-29"></a>    return &quot;action&quot;
</span><span id="__span-242-30"><a id="__codelineno-242-30" name="__codelineno-242-30" href="#__codelineno-242-30"></a>
</span><span id="__span-242-31"><a id="__codelineno-242-31" name="__codelineno-242-31" href="#__codelineno-242-31"></a>
</span><span id="__span-242-32"><a id="__codelineno-242-32" name="__codelineno-242-32" href="#__codelineno-242-32"></a># Define a new graph
</span><span id="__span-242-33"><a id="__codelineno-242-33" name="__codelineno-242-33" href="#__codelineno-242-33"></a>workflow = StateGraph(MessagesState)
</span><span id="__span-242-34"><a id="__codelineno-242-34" name="__codelineno-242-34" href="#__codelineno-242-34"></a>workflow.add_node(&quot;agent&quot;, call_model)
</span><span id="__span-242-35"><a id="__codelineno-242-35" name="__codelineno-242-35" href="#__codelineno-242-35"></a>workflow.add_node(&quot;action&quot;, tool_node)
</span><span id="__span-242-36"><a id="__codelineno-242-36" name="__codelineno-242-36" href="#__codelineno-242-36"></a>
</span><span id="__span-242-37"><a id="__codelineno-242-37" name="__codelineno-242-37" href="#__codelineno-242-37"></a># This is our new node we&#39;re defining
</span><span id="__span-242-38"><a id="__codelineno-242-38" name="__codelineno-242-38" href="#__codelineno-242-38"></a>workflow.add_node(delete_messages)
</span><span id="__span-242-39"><a id="__codelineno-242-39" name="__codelineno-242-39" href="#__codelineno-242-39"></a>
</span><span id="__span-242-40"><a id="__codelineno-242-40" name="__codelineno-242-40" href="#__codelineno-242-40"></a>
</span><span id="__span-242-41"><a id="__codelineno-242-41" name="__codelineno-242-41" href="#__codelineno-242-41"></a>workflow.add_edge(START, &quot;agent&quot;)
</span><span id="__span-242-42"><a id="__codelineno-242-42" name="__codelineno-242-42" href="#__codelineno-242-42"></a>workflow.add_conditional_edges(
</span><span id="__span-242-43"><a id="__codelineno-242-43" name="__codelineno-242-43" href="#__codelineno-242-43"></a>    &quot;agent&quot;,
</span><span id="__span-242-44"><a id="__codelineno-242-44" name="__codelineno-242-44" href="#__codelineno-242-44"></a>    should_continue,
</span><span id="__span-242-45"><a id="__codelineno-242-45" name="__codelineno-242-45" href="#__codelineno-242-45"></a>)
</span><span id="__span-242-46"><a id="__codelineno-242-46" name="__codelineno-242-46" href="#__codelineno-242-46"></a>workflow.add_edge(&quot;action&quot;, &quot;agent&quot;)
</span><span id="__span-242-47"><a id="__codelineno-242-47" name="__codelineno-242-47" href="#__codelineno-242-47"></a>
</span><span id="__span-242-48"><a id="__codelineno-242-48" name="__codelineno-242-48" href="#__codelineno-242-48"></a># This is the new edge we&#39;re adding: after we delete messages, we finish
</span><span id="__span-242-49"><a id="__codelineno-242-49" name="__codelineno-242-49" href="#__codelineno-242-49"></a>workflow.add_edge(&quot;delete_messages&quot;, END)
</span><span id="__span-242-50"><a id="__codelineno-242-50" name="__codelineno-242-50" href="#__codelineno-242-50"></a>app = workflow.compile(checkpointer=memory)
</span></code></pre></div>
<p>We can now try this out. We can call the graph twice and then check the state</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-243-1"><a id="__codelineno-243-1" name="__codelineno-243-1" href="#__codelineno-243-1"></a>from langchain_core.messages import HumanMessage
</span><span id="__span-243-2"><a id="__codelineno-243-2" name="__codelineno-243-2" href="#__codelineno-243-2"></a>
</span><span id="__span-243-3"><a id="__codelineno-243-3" name="__codelineno-243-3" href="#__codelineno-243-3"></a>config = {&quot;configurable&quot;: {&quot;thread_id&quot;: &quot;3&quot;}}
</span><span id="__span-243-4"><a id="__codelineno-243-4" name="__codelineno-243-4" href="#__codelineno-243-4"></a>input_message = HumanMessage(content=&quot;hi! I&#39;m bob&quot;)
</span><span id="__span-243-5"><a id="__codelineno-243-5" name="__codelineno-243-5" href="#__codelineno-243-5"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-243-6"><a id="__codelineno-243-6" name="__codelineno-243-6" href="#__codelineno-243-6"></a>    print([(message.type, message.content) for message in event[&quot;messages&quot;]])
</span><span id="__span-243-7"><a id="__codelineno-243-7" name="__codelineno-243-7" href="#__codelineno-243-7"></a>
</span><span id="__span-243-8"><a id="__codelineno-243-8" name="__codelineno-243-8" href="#__codelineno-243-8"></a>
</span><span id="__span-243-9"><a id="__codelineno-243-9" name="__codelineno-243-9" href="#__codelineno-243-9"></a>input_message = HumanMessage(content=&quot;what&#39;s my name?&quot;)
</span><span id="__span-243-10"><a id="__codelineno-243-10" name="__codelineno-243-10" href="#__codelineno-243-10"></a>for event in app.stream({&quot;messages&quot;: [input_message]}, config, stream_mode=&quot;values&quot;):
</span><span id="__span-243-11"><a id="__codelineno-243-11" name="__codelineno-243-11" href="#__codelineno-243-11"></a>    print([(message.type, message.content) for message in event[&quot;messages&quot;]])
</span></code></pre></div>
<p>API Reference: HumanMessage</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-244-1"><a id="__codelineno-244-1" name="__codelineno-244-1" href="#__codelineno-244-1"></a>[(&#39;human&#39;, &quot;hi! I&#39;m bob&quot;)]
</span><span id="__span-244-2"><a id="__codelineno-244-2" name="__codelineno-244-2" href="#__codelineno-244-2"></a>[(&#39;human&#39;, &quot;hi! I&#39;m bob&quot;), (&#39;ai&#39;, &quot;Hello Bob! It&#39;s nice to meet you. I&#39;m an AI assistant created by Anthropic. I&#39;m here to help with any questions or tasks you might have. Please let me know how I can assist you.&quot;)]
</span><span id="__span-244-3"><a id="__codelineno-244-3" name="__codelineno-244-3" href="#__codelineno-244-3"></a>[(&#39;human&#39;, &quot;hi! I&#39;m bob&quot;), (&#39;ai&#39;, &quot;Hello Bob! It&#39;s nice to meet you. I&#39;m an AI assistant created by Anthropic. I&#39;m here to help with any questions or tasks you might have. Please let me know how I can assist you.&quot;), (&#39;human&#39;, &quot;what&#39;s my name?&quot;)]
</span><span id="__span-244-4"><a id="__codelineno-244-4" name="__codelineno-244-4" href="#__codelineno-244-4"></a>[(&#39;human&#39;, &quot;hi! I&#39;m bob&quot;), (&#39;ai&#39;, &quot;Hello Bob! It&#39;s nice to meet you. I&#39;m an AI assistant created by Anthropic. I&#39;m here to help with any questions or tasks you might have. Please let me know how I can assist you.&quot;), (&#39;human&#39;, &quot;what&#39;s my name?&quot;), (&#39;ai&#39;, &#39;You said your name is Bob, so that is the name I have for you.&#39;)]
</span><span id="__span-244-5"><a id="__codelineno-244-5" name="__codelineno-244-5" href="#__codelineno-244-5"></a>[(&#39;ai&#39;, &quot;Hello Bob! It&#39;s nice to meet you. I&#39;m an AI assistant created by Anthropic. I&#39;m here to help with any questions or tasks you might have. Please let me know how I can assist you.&quot;), (&#39;human&#39;, &quot;what&#39;s my name?&quot;), (&#39;ai&#39;, &#39;You said your name is Bob, so that is the name I have for you.&#39;)]
</span></code></pre></div>
<p>If we now check the state, we should see that it is only three messages long. This is because we just deleted the earlier messages - otherwise it would be four!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-245-1"><a id="__codelineno-245-1" name="__codelineno-245-1" href="#__codelineno-245-1"></a>messages = app.get_state(config).values[&quot;messages&quot;]
</span><span id="__span-245-2"><a id="__codelineno-245-2" name="__codelineno-245-2" href="#__codelineno-245-2"></a>messages
</span></code></pre></div>
<p><div class="language-text highlight"><pre><span></span><code><span id="__span-246-1"><a id="__codelineno-246-1" name="__codelineno-246-1" href="#__codelineno-246-1"></a>[AIMessage(content=&quot;Hello Bob! It&#39;s nice to meet you. I&#39;m an AI assistant created by Anthropic. I&#39;m here to help with any questions or tasks you might have. Please let me know how I can assist you.&quot;, response_metadata={&#39;id&#39;: &#39;msg_01XPEgPPbcnz5BbGWUDWTmzG&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 48}}, id=&#39;run-eded3820-b6a9-4d66-9210-03ca41787ce6-0&#39;, usage_metadata={&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 48, &#39;total_tokens&#39;: 60}),
</span><span id="__span-246-2"><a id="__codelineno-246-2" name="__codelineno-246-2" href="#__codelineno-246-2"></a> HumanMessage(content=&quot;what&#39;s my name?&quot;, id=&#39;a0ea2097-3280-402b-92e1-67177b807ae8&#39;),
</span><span id="__span-246-3"><a id="__codelineno-246-3" name="__codelineno-246-3" href="#__codelineno-246-3"></a> AIMessage(content=&#39;You said your name is Bob, so that is the name I have for you.&#39;, response_metadata={&#39;id&#39;: &#39;msg_01JGT62pxhrhN4SykZ57CSjW&#39;, &#39;model&#39;: &#39;claude-3-haiku-20240307&#39;, &#39;stop_reason&#39;: &#39;end_turn&#39;, &#39;stop_sequence&#39;: None, &#39;usage&#39;: {&#39;input_tokens&#39;: 68, &#39;output_tokens&#39;: 20}}, id=&#39;run-ace3519c-81f8-45fe-a777-91f42d48b3a3-0&#39;, usage_metadata={&#39;input_tokens&#39;: 68, &#39;output_tokens&#39;: 20, &#39;total_tokens&#39;: 88})]
</span><span id="__span-246-4"><a id="__codelineno-246-4" name="__codelineno-246-4" href="#__codelineno-246-4"></a> ```
</span><span id="__span-246-5"><a id="__codelineno-246-5" name="__codelineno-246-5" href="#__codelineno-246-5"></a>
</span><span id="__span-246-6"><a id="__codelineno-246-6" name="__codelineno-246-6" href="#__codelineno-246-6"></a> Remember, when deleting messages you will want to make sure that the remaining message list is still valid. This message list may actually not be - this is because it currently starts with an AI message, which some models do not allow.
</span><span id="__span-246-7"><a id="__codelineno-246-7" name="__codelineno-246-7" href="#__codelineno-246-7"></a>
</span><span id="__span-246-8"><a id="__codelineno-246-8" name="__codelineno-246-8" href="#__codelineno-246-8"></a> # How to add summary of the conversation history
</span><span id="__span-246-9"><a id="__codelineno-246-9" name="__codelineno-246-9" href="#__codelineno-246-9"></a> One of the most common use cases for persistence is to use it to keep track of conversation history. This is great - it makes it easy to continue conversations. As conversations get longer and longer, however, this conversation history can build up and take up more and more of the context window. This can often be undesirable as it leads to more expensive and longer calls to the LLM, and potentially ones that error. One way to work around that is to create a summary of the conversation to date, and use that with the past N messages. This guide will go through an example of how to do that.
</span><span id="__span-246-10"><a id="__codelineno-246-10" name="__codelineno-246-10" href="#__codelineno-246-10"></a>
</span><span id="__span-246-11"><a id="__codelineno-246-11" name="__codelineno-246-11" href="#__codelineno-246-11"></a> This will involve a few steps:
</span><span id="__span-246-12"><a id="__codelineno-246-12" name="__codelineno-246-12" href="#__codelineno-246-12"></a>
</span><span id="__span-246-13"><a id="__codelineno-246-13" name="__codelineno-246-13" href="#__codelineno-246-13"></a>
</span><span id="__span-246-14"><a id="__codelineno-246-14" name="__codelineno-246-14" href="#__codelineno-246-14"></a>- Check if the conversation is too long (can be done by checking number of messages or length of messages)
</span><span id="__span-246-15"><a id="__codelineno-246-15" name="__codelineno-246-15" href="#__codelineno-246-15"></a>- If yes, the create summary (will need a prompt for this)
</span><span id="__span-246-16"><a id="__codelineno-246-16" name="__codelineno-246-16" href="#__codelineno-246-16"></a>- Then remove all except the last N messages
</span><span id="__span-246-17"><a id="__codelineno-246-17" name="__codelineno-246-17" href="#__codelineno-246-17"></a>
</span><span id="__span-246-18"><a id="__codelineno-246-18" name="__codelineno-246-18" href="#__codelineno-246-18"></a>## Build the chatbot
</span></code></pre></div>
from typing import Literal</p>
<p>from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState, StateGraph, START, END</p>
<p>memory = MemorySaver()</p>
<h1 id="we-will-add-a-summary-attribute-in-addition-to-messages-key">We will add a <code>summary</code> attribute (in addition to <code>messages</code> key,<a class="headerlink" href="#we-will-add-a-summary-attribute-in-addition-to-messages-key" title="Permanent link">#</a></h1>
<h1 id="which-messagesstate-already-has">which MessagesState already has)<a class="headerlink" href="#which-messagesstate-already-has" title="Permanent link">#</a></h1>
<p>class State(MessagesState):
    summary: str</p>
<h1 id="we-will-use-this-model-for-both-the-conversation-and-the-summarization">We will use this model for both the conversation and the summarization<a class="headerlink" href="#we-will-use-this-model-for-both-the-conversation-and-the-summarization" title="Permanent link">#</a></h1>
<p>model = ChatAnthropic(model_name="claude-3-haiku-20240307")</p>
<h1 id="define-the-logic-to-call-the-model">Define the logic to call the model<a class="headerlink" href="#define-the-logic-to-call-the-model" title="Permanent link">#</a></h1>
<p>def call_model(state: State):
    # If a summary exists, we add this in as a system message
    summary = state.get("summary", "")
    if summary:
        system_message = f"Summary of conversation earlier: {summary}"
        messages = [SystemMessage(content=system_message)] + state["messages"]
    else:
        messages = state["messages"]
    response = model.invoke(messages)
    # We return a list, because this will get added to the existing list
    return {"messages": [response]}</p>
<h1 id="we-now-define-the-logic-for-determining-whether-to-end-or-summarize-the-conversation">We now define the logic for determining whether to end or summarize the conversation<a class="headerlink" href="#we-now-define-the-logic-for-determining-whether-to-end-or-summarize-the-conversation" title="Permanent link">#</a></h1>
<p>def should_continue(state: State) -&gt; Literal["summarize_conversation", END]:
    """Return the next node to execute."""
    messages = state["messages"]
    # If there are more than six messages, then we summarize the conversation
    if len(messages) &gt; 6:
        return "summarize_conversation"
    # Otherwise we can just end
    return END</p>
<p>def summarize_conversation(state: State):
    # First, we summarize the conversation
    summary = state.get("summary", "")
    if summary:
        # If a summary already exists, we use a different system prompt
        # to summarize it than if one didn't
        summary_message = (
            f"This is summary of the conversation to date: {summary}\n\n"
            "Extend the summary by taking into account the new messages above:"
        )
    else:
        summary_message = "Create a summary of the conversation above:"</p>
<div class="language-text highlight"><pre><span></span><code>messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)]
response = model.invoke(messages)
# We now need to delete messages that we no longer want to show up
# I will delete all but the last two messages, but you can change this
delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]
return {&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages}
</code></pre></div>
<h1 id="define-a-new-graph_1">Define a new graph<a class="headerlink" href="#define-a-new-graph_1" title="Permanent link">#</a></h1>
<p>workflow = StateGraph(State)</p>
<h1 id="define-the-conversation-node-and-the-summarize-node">Define the conversation node and the summarize node<a class="headerlink" href="#define-the-conversation-node-and-the-summarize-node" title="Permanent link">#</a></h1>
<p>workflow.add_node("conversation", call_model)
workflow.add_node(summarize_conversation)</p>
<h1 id="set-the-entrypoint-as-conversation">Set the entrypoint as conversation<a class="headerlink" href="#set-the-entrypoint-as-conversation" title="Permanent link">#</a></h1>
<p>workflow.add_edge(START, "conversation")</p>
<h1 id="we-now-add-a-conditional-edge_1">We now add a conditional edge<a class="headerlink" href="#we-now-add-a-conditional-edge_1" title="Permanent link">#</a></h1>
<p>workflow.add_conditional_edges(
    # First, we define the start node. We use <code>conversation</code>.
    # This means these are the edges taken after the <code>conversation</code> node is called.
    "conversation",
    # Next, we pass in the function that will determine which node is called next.
    should_continue,
)</p>
<h1 id="we-now-add-a-normal-edge-from-summarize_conversation-to-end">We now add a normal edge from <code>summarize_conversation</code> to END.<a class="headerlink" href="#we-now-add-a-normal-edge-from-summarize_conversation-to-end" title="Permanent link">#</a></h1>
<h1 id="this-means-that-after-summarize_conversation-is-called-we-end">This means that after <code>summarize_conversation</code> is called, we end.<a class="headerlink" href="#this-means-that-after-summarize_conversation-is-called-we-end" title="Permanent link">#</a></h1>
<p>workflow.add_edge("summarize_conversation", END)</p>
<h1 id="finally-we-compile-it_1">Finally, we compile it!<a class="headerlink" href="#finally-we-compile-it_1" title="Permanent link">#</a></h1>
<p>app = workflow.compile(checkpointer=memory)
<div class="language-text highlight"><pre><span></span><code><span id="__span-247-1"><a id="__codelineno-247-1" name="__codelineno-247-1" href="#__codelineno-247-1"></a>## Using the graph
</span></code></pre></div>
def print_update(update):
    for k, v in update.items():
        for m in v["messages"]:
            m.pretty_print()
        if "summary" in v:
            print(v["summary"])
<div class="language-text highlight"><pre><span></span><code><span id="__span-248-1"><a id="__codelineno-248-1" name="__codelineno-248-1" href="#__codelineno-248-1"></a>
</span></code></pre></div>
from langchain_core.messages import HumanMessage</p>
<p>config = {"configurable": {"thread_id": "4"}}
input_message = HumanMessage(content="hi! I'm bob")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)</p>
<p>input_message = HumanMessage(content="what's my name?")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)</p>
<p>input_message = HumanMessage(content="i like the celtics!")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
<div class="language-text highlight"><pre><span></span><code><span id="__span-249-1"><a id="__codelineno-249-1" name="__codelineno-249-1" href="#__codelineno-249-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>hi! I'm bob
==================================[1m Ai Message [0m==================================</p>
<p>It's nice to meet you, Bob! I'm an AI assistant created by Anthropic. How can I help you today?
================================[1m Human Message [0m=================================</p>
<p>what's my name?
==================================[1m Ai Message [0m==================================</p>
<p>Your name is Bob, as you told me at the beginning of our conversation.
================================[1m Human Message [0m=================================</p>
<p>i like the celtics!
==================================[1m Ai Message [0m==================================</p>
<p>That's great, the Celtics are a fun team to follow! Basketball is an exciting sport. Do you have a favorite Celtics player or a favorite moment from a Celtics game you've watched? I'd be happy to discuss the team and the sport with you.
<div class="language-text highlight"><pre><span></span><code><span id="__span-250-1"><a id="__codelineno-250-1" name="__codelineno-250-1" href="#__codelineno-250-1"></a>We can see that so far no summarization has happened - this is because there are only six messages in the list.
</span></code></pre></div>
values = app.get_state(config).values
values
<div class="language-text highlight"><pre><span></span><code><span id="__span-251-1"><a id="__codelineno-251-1" name="__codelineno-251-1" href="#__codelineno-251-1"></a>Now let&#39;s send another message in
</span></code></pre></div>
input_message = HumanMessage(content="i like how much they win")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
<div class="language-text highlight"><pre><span></span><code><span id="__span-252-1"><a id="__codelineno-252-1" name="__codelineno-252-1" href="#__codelineno-252-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>i like how much they win
==================================[1m Ai Message [0m==================================</p>
<p>That's understandable, the Celtics have been one of the more successful NBA franchises over the years. Their history of winning championships is very impressive. It's always fun to follow a team that regularly competes for titles. What do you think has been the key to the Celtics' sustained success? Is there a particular era or team that stands out as your favorite?
================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>Here is a summary of our conversation so far:</p>
<ul>
<li>You introduced yourself as Bob and said you like the Boston Celtics basketball team.</li>
<li>I acknowledged that it's nice to meet you, Bob, and noted that you had shared your name earlier in the conversation.</li>
<li>You expressed that you like how much the Celtics win, and I agreed that their history of sustained success and championship pedigree is impressive.</li>
<li>I asked if you have a favorite Celtics player or moment that stands out to you, and invited further discussion about the team and the sport of basketball.</li>
<li>The overall tone has been friendly and conversational, with me trying to engage with your interest in the Celtics by asking follow-up questions.
<div class="language-text highlight"><pre><span></span><code><span id="__span-253-1"><a id="__codelineno-253-1" name="__codelineno-253-1" href="#__codelineno-253-1"></a>If we check the state now, we can see that we have a summary of the conversation, as well as the last two messages
</span></code></pre></div>
values = app.get_state(config).values
values
<div class="language-text highlight"><pre><span></span><code><span id="__span-254-1"><a id="__codelineno-254-1" name="__codelineno-254-1" href="#__codelineno-254-1"></a>
</span></code></pre></div>
{'messages': [HumanMessage(content='i like how much they win', id='bb916ce7-534c-4d48-9f92-e269f9dc4859'),
  AIMessage(content="That's understandable, the Celtics have been one of the more successful NBA franchises over the years. Their history of winning championships is very impressive. It's always fun to follow a team that regularly competes for titles. What do you think has been the key to the Celtics' sustained success? Is there a particular era or team that stands out as your favorite?", response_metadata={'id': 'msg_01B7TMagaM8xBnYXLSMwUDAG', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 148, 'output_tokens': 82}}, id='run-c5aa9a8f-7983-4a7f-9c1e-0c0055334ac1-0')],
 'summary': "Here is a summary of our conversation so far:\n\n- You introduced yourself as Bob and said you like the Boston Celtics basketball team.\n- I acknowledged that it's nice to meet you, Bob, and noted that you had shared your name earlier in the conversation.\n- You expressed that you like how much the Celtics win, and I agreed that their history of sustained success and championship pedigree is impressive.\n- I asked if you have a favorite Celtics player or moment that stands out to you, and invited further discussion about the team and the sport of basketball.\n- The overall tone has been friendly and conversational, with me trying to engage with your interest in the Celtics by asking follow-up questions."}
 <div class="language-text highlight"><pre><span></span><code><span id="__span-255-1"><a id="__codelineno-255-1" name="__codelineno-255-1" href="#__codelineno-255-1"></a>We can now resume having a conversation! Note that even though we only have the last two messages, we can still ask it questions about things mentioned earlier in the conversation (because we summarized those)
</span></code></pre></div>
 input_message = HumanMessage(content="what's my name?")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
<div class="language-text highlight"><pre><span></span><code><span id="__span-256-1"><a id="__codelineno-256-1" name="__codelineno-256-1" href="#__codelineno-256-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</li>
</ul>
<p>what's my name?
==================================[1m Ai Message [0m==================================</p>
<p>In our conversation so far, you introduced yourself as Bob. I acknowledged that earlier when you had shared your name.
<div class="language-text highlight"><pre><span></span><code><span id="__span-257-1"><a id="__codelineno-257-1" name="__codelineno-257-1" href="#__codelineno-257-1"></a>
</span></code></pre></div>
input_message = HumanMessage(content="what NFL team do you think I like?")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
<div class="language-text highlight"><pre><span></span><code><span id="__span-258-1"><a id="__codelineno-258-1" name="__codelineno-258-1" href="#__codelineno-258-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>what NFL team do you think I like?
==================================[1m Ai Message [0m==================================</p>
<p>I don't actually have any information about what NFL team you might like. In our conversation so far, you've only mentioned that you're a fan of the Boston Celtics basketball team. I don't have any prior knowledge about your preferences for NFL teams. Unless you provide me with that information, I don't have a basis to guess which NFL team you might be a fan of.
<div class="language-text highlight"><pre><span></span><code><span id="__span-259-1"><a id="__codelineno-259-1" name="__codelineno-259-1" href="#__codelineno-259-1"></a>
</span></code></pre></div>
input_message = HumanMessage(content="i like the patriots!")
input_message.pretty_print()
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
<div class="language-text highlight"><pre><span></span><code><span id="__span-260-1"><a id="__codelineno-260-1" name="__codelineno-260-1" href="#__codelineno-260-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>i like the patriots!
==================================[1m Ai Message [0m==================================</p>
<p>Okay, got it! Thanks for sharing that you're also a fan of the New England Patriots in the NFL. That makes sense, given your interest in other Boston sports teams like the Celtics. The Patriots have also had a very successful run over the past couple of decades, winning multiple Super Bowls. It's fun to follow winning franchises like the Celtics and Patriots. Do you have a favorite Patriots player or moment that stands out to you?
================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>================================[1m Remove Message [0m================================</p>
<p>Okay, extending the summary with the new information:</p>
<ul>
<li>You initially introduced yourself as Bob and said you like the Boston Celtics basketball team. </li>
<li>I acknowledged that and we discussed your appreciation for the Celtics' history of winning.</li>
<li>You then asked what your name was, and I reminded you that you had introduced yourself as Bob earlier in the conversation.</li>
<li>You followed up by asking what NFL team I thought you might like, and I explained that I didn't have any prior information about your NFL team preferences.</li>
<li>You then revealed that you are also a fan of the New England Patriots, which made sense given your Celtics fandom.</li>
<li>I responded positively to this new information, noting the Patriots' own impressive success and dynasty over the past couple of decades.</li>
<li>I then asked if you have a particular favorite Patriots player or moment that stands out to you, continuing the friendly, conversational tone.</li>
</ul>
<p>Overall, the discussion has focused on your sports team preferences, with you sharing that you are a fan of both the Celtics and the Patriots. I've tried to engage with your interests and ask follow-up questions to keep the dialogue flowing.
<div class="language-text highlight"><pre><span></span><code><span id="__span-261-1"><a id="__codelineno-261-1" name="__codelineno-261-1" href="#__codelineno-261-1"></a># Tool calling
</span><span id="__span-261-2"><a id="__codelineno-261-2" name="__codelineno-261-2" href="#__codelineno-261-2"></a>## How to call tools using ToolNode
</span><span id="__span-261-3"><a id="__codelineno-261-3" name="__codelineno-261-3" href="#__codelineno-261-3"></a>ToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph&#39;s prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).
</span><span id="__span-261-4"><a id="__codelineno-261-4" name="__codelineno-261-4" href="#__codelineno-261-4"></a>
</span><span id="__span-261-5"><a id="__codelineno-261-5" name="__codelineno-261-5" href="#__codelineno-261-5"></a>
</span><span id="__span-261-6"><a id="__codelineno-261-6" name="__codelineno-261-6" href="#__codelineno-261-6"></a>## Define tools
</span></code></pre></div>
from langchain_core.messages import AIMessage
from langchain_core.tools import tool</p>
<p>from langgraph.prebuilt import ToolNode
<div class="language-text highlight"><pre><span></span><code><span id="__span-262-1"><a id="__codelineno-262-1" name="__codelineno-262-1" href="#__codelineno-262-1"></a>
</span></code></pre></div>
@tool
def get_weather(location: str):
    """Call to get the current weather."""
    if location.lower() in ["sf", "san francisco"]:
        return "It's 60 degrees and foggy."
    else:
        return "It's 90 degrees and sunny."</p>
<p>@tool
def get_coolest_cities():
    """Get a list of coolest cities"""
    return "nyc, sf"
<div class="language-text highlight"><pre><span></span><code><span id="__span-263-1"><a id="__codelineno-263-1" name="__codelineno-263-1" href="#__codelineno-263-1"></a>
</span></code></pre></div>
tools = [get_weather, get_coolest_cities]
tool_node = ToolNode(tools)
<div class="language-text highlight"><pre><span></span><code><span id="__span-264-1"><a id="__codelineno-264-1" name="__codelineno-264-1" href="#__codelineno-264-1"></a>## Manually call ToolNode
</span><span id="__span-264-2"><a id="__codelineno-264-2" name="__codelineno-264-2" href="#__codelineno-264-2"></a>ToolNode operates on graph state with a list of messages. It expects the last message in the list to be an AIMessage with tool_calls parameter.
</span><span id="__span-264-3"><a id="__codelineno-264-3" name="__codelineno-264-3" href="#__codelineno-264-3"></a>
</span><span id="__span-264-4"><a id="__codelineno-264-4" name="__codelineno-264-4" href="#__codelineno-264-4"></a>Let&#39;s first see how to invoke the tool node manually:
</span></code></pre></div>
message_with_single_tool_call = AIMessage(
    content="",
    tool_calls=[
        {
            "name": "get_weather",
            "args": {"location": "sf"},
            "id": "tool_call_id",
            "type": "tool_call",
        }
    ],
)</p>
<p>tool_node.invoke({"messages": [message_with_single_tool_call]})
<div class="language-text highlight"><pre><span></span><code><span id="__span-265-1"><a id="__codelineno-265-1" name="__codelineno-265-1" href="#__codelineno-265-1"></a>
</span></code></pre></div>
{'messages': [ToolMessage(content="It's 60 degrees and foggy.", name='get_weather', tool_call_id='tool_call_id')]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-266-1"><a id="__codelineno-266-1" name="__codelineno-266-1" href="#__codelineno-266-1"></a>Note that typically you don&#39;t need to create AIMessage manually, and it will be automatically generated by any LangChain chat model that supports tool calling.
</span><span id="__span-266-2"><a id="__codelineno-266-2" name="__codelineno-266-2" href="#__codelineno-266-2"></a>
</span><span id="__span-266-3"><a id="__codelineno-266-3" name="__codelineno-266-3" href="#__codelineno-266-3"></a>You can also do parallel tool calling using ToolNode if you pass multiple tool calls to AIMessage&#39;s tool_calls parameter:
</span></code></pre></div>
message_with_multiple_tool_calls = AIMessage(
    content="",
    tool_calls=[
        {
            "name": "get_coolest_cities",
            "args": {},
            "id": "tool_call_id_1",
            "type": "tool_call",
        },
        {
            "name": "get_weather",
            "args": {"location": "sf"},
            "id": "tool_call_id_2",
            "type": "tool_call",
        },
    ],
)</p>
<p>tool_node.invoke({"messages": [message_with_multiple_tool_calls]})
<div class="language-text highlight"><pre><span></span><code><span id="__span-267-1"><a id="__codelineno-267-1" name="__codelineno-267-1" href="#__codelineno-267-1"></a>
</span></code></pre></div>
{'messages': [ToolMessage(content='nyc, sf', name='get_coolest_cities', tool_call_id='tool_call_id_1'),
  ToolMessage(content="It's 60 degrees and foggy.", name='get_weather', tool_call_id='tool_call_id_2')]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-268-1"><a id="__codelineno-268-1" name="__codelineno-268-1" href="#__codelineno-268-1"></a>## Using with chat models
</span><span id="__span-268-2"><a id="__codelineno-268-2" name="__codelineno-268-2" href="#__codelineno-268-2"></a>
</span><span id="__span-268-3"><a id="__codelineno-268-3" name="__codelineno-268-3" href="#__codelineno-268-3"></a>We&#39;ll be using a small chat model from Anthropic in our example. To use chat models with tool calling, we need to first ensure that the model is aware of the available tools. We do this by calling .bind_tools method on ChatAnthropic model
</span></code></pre></div>
from typing import Literal</p>
<p>from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode</p>
<p>model_with_tools = ChatAnthropic(
    model="claude-3-haiku-20240307", temperature=0
).bind_tools(tools)
<div class="language-text highlight"><pre><span></span><code><span id="__span-269-1"><a id="__codelineno-269-1" name="__codelineno-269-1" href="#__codelineno-269-1"></a>
</span></code></pre></div>
model_with_tools.invoke("what's the weather in sf?").tool_calls
<div class="language-text highlight"><pre><span></span><code><span id="__span-270-1"><a id="__codelineno-270-1" name="__codelineno-270-1" href="#__codelineno-270-1"></a>
</span></code></pre></div>
[{'name': 'get_weather',
  'args': {'location': 'San Francisco'},
  'id': 'toolu_01Fwm7dg1mcJU43Fkx2pqgm8',
  'type': 'tool_call'}]
<div class="language-text highlight"><pre><span></span><code><span id="__span-271-1"><a id="__codelineno-271-1" name="__codelineno-271-1" href="#__codelineno-271-1"></a>As you can see, the AI message generated by the chat model already has tool_calls populated, so we can just pass it directly to ToolNode
</span></code></pre></div>
tool_node.invoke({"messages": [model_with_tools.invoke("what's the weather in sf?")]})
<div class="language-text highlight"><pre><span></span><code><span id="__span-272-1"><a id="__codelineno-272-1" name="__codelineno-272-1" href="#__codelineno-272-1"></a>
</span></code></pre></div>
{'messages': [ToolMessage(content="It's 60 degrees and foggy.", name='get_weather', tool_call_id='toolu_01LFvAVT3xJMeZS6kbWwBGZK')]}
<div class="language-text highlight"><pre><span></span><code><span id="__span-273-1"><a id="__codelineno-273-1" name="__codelineno-273-1" href="#__codelineno-273-1"></a>## ReAct Agent
</span><span id="__span-273-2"><a id="__codelineno-273-2" name="__codelineno-273-2" href="#__codelineno-273-2"></a>Next, let&#39;s see how to use ToolNode inside a LangGraph graph. Let&#39;s set up a graph implementation of the ReAct agent. This agent takes some query as input, then repeatedly call tools until it has enough information to resolve the query. We&#39;ll be using ToolNode and the Anthropic model with tools we just defined
</span></code></pre></div>
from typing import Literal</p>
<p>from langgraph.graph import StateGraph, MessagesState, START, END</p>
<p>def should_continue(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "tools"
    return END</p>
<p>def call_model(state: MessagesState):
    messages = state["messages"]
    response = model_with_tools.invoke(messages)
    return {"messages": [response]}</p>
<p>workflow = StateGraph(MessagesState)</p>
<h1 id="define-the-two-nodes-we-will-cycle-between_1">Define the two nodes we will cycle between<a class="headerlink" href="#define-the-two-nodes-we-will-cycle-between_1" title="Permanent link">#</a></h1>
<p>workflow.add_node("agent", call_model)
workflow.add_node("tools", tool_node)</p>
<p>workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", should_continue, ["tools", END])
workflow.add_edge("tools", "agent")</p>
<p>app = workflow.compile()
<div class="language-text highlight"><pre><span></span><code><span id="__span-274-1"><a id="__codelineno-274-1" name="__codelineno-274-1" href="#__codelineno-274-1"></a>
</span></code></pre></div>
from IPython.display import Image, display</p>
<p>try:
    display(Image(app.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
<div class="language-text highlight"><pre><span></span><code><span id="__span-275-1"><a id="__codelineno-275-1" name="__codelineno-275-1" href="#__codelineno-275-1"></a>
</span></code></pre></div></p>
<h1 id="example-with-a-single-tool-call">example with a single tool call<a class="headerlink" href="#example-with-a-single-tool-call" title="Permanent link">#</a></h1>
<p>for chunk in app.stream(
    {"messages": [("human", "what's the weather in sf?")]}, stream_mode="values"
):
    chunk["messages"][-1].pretty_print()
<div class="language-text highlight"><pre><span></span><code><span id="__span-276-1"><a id="__codelineno-276-1" name="__codelineno-276-1" href="#__codelineno-276-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>what's the weather in sf?
==================================[1m Ai Message [0m==================================</p>
<p>[{'text': "Okay, let's check the weather in San Francisco:", 'type': 'text'}, {'id': 'toolu_01LdmBXYeccWKdPrhZSwFCDX', 'input': {'location': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}]
Tool Calls:
  get_weather (toolu_01LdmBXYeccWKdPrhZSwFCDX)
 Call ID: toolu_01LdmBXYeccWKdPrhZSwFCDX
  Args:
    location: San Francisco
=================================[1m Tool Message [0m=================================
Name: get_weather</p>
<p>It's 60 degrees and foggy.
==================================[1m Ai Message [0m==================================</p>
<p>The weather in San Francisco is currently 60 degrees with foggy conditions.
<div class="language-text highlight"><pre><span></span><code><span id="__span-277-1"><a id="__codelineno-277-1" name="__codelineno-277-1" href="#__codelineno-277-1"></a>
</span></code></pre></div></p>
<h1 id="example-with-a-multiple-tool-calls-in-succession">example with a multiple tool calls in succession<a class="headerlink" href="#example-with-a-multiple-tool-calls-in-succession" title="Permanent link">#</a></h1>
<p>for chunk in app.stream(
    {"messages": [("human", "what's the weather in the coolest cities?")]},
    stream_mode="values",
):
    chunk["messages"][-1].pretty_print()
<div class="language-text highlight"><pre><span></span><code><span id="__span-278-1"><a id="__codelineno-278-1" name="__codelineno-278-1" href="#__codelineno-278-1"></a>
</span></code></pre></div>
================================[1m Human Message [0m=================================</p>
<p>what's the weather in the coolest cities?
==================================[1m Ai Message [0m==================================</p>
<p>[{'text': "Okay, let's find out the weather in the coolest cities:", 'type': 'text'}, {'id': 'toolu_01LFZUWTccyveBdaSAisMi95', 'input': {}, 'name': 'get_coolest_cities', 'type': 'tool_use'}]
Tool Calls:
  get_coolest_cities (toolu_01LFZUWTccyveBdaSAisMi95)
 Call ID: toolu_01LFZUWTccyveBdaSAisMi95
  Args:
=================================[1m Tool Message [0m=================================
Name: get_coolest_cities</p>
<p>nyc, sf
==================================[1m Ai Message [0m==================================</p>
<p>[{'text': "Now let's get the weather for those cities:", 'type': 'text'}, {'id': 'toolu_01RHPQBhT1u6eDnPqqkGUpsV', 'input': {'location': 'nyc'}, 'name': 'get_weather', 'type': 'tool_use'}]
Tool Calls:
  get_weather (toolu_01RHPQBhT1u6eDnPqqkGUpsV)
 Call ID: toolu_01RHPQBhT1u6eDnPqqkGUpsV
  Args:
    location: nyc
=================================[1m Tool Message [0m=================================
Name: get_weather</p>
<p>It's 90 degrees and sunny.
==================================[1m Ai Message [0m==================================</p>
<p>[{'id': 'toolu_01W5sFGF8PfgYzdY4CqT5c6e', 'input': {'location': 'sf'}, 'name': 'get_weather', 'type': 'tool_use'}]
Tool Calls:
  get_weather (toolu_01W5sFGF8PfgYzdY4CqT5c6e)
 Call ID: toolu_01W5sFGF8PfgYzdY4CqT5c6e
  Args:
    location: sf
=================================[1m Tool Message [0m=================================
Name: get_weather</p>
<p>It's 60 degrees and foggy.
==================================[1m Ai Message [0m==================================</p>
<p>Based on the results, it looks like the weather in the coolest cities is:
- New York City: 90 degrees and sunny
- San Francisco: 60 degrees and foggy</p>
<p>So the weather in the coolest cities is a mix of warm and cool temperatures, with some sunny and some foggy conditions.
```</p>
<p>ToolNode can also handle errors during tool execution. You can enable / disable this by setting handle_tool_errors=True (enabled by default). See our guide on handling errors in ToolNode here</p>
<h1 id="how-to-integrate-langgraph-into-your-react-application">How to integrate LangGraph into your React application<a class="headerlink" href="#how-to-integrate-langgraph-into-your-react-application" title="Permanent link">#</a></h1>
<p><a href="https://langchain-ai.github.io/langgraph/cloud/how-tos/use_stream_react/">React application</a></p>
<h1 id="launch-local-langgraph-server">Launch Local LangGraph Server<a class="headerlink" href="#launch-local-langgraph-server" title="Permanent link">#</a></h1>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/">LangGraph Server</a></p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="February 27, 2026 10:12:34 UTC">February 27, 2026</span>
  </span>

    
    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"/></svg>
      
    </span>
    <nav>
      
        <a href="mailto:51238163+ganeshkinkar@users.noreply.github.com">ganeshkinkar</a>
    </nav>
  </span>

    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.path", "navigation.footer", "navigation.indexes", "toc.follow", "search.highlight", "search.suggest", "search.share", "content.code.copy", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>