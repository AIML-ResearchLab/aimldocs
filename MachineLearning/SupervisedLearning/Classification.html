<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Ganesh kinkar Giri" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Classification - AIML documents</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Classification";
        var mkdocs_page_input_path = "MachineLearning/SupervisedLearning/Classification.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../index.html" class="icon icon-home"> AIML documents
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../index.html">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">AIML</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" >Programing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Programing/python.html">PYTHON</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Statistic</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Descriptive Statistics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" >Measures of Central Tendency</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mean.html">Mean</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Median.html">Median</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Central-Tendency/Mode.html">Mode</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Measures of Position (Relative Standing)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Percentiles.html">Percentiles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Quartiles.html">Quartiles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Deciles.html">Deciles</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Position-Relative-Standing/Z-Score.html">Z-Score</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Shape of the Distribution</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Skewness.html">Skewness</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Shape-of-the-Distribution/Kurtosis.html">Kurtosis</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Visualization Tools</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/Histogram.html">Histogram</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/BarChart.html">Bar Chart</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/PieChart.html">Pie Chart</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/BoxPlot.html">Box Plot</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/LinePlot.html">Line Plot</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Visualization-Tools/DotPlot.html">Dot Plot</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Measures of Dispersion (Variability)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Range.html">Range</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/Variance.html">Variance</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/StandardDeviation.html">Standard Deviation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/InterquartileRange.html">Interquartile Range(IQR)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/DescriptiveStatistics/Measures-of-Dispersion/CofficientVariation.html">Cofficient of Variation</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Inferential Statistics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" >Population and Sample</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/Population.html">Population</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/Sample.html">Sample</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Population-and-Sample/SamplingMethods.html">Sampling Methods</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Estimation</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/PointEstimation.html">Point Estimation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/IntervalEstimation.html">Interval Estimation</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Estimation/MarginError.html">Margin of Error</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Regression and Correlation Analysis</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LinearRegression.html">Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/LogisticRegression.html">Logistic Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/MultipleRegression.html">Multiple Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Regression-and-Correlation-Analysis/CorrelationCoefficients.html">Correlation Coefficients</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Hypothesis Testing</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/NullHypothesis.html">Null Hypothesis (H₀)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/AlternativeHypothesis.html">Alternative Hypothesis (H₁)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TestStatistic.html">Test Statistic</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/pvalue.html">p-value</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/SignificanceLevel.html">Significance Level (α)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIError.html">Type I Error (α)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/TypeIIError.html">Type II Error (β)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Hypothesis-Testing/PoweroftheTest.html">Power of the Test</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Parametric Tests</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/t-test.html">t-test</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/z-test.html">z-test</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/ANOVA.html">ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Parametric-Tests/F-test.html">F-test</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Non-Parametric Tests</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Mann-WhitneyU.html">Mann-Whitney U</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Kruskal-Wallis.html">Kruskal-Wallis</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Wilcoxon.html">Wilcoxon</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Non-Parametric-Tests/Chi-square.html">Chi-square</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Resampling Methods</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Resampling-Methods/Bootstrapping.html">Bootstrapping</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Resampling-Methods/Jackknife.html">Jackknife</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Analysis of Variance (ANOVA)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/One-way-ANOVA.html">One-way ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/Two-way-ANOVA.html">Two-way ANOVA</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/ANOVA/Post-hoc-Tests.html">Post-hoc Tests</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Probability Theory</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/ProbabilityDistributions.html">Probability Distributions</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/CentralLimitTheorem.html">Central Limit Theorem</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Statistic/InferentialStatistics/Probability-Theory/BayesianInference.html">Bayesian Inference</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Time Series</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Trend.html">Trend</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Seasonality.html">Seasonality</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Cyclic.html">Cyclic</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Noise.html">Irregular/Noise</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Stationarity.html">Stationarity</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Non-stationary.html">Non-stationary</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Autocorrelation.html">Autocorrelation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Lag.html">Lag</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/MovingAverages.html">Moving Averages</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Holt-Winters.html">Holt-Winters Method</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Additive.html">Additive</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Multiplicative.html">Multiplicative</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AR.html">AR (Auto Regression)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/ARIMA.html">ARIMA</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Arimax.html">Arimax</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Sarimax.html">Sarimax</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Smoothing.html">Smoothing</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AutomatedForecasting.html">Automated Forecasting</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/AutomatedTimeSeries.html">Automated Time Series</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../Statistic/TimeSeries/Multivariate.html">Uni, Bi and Multivariate</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/metrics.html">Metrics Evaluation</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/timeseries.html">Time Series Old</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Statistic/statistic-details.html">Statistic Details</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Data manipulation and analysis</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-manipulation-and-analysis/data-manipulation-analysis.html">PANDAS</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Data Processing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/sql.html">Basic SQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/sql-datascience.html">Using SQL for Data Science</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/unstructured-data.html">Unstructured Data</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Data-processing/exploratory-data-analysis.html">Exploratory Data Analysis(EDA)</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../Data-processing/building-ml-models-on-text-data.md">Building ML Models on Text Data</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Databases</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/PostgreSQL.html">PostgreSQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/MySQL.html">MySQL</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../Databases/MongoDB.html">MongoDB</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Machine Learning</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../Overview.html">Overview</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" >Supervised Learning</a>
    <ul class="current">
                <li class="toctree-l3"><a class="reference internal" href="Overview.html">Overview</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="Regression.html">Regression</a>
                </li>
                <li class="toctree-l3 current"><a class="reference internal current" href="#">Classification</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="CrossValidation.html">Cross Validation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="HyperparameterTuning.html">Hyperparameter Tuning</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="TuningDecisionThreshold.html">Tuning decision threshold</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Regression Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/SimpleLinearRegression.html">Simple Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/MultipleLinearRegression.html">Multiple Linear Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/PolynomialRegression.html">Polynomial Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/RidgeLassoRegression.html">Ridge & Lasso Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/SupportVectorRegression.html">Support Vector Regression (SVR)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/DecisionTreeRegression.html">Decision Tree Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="RegressionModels/RandomForestRegression.html">Random Forest Regression</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Linear Classification Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="LinearClassificationModels/LogisticRegression.html">Logistic Regression</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="LinearClassificationModels/SupportVectorMachines.html">Support Vector Machines</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="LinearClassificationModels/SinglelayerPerceptron.html">Single-layer Perceptron</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="LinearClassificationModels/StochasticGradientDescent.html">Stochastic Gradient Descent (SGD)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Non-linear Classification Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/DecisionTreeClassification.html">Decision Tree Classification</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/KNearestNeighbours.html">K-Nearest Neighbours</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/NaiveBayes.html">Naive Bayes</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/RandomForests.html">Random Forests</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/AdaBoost.html">AdaBoost</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/BaggingClassifier.html">Bagging Classifier</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/Ensemblelearningclassifiers.html">Ensemble learning classifiers</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="NonlinearClassificationModels/KernelSVM.html">Kernel SVM</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Unsupervised Learning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../UnsupervisedLearning/overview.html">Overview</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../UnsupervisedLearning/Clustering.html">Clustering</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../UnsupervisedLearning/Pca.html">Principal Component Analysis(PCA)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Reinforcement Learning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/ReinforcementLearning.html">Overview</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Linear Algebra</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../LinearAlgebra/Overview.html">Overview</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Deep Learning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../DeepLearning/Overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../DeepLearning/Vanishing.html">Vanishing and Exploding Gradients Problems</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Components of Neural Networks</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/LayersNeuralNetworks.html">Layers in Neural Networks</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/WeightsBiases.html">Weights and Biases</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/ForwardPropagation.html">Forward Propagation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/ActivationFunctions.html">Activation Functions</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/LossFunctions.html">Loss Functions</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/Backpropagation.html">Backpropagation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Components/LearningRate.html">Learning Rate</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Optimization Algorithm</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/GradientDescent.html">Gradient Descent</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/SGD.html">Stochastic Gradient Descent (SGD)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/Adam.html">Adam (Adaptive Moment Estimation)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/BatchNormalization.html">Batch Normalization</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/Mini-batch-GD.html">Mini-batch Gradient Descent</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/Momentum-based-GO.html">Momentum-based Gradient Optimizer</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/AdagradOptimizer.html">Adagrad Optimizer</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/OptimizationAlgorithm/RMSPropOptimizer.html">RMSProp Optimizer</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Models</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/FNN.html">Feedforward Neural Network (FNN)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Recurrent Neural Network (RNN)</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../DeepLearning/Models/RNN.html">Recurrent Neural Network (RNN)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../DeepLearning/Models/LSTM.html">LSTM (Long Short-Term Memory)</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../DeepLearning/Models/GRU.html">GRU (Gated Recurrent Unit)</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/CNN.html">Convolutional Neural Network (CNN)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/RBFN.html">Radial Basis Function Network (RBFN)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/ComputerVision.html">Computer Vision</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/GANs.html">Generative Adversarial Networks (GANs)</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/Transformer.html">Transformer Networks</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/Autoencoders.html">Autoencoders</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../DeepLearning/Models/SOM.html">Self-Organizing Maps (SOM)</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Natural Language Processing(NLP)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../NLP/overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../NLP/nlpdetails.html">NLP Details</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Retrieval-Augmented Generation(RAG)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../RAG/rag.html">RAG</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >AI agents</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../AIagents/aiagents.html">AI agents</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Agentic AI</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/general.html">general</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/overview.html">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/crewai.html">crewai</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/LangGraph.html">LangGraph</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/AutoGen.html">AutoGen</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/aws.html">AWS</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../AgenticAI/azure.html">AZURE</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Agent Development Kit</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/adk.html">ADK</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/Agents.html">Agents</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/Tools.html">Tools</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../AgenticAI/GCP/a2a.html">Tools</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >MCPModel Context Protocol (MCP)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../MCP/mcp.html">MCP</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Models Details information</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Models/Ollama.html">Ollama</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Note Book</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Notebook/allnotebook.html">All Notebook</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">AIML documents</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html" class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">AIML</li>
          <li class="breadcrumb-item">Machine Learning</li>
          <li class="breadcrumb-item">Supervised Learning</li>
      <li class="breadcrumb-item active">Classification</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 style="color:red;">✅ What is Classification in Supervised Learning?</h2>

<p><strong>Classification</strong> is a type of Supervised Learning where the model learns from labeled data to predict discrete categories or classes.</p>
<p><strong>Classification teaches a machine to sort things into categories. It learns by looking at examples with labels (like emails marked "spam" or "not spam"). After learning, it can decide which category new items belong to, like identifying if a new email is spam or not.</strong></p>
<p>For example a classification model might be trained on dataset of images labeled as either <strong>dogs</strong> or <strong>cats</strong> and it can be used to predict the class of new and unseen images as dogs or cats based on their features such as color, texture and shape.</p>
<h3 style="color:blue;">📌 Types of Classification</h3>

<p>When we talk about classification in machine learning, we’re talking about the process of sorting data into categories based on specific features or characteristics. There are different types of classification problems depending on how many categories (or classes) we are working with and how they are organized. There are two main classification types in machine learning:</p>
<ol>
<li><strong>Binary Classification</strong></li>
</ol>
<p>This is the simplest kind of classification. In binary classification, the goal is to sort the data into <strong>two distinct categories</strong>.</p>
<p>Think of it like a simple choice between two options. Imagine a system that sorts emails into either spam or not spam. It works by looking at different features of the email like certain keywords or sender details, and decides whether it’s spam or not. It only chooses between these two options.</p>
<ol>
<li><strong>Multiclass Classification</strong></li>
</ol>
<p>Here, instead of just two categories, the data needs to be sorted into <strong>more than two categories</strong>. The model picks the one that best matches the input. Think of an image recognition system that sorts pictures of animals into categories like <strong>cat, dog, and bird</strong>.</p>
<p>Basically, machine looks at the features in the image (like shape, color, or texture) and chooses which animal the picture is most likely to be based on the training it received.</p>
<h3 style="color:blue;">📌 Examples of Machine Learning Classification in Real Life</h3>

<ul>
<li>
<p><strong>Email spam filtering</strong></p>
</li>
<li>
<p><strong>Credit risk assessment:</strong> Algorithms predict whether a loan applicant is likely to default by analyzing factors such as credit score, income, and loan history. This helps banks make informed lending decisions and minimize financial risk.</p>
</li>
<li>
<p><strong>Medical diagnosis:</strong> Machine learning models classify whether a patient has a certain condition (e.g., cancer or diabetes) based on medical data such as test results, symptoms, and patient history. This aids doctors in making quicker, more accurate diagnoses, improving patient care.</p>
</li>
<li>
<p><strong>Image classification:</strong> Applied in fields such as facial recognition, autonomous driving, and medical imaging.</p>
</li>
<li>
<p><strong>Sentiment analysis:</strong> Determining whether the sentiment of a piece of text is positive, negative, or neutral. Businesses use this to understand customer opinions, helping to improve products and services.</p>
</li>
<li>
<p><strong>Fraud detection:</strong> Algorithms detect fraudulent activities by analyzing transaction patterns and identifying anomalies crucial in protecting against credit card fraud and other financial crimes.</p>
</li>
<li>
<p><strong>Recommendation systems:</strong> Used to recommend products or content based on past user behavior, such as suggesting movies on Netflix or products on Amazon. This personalization boosts user satisfaction and sales for businesses.</p>
</li>
</ul>
<h3 style="color:blue;">📌 Key characteristics of Classification Models</h3>

<ol>
<li>
<p><strong>Class Separation:</strong> Classification relies on distinguishing between distinct classes. The goal is to learn a model that can separate or categorize data points into predefined classes based on their features.</p>
</li>
<li>
<p><strong>Decision Boundaries:</strong> The model draws decision boundaries in the feature space to differentiate between classes. These boundaries can be linear or non-linear.</p>
</li>
<li>
<p><strong>Sensitivity to Data Quality:</strong> Classification models are sensitive to the quality and quantity of the training data. Well-labeled, representative data ensures better performance, while noisy or biased data can lead to poor predictions.</p>
</li>
<li>
<p><strong>Handling Imbalanced Data:</strong> Classification problems may face challenges when one class is underrepresented. Special techniques like resampling or weighting are used to handle class imbalances.</p>
</li>
<li>
<p><strong>Interpretability:</strong> Some classification algorithms, such as Decision Trees, offer higher interpretability, meaning it's easier to understand why a model made a particular prediction.</p>
</li>
</ol>
<h3 style="color:blue;">📌 Classification Algorithms</h3>

<p>Now, for implementation of any classification model it is essential to understand <strong>Logistic Regression</strong>, which is one of the most fundamental and widely used algorithms in machine learning for classification tasks. There are various types of <strong>classifiers algorithms</strong>. Some of them are : </p>
<p><strong>Linear Classifiers:</strong> Linear classifier models create a linear decision boundary between classes. They are simple and computationally efficient. Some of the linear classification models are as follows: </p>
<ol>
<li>
<p><strong>Logistic Regression</strong></p>
</li>
<li>
<p><strong>Support Vector Machines having kernel = 'linear'</strong></p>
</li>
<li>
<p><strong>Single-layer Perceptron</strong></p>
</li>
<li>
<p><strong>Stochastic Gradient Descent (SGD) Classifier</strong></p>
</li>
</ol>
<p><strong>Non-linear Classifiers:</strong> Non-linear models create a non-linear decision boundary between classes. They can capture more complex relationships between input features and target variable. Some of the non-linear classification models are as follows:</p>
<ol>
<li>
<p><strong>K-Nearest Neighbours</strong></p>
</li>
<li>
<p><strong>Kernel SVM</strong></p>
</li>
<li>
<p><strong>Naive Bayes</strong></p>
</li>
<li>
<p><strong>Decision Tree Classification</strong></p>
</li>
<li>
<p><strong>Random Forests</strong></p>
</li>
<li>
<p><strong>AdaBoost</strong></p>
</li>
<li>
<p><strong>Bagging Classifier</strong></p>
</li>
<li>
<p><strong>Voting Classifier</strong></p>
</li>
<li>
<p><strong>Extra Trees Classifier</strong></p>
</li>
<li>
<p><strong>Multi-layer Artificial Neural Networks</strong></p>
</li>
</ol>
<h3 style="color:blue;">📌 Logistic Regression in Machine Learning</h3>

<p>Logistic Regression is a supervised machine learning algorithm used for classification problems.
Unlike linear regression which predicts continuous values it predicts the probability that an input belongs to a specific class.</p>
<p>It is used for binary classification where the output can be one of two possible categories such as Yes/No, True/False or 0/1. It uses <strong>sigmoid</strong> function to convert inputs into a probability value between 0 and 1. </p>
<p><img alt="alt text" src="../images/SL20.png" /></p>
<p><img alt="alt text" src="../images/SL21.png" /></p>
<p><img alt="alt text" src="../images/SL22.png" /></p>
<h3 style="color:blue;">📌 Types of Logistic Regression</h3>

<p>Logistic regression can be classified into three main types based on the nature of the dependent variable:</p>
<ol>
<li>
<p><strong>Binomial Logistic Regression:</strong> This type is used when the dependent variable has only two possible categories. Examples include Yes/No, Pass/Fail or 0/1. It is the most common form of logistic regression and is used for binary classification problems.</p>
</li>
<li>
<p><strong>Multinomial Logistic Regression:</strong> This is used when the dependent variable has three or more possible categories that are not ordered. For example, classifying animals into categories like "cat," "dog" or "sheep." It extends the binary logistic regression to handle multiple classes.</p>
</li>
<li>
<p><strong>Ordinal Logistic Regression:</strong> This type applies when the dependent variable has three or more categories with a natural order or ranking. Examples include ratings like "low," "medium" and "high." It takes the order of the categories into account when modeling.</p>
</li>
</ol>
<h3 style="color:blue;">📌 Assumptions of Logistic Regression</h3>

<p>Understanding the assumptions behind logistic regression is important to ensure the model is applied correctly, main assumptions are:</p>
<ol>
<li>
<p><strong>Independent observations:</strong> Each data point is assumed to be independent of the others means there should be no correlation or dependence between the input samples.</p>
</li>
<li>
<p><strong>Binary dependent variables:</strong> It takes the assumption that the dependent variable must be binary, means it can take only two values. For more than two categories <strong>SoftMax functions</strong> are used.</p>
</li>
<li>
<p><strong>Linearity relationship between independent variables and log odds:</strong> The model assumes a linear relationship between the independent variables and the log odds of the dependent variable which means the predictors affect the log odds in a linear way.</p>
</li>
<li>
<p><strong>No outliers:</strong> The dataset should not contain extreme outliers as they can distort the estimation of the logistic regression coefficients.</p>
</li>
<li>
<p><strong>Large sample size:</strong> It requires a sufficiently large sample size to produce reliable and stable results.</p>
</li>
</ol>
<h3 style="color:blue;">📌 Understanding Sigmoid Function</h3>

<ol>
<li>
<p>The sigmoid function is a important part of logistic regression which is used to convert the raw output of the model into a probability value between 0 and 1.</p>
</li>
<li>
<p>This function takes any real number and maps it into the range 0 to 1 forming an "S" shaped curve called the sigmoid curve or logistic curve. Because probabilities must lie between 0 and 1, the sigmoid function is perfect for this purpose.</p>
</li>
<li>
<p>In logistic regression, we use a threshold value usually 0.5 to decide the class label.</p>
<ul>
<li>
<p>If the sigmoid output is same or above the threshold, the input is classified as Class 1.</p>
</li>
<li>
<p>If it is below the threshold, the input is classified as Class 0.</p>
</li>
</ul>
</li>
</ol>
<h3 style="color:blue;">📌 How does Logistic Regression work?</h3>

<p>The logit function is commonly used in <strong>Logistic Regression</strong>, especially when working with binary classification problems. It maps probabilities (values between 0 and 1) to real numbers (−∞ to +∞). Here's a full explanation and example of how it works:</p>
<h3 style="color:blue;">📌 What is the logit function?</h3>

<p>The logit function is defined as:</p>
<p><img alt="alt text" src="../images/SL23.png" /></p>
<p><strong>Logistic Function (Sigmoid)</strong></p>
<p>The inverse of the logit function is the sigmoid function:</p>
<p><img alt="alt text" src="../images/SL24.png" /></p>
<h3 style="color:blue;">📌 How to Evaluate Logistic Regression Model?</h3>

<p><img alt="alt text" src="../images/SL25.png" /></p>
<h3 style="color:blue;">📌 Differences Between Linear and Logistic Regression?</h3>

<table>
<thead>
<tr>
<th>Feature</th>
<th>Linear Regression</th>
<th>Logistic Regression</th>
</tr>
</thead>
<tbody>
<tr>
<td>Purpose</td>
<td>Predict continuous dependent variable</td>
<td>Predict categorical dependent variable</td>
</tr>
<tr>
<td>Problem Type</td>
<td>Regression</td>
<td>Classification</td>
</tr>
<tr>
<td>Prediction Output</td>
<td>Continuous value (e.g., price, age)</td>
<td>Categorical value (e.g., 0 or 1, Yes or No)</td>
</tr>
<tr>
<td>Curve</td>
<td>Best fit line</td>
<td>S-curve (Sigmoid function)</td>
</tr>
<tr>
<td>Estimation Method</td>
<td>Least Squares Estimation</td>
<td>Maximum Likelihood Estimation</td>
</tr>
<tr>
<td>Relationship Requirement</td>
<td>Requires linear relationship</td>
<td>Does <strong>not</strong> require linear relationship</td>
</tr>
<tr>
<td>Collinearity</td>
<td>Can handle some collinearity</td>
<td>Should have little or no collinearity</td>
</tr>
<tr>
<td>Target Variable</td>
<td>Continuous</td>
<td>Categorical</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Key Concepts</h3>

<table>
<thead>
<tr>
<th>Aspect</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Objective</strong></td>
<td>Predict <strong>class labels</strong> (e.g., Yes/No, Spam/Not Spam, Disease/No Disease)</td>
</tr>
<tr>
<td><strong>Input</strong></td>
<td>Features (X)</td>
</tr>
<tr>
<td><strong>Output</strong></td>
<td>Categorical label (Y)</td>
</tr>
<tr>
<td><strong>Type</strong></td>
<td>Supervised Learning</td>
</tr>
<tr>
<td><strong>Examples</strong></td>
<td>Email spam detection, Disease prediction, Image recognition</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Real-time Example: Medical Diagnosis System</h3>

<p>Imagine a hospital wants to predict whether a patient has <strong>Diabetes</strong> based on medical measurements.</p>
<p><strong>Sample Dataset</strong></p>
<table>
<thead>
<tr>
<th>Glucose</th>
<th>Blood Pressure</th>
<th>BMI</th>
<th>Age</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr>
<td>148</td>
<td>72</td>
<td>33.6</td>
<td>50</td>
<td>1</td>
</tr>
<tr>
<td>85</td>
<td>66</td>
<td>26.6</td>
<td>31</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>Input Features (X):</strong> Glucose, Blood Pressure, BMI, Age</p>
</li>
<li>
<p><strong>Target (Y):</strong> Outcome → 1 (Has Diabetes), 0 (No Diabetes)</p>
</li>
</ul>
<h3 style="color:blue;">📌 Steps in Classification Project</h3>

<ol>
<li><strong>Data Collection</strong></li>
</ol>
<p>Medical records, lab test results, etc.</p>
<ol>
<li>
<p><strong>Data Preprocessing</strong></p>
<ul>
<li>
<p>Handle missing values</p>
</li>
<li>
<p>Normalize/scale features</p>
</li>
<li>
<p>Encode categorical variables (if any)</p>
</li>
</ul>
</li>
<li>
<p><strong>Exploratory Data Analysis (EDA)</strong></p>
<ul>
<li>Visualize class balance, distributions, correlations.</li>
</ul>
</li>
<li>
<p><strong>Feature Selection</strong></p>
<ul>
<li>Use correlation or feature importance (from models).</li>
</ul>
</li>
<li>
<p><strong>Model Building</strong></p>
</li>
<li>
<p>Common models for classification:</p>
<ul>
<li>
<p><strong>Logistic Regression</strong></p>
</li>
<li>
<p><strong>Decision Tree</strong></p>
</li>
<li>
<p><strong>Random Forest</strong></p>
</li>
<li>
<p><strong>Support Vector Machine (SVM)</strong></p>
</li>
<li>
<p><strong>K-Nearest Neighbors (KNN)</strong></p>
</li>
<li>
<p><strong>Naive Bayes</strong></p>
</li>
<li>
<p><strong>Neural Networks</strong></p>
</li>
</ul>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

<ol>
<li>
<p><strong>Model Evaluation</strong></p>
</li>
<li>
<p>Use classification metrics:</p>
<ul>
<li>
<p><strong>Accuracy</strong></p>
</li>
<li>
<p><strong>Precision</strong></p>
</li>
<li>
<p><strong>Recall</strong></p>
</li>
<li>
<p><strong>F1 Score</strong></p>
</li>
<li>
<p><strong>Confusion Matrix</strong></p>
</li>
<li>
<p><strong>ROC AUC</strong></p>
</li>
</ul>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>

<h3 style="color:blue;">📌 Evaluation Example</h3>

<table>
<thead>
<tr>
<th>Predicted ↓ / Actual →</th>
<th>Positive</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr>
<td>Negative</td>
<td>FN</td>
<td>TN</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Real-World Classification Use Cases</h3>

<table>
<thead>
<tr>
<th>Domain</th>
<th>Use Case</th>
<th>Classes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Finance</td>
<td>Fraud Detection</td>
<td>Fraud / Not Fraud</td>
</tr>
<tr>
<td>HR/Recruiting</td>
<td>Resume Screening</td>
<td>Suitable / Not Suitable</td>
</tr>
<tr>
<td>Healthcare</td>
<td>Disease Prediction</td>
<td>Positive / Negative</td>
</tr>
<tr>
<td>Retail</td>
<td>Customer Churn</td>
<td>Churn / Retain</td>
</tr>
<tr>
<td>Security</td>
<td>Intrusion Detection</td>
<td>Attack / Normal</td>
</tr>
<tr>
<td>Email</td>
<td>Spam Filter</td>
<td>Spam / Not Spam</td>
</tr>
<tr>
<td>Telecom</td>
<td>Call Drop Reason Prediction</td>
<td>Technical / Customer-based</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Tools/Libraries for Classification</h3>

<ul>
<li>
<p><strong>Python:</strong> <code>scikit-learn, xgboost, lightgbm, catboost, tensorflow, pytorch</code></p>
</li>
<li>
<p><strong>Visualization:</strong> <code>matplotlib, seaborn, plotly</code></p>
</li>
</ul>
<h2 style="color:red;">✅ Use Cases</h2>

<h3 style="color:blue;">📌 Predicting Diabetes - (Classification)</h3>

<h3 style="color:green;">1. Imports Library</h3>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
</code></pre></div>

<h3 style="color:green;">2. Load Data</h3>

<p><a href="https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database">Pima Indians Diabetes Database</a></p>
<div class="codehilite"><pre><span></span><code>df = pd.read_csv(&#39;diabetes.csv&#39;)
df.head()
</code></pre></div>

<table>
<thead>
<tr>
<th>Pregnancies</th>
<th>Glucose</th>
<th>BloodPressure</th>
<th>SkinThickness</th>
<th>Insulin</th>
<th>BMI</th>
<th>DiabetesPedigreeFunction</th>
<th>Age</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr>
<td>6</td>
<td>148</td>
<td>72</td>
<td>35</td>
<td>0</td>
<td>33.6</td>
<td>0.627</td>
<td>50</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>85</td>
<td>66</td>
<td>29</td>
<td>0</td>
<td>26.6</td>
<td>0.351</td>
<td>31</td>
<td>0</td>
</tr>
<tr>
<td>8</td>
<td>183</td>
<td>64</td>
<td>0</td>
<td>0</td>
<td>23.3</td>
<td>0.672</td>
<td>32</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>89</td>
<td>66</td>
<td>23</td>
<td>94</td>
<td>28.1</td>
<td>0.167</td>
<td>21</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>137</td>
<td>40</td>
<td>35</td>
<td>168</td>
<td>43.1</td>
<td>2.288</td>
<td>33</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 style="color:green;">3. Data Preprocessing</h3>

<h3 style="color:green;">1. Handle Missing Data</h3>

<ul>
<li><strong>Check for NaN or null values</strong></li>
</ul>
<div class="codehilite"><pre><span></span><code>print(df.isnull().sum())
</code></pre></div>

<table>
<thead>
<tr>
<th>Column Name</th>
<th>Missing Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pregnancies</td>
<td>0</td>
</tr>
<tr>
<td>Glucose</td>
<td>0</td>
</tr>
<tr>
<td>BloodPressure</td>
<td>0</td>
</tr>
<tr>
<td>SkinThickness</td>
<td>0</td>
</tr>
<tr>
<td>Insulin</td>
<td>0</td>
</tr>
<tr>
<td>BMI</td>
<td>0</td>
</tr>
<tr>
<td>DiabetesPedigreeFunction</td>
<td>0</td>
</tr>
<tr>
<td>Age</td>
<td>0</td>
</tr>
<tr>
<td>Outcome</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>Drop rows or columns with too many missing values</strong></p>
</li>
<li>
<p><strong>Impute missing values:</strong></p>
<ul>
<li>
<p>Mean/Median (numerical)</p>
</li>
<li>
<p>Mode (categorical)</p>
</li>
<li>
<p>Forward/Backward fill</p>
</li>
<li>
<p>Model-based imputation</p>
</li>
</ul>
</li>
<li>
<p><strong>Check &amp; Remove Duplicate value</strong></p>
<ul>
<li>Detect and remove duplicate rows </li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><code>print(df.duplicated().sum())
</code></pre></div>

<ul>
<li>
<p><strong>Handle Outliers</strong></p>
</li>
<li>
<p>Identify outliers using:</p>
<ul>
<li>
<p>IQR (Interquartile Range)</p>
</li>
<li>
<p>Z-score</p>
</li>
<li>
<p>Boxplot</p>
</li>
</ul>
</li>
<li>
<p>Remove or cap outliers</p>
</li>
<li>
<p><strong>Data Type Correction</strong></p>
</li>
<li>
<p>Ensure columns have correct data types:</p>
<ul>
<li>
<p>e.g., convert <code>object to int, datetime, or float</code></p>
</li>
<li>
<p>Use <code>pd.to_numeric() or pd.to_datetime()</code></p>
</li>
</ul>
</li>
<li>
<p><strong>Normalize / Scale Values</strong></p>
<ul>
<li>
<p>Standardize features (<code>StandardScaler, MinMaxScaler</code>)</p>
</li>
<li>
<p>Normalize data if using distance-based models (e.g., KNN, SVM)</p>
</li>
</ul>
</li>
<li>
<p><strong>Fix Structural Errors</strong></p>
<ul>
<li>
<p>Inconsistent formatting (e.g., <code>yes, Yes, Y</code>)</p>
</li>
<li>
<p>Incorrect spelling or labels</p>
</li>
<li>
<p>Strip whitespaces</p>
</li>
<li>
<p>Format phone numbers, dates, currencies</p>
</li>
</ul>
</li>
<li>
<p><strong>Handle Categorical Variables</strong></p>
</li>
<li>
<p>Encode using:</p>
<ul>
<li>
<p>One-hot encoding (<code>pd.get_dummies</code>)</p>
</li>
<li>
<p>Label encoding</p>
</li>
<li>
<p>Frequency/target encoding (advanced)</p>
</li>
</ul>
</li>
<li>
<p><strong>Remove Irrelevant or Redundant Features</strong></p>
<ul>
<li>
<p>Drop ID columns, unnecessary time stamps</p>
</li>
<li>
<p>Use correlation or variance analysis to drop low-impact features</p>
</li>
</ul>
</li>
<li>
<p><strong>Binning / Discretization</strong></p>
<ul>
<li>Convert continuous variables to categories (e.g., age groups)</li>
</ul>
</li>
<li>
<p><strong>Text Cleaning (for NLP)</strong></p>
<ul>
<li>
<p>Lowercasing, stopword removal, stemming/lemmatization, punctuation removal</p>
</li>
<li>
<p>Text Cleaning (for NLP)**</p>
</li>
</ul>
</li>
<li>
<p><strong>Feature Engineering</strong></p>
<ul>
<li>Create new features from existing data (e.g., BMI from weight/height)</li>
</ul>
</li>
<li>
<p><strong>Consistency Checks</strong></p>
<ul>
<li>
<p>Ensure dates are in logical order (e.g., start_date &lt; end_date)</p>
</li>
<li>
<p>Check valid ranges (e.g., age &gt; 0)</p>
</li>
</ul>
</li>
</ul>
<h3 style="color:blue;">✅ Data Cleaning Template (Python Code)</h3>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.impute</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Load your dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;your_dataset.csv&quot;</span><span class="p">)</span>  <span class="c1"># replace with your actual file path</span>

<span class="c1"># 1. Check for missing values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing values:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="kp">sum</span><span class="p">())</span>

<span class="c1"># 2. Replace zero values in specific columns (common in medical datasets)</span>
<span class="n">cols_with_zero_as_nan</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="s1">&#39;BloodPressure&#39;</span><span class="p">,</span> <span class="s1">&#39;SkinThickness&#39;</span><span class="p">,</span> <span class="s1">&#39;Insulin&#39;</span><span class="p">,</span> <span class="s1">&#39;BMI&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">cols_with_zero_as_nan</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols_with_zero_as_nan</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="kp">nan</span><span class="p">)</span>

<span class="c1"># 3. Impute missing values with median</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="n">cols_with_zero_as_nan</span><span class="p">]</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cols_with_zero_as_nan</span><span class="p">])</span>

<span class="c1"># 4. Remove duplicates</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>

<span class="c1"># 5. Convert data types (if necessary)</span>
<span class="c1"># Example: df[&#39;Age&#39;] = df[&#39;Age&#39;].astype(int)</span>

<span class="c1"># 6. Detect and remove outliers using IQR</span>
<span class="k">def</span><span class="w"> </span><span class="nf">remove_outliers_iqr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">Q1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">Q3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">lower</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">upper</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">remove_outliers_iqr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cols_with_zero_as_nan</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">])</span>

<span class="c1"># 7. Normalize/Standardize data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Outcome&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">df</span><span class="p">[</span><span class="n">numerical_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">numerical_features</span><span class="p">])</span>

<span class="c1"># 8. Final check</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cleaned Data Preview:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Types:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Shape of cleaned data:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
</code></pre></div>

<h3 style="color:blue;">📌 Exploratory Data Analysis (EDA) – Complete Guide with Python</h3>

<p><strong>✅ Typical EDA Activities</strong></p>
<table>
<thead>
<tr>
<th>Step</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1️⃣</td>
<td>Understand dataset structure (rows, columns, datatypes)</td>
</tr>
<tr>
<td>2️⃣</td>
<td>Descriptive statistics (mean, median, mode, std)</td>
</tr>
<tr>
<td>3️⃣</td>
<td>Null/missing values analysis</td>
</tr>
<tr>
<td>4️⃣</td>
<td>Value distributions and outliers</td>
</tr>
<tr>
<td>5️⃣</td>
<td>Correlation analysis</td>
</tr>
<tr>
<td>6️⃣</td>
<td>Feature relationships (scatter, box, violin plots)</td>
</tr>
<tr>
<td>7️⃣</td>
<td>Target variable balance check (classification)</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Exploratory Data Analysis (EDA) – Complete Guide with Python</h3>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># Load dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;diabetes.csv&quot;</span><span class="p">)</span>

<span class="c1"># 1. Shape &amp; basic info</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset shape:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>

<span class="c1"># 2. Summary statistics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="c1"># 3. Check class balance</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Outcome&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Class Distribution (0 = No Diabetes, 1 = Diabetes)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 4. Missing value check</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># 5. Correlation matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Heatmap&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 6. Pairplot (optional for small data)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Outcome&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 7. Distribution of numerical features</span>
<span class="n">df</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Histograms of Features&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 8. Box plots to detect outliers</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Boxplot of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 9. Check skewness</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">skew</span><span class="p">())</span>
</code></pre></div>

<h3 style="color:blue;">📌 Key Questions to Answer During EDA:</h3>

<ul>
<li>
<p>Are there any missing values or outliers?</p>
</li>
<li>
<p>Are there highly correlated features?</p>
</li>
<li>
<p>Is the target variable (e.g., Outcome) imbalanced?</p>
</li>
<li>
<p>Which features differ significantly between classes?</p>
</li>
</ul>
<h3 style="color:blue;">📌 Heatmap Explanation (Correlation Heatmap)</h3>

<p>A heatmap is a graphical representation of data using colors to indicate the strength of correlation between variables. In EDA, a correlation heatmap is commonly used to understand relationships between numerical features.</p>
<h3 style="color:blue;">📌 What Is Correlation?</h3>

<p>Correlation measures the linear relationship between two variables. The value ranges from:</p>
<ul>
<li>
<p><strong>+1</strong> → perfect positive correlation (as one increases, so does the other)</p>
</li>
<li>
<p><strong>0</strong> → no correlation</p>
</li>
<li>
<p><strong>–1</strong> → perfect negative correlation (as one increases, the other decreases)</p>
</li>
</ul>
<h3 style="color:blue;">📌 How to Read a Correlation Heatmap</h3>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Heatmap&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<table>
<thead>
<tr>
<th>Element</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>df.corr()</code></td>
<td>Calculates pairwise correlation between all numerical columns.</td>
</tr>
<tr>
<td><code>annot=True</code></td>
<td>Shows the correlation coefficient numbers in each cell.</td>
</tr>
<tr>
<td><code>cmap='coolwarm'</code></td>
<td>Color map; red = high positive correlation, blue = high negative.</td>
</tr>
<tr>
<td><code>fmt=".2f"</code></td>
<td>Shows values up to 2 decimal places.</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 What to Look for in Heatmaps</h3>

<table>
<thead>
<tr>
<th>Goal</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>🔍 Identify multicollinearity</td>
<td>If two features have correlation &gt; 0.9 or &lt; –0.9, one can be removed.</td>
</tr>
<tr>
<td>🎯 Target association</td>
<td>Look for features highly correlated with the target variable (<code>Outcome</code>).</td>
</tr>
<tr>
<td>🧼 Data cleaning</td>
<td>Helps identify redundant variables.</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Example Interpretation</h3>

<table>
<thead>
<tr>
<th>Feature 1</th>
<th>Feature 2</th>
<th>Correlation</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Glucose</td>
<td>Outcome</td>
<td><strong>0.47</strong></td>
<td>Moderate positive correlation – higher glucose relates to diabetes</td>
</tr>
<tr>
<td>BMI</td>
<td>Outcome</td>
<td><strong>0.31</strong></td>
<td>Slight positive correlation</td>
</tr>
<tr>
<td>Age</td>
<td>Pregnancies</td>
<td><strong>0.54</strong></td>
<td>Older individuals tend to have more pregnancies in the dataset</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Example Output of Correlation with Outcome</h3>

<p><img alt="alt text" src="../images/SL5.png" /></p>
<p><strong>Correlation with Outcome</strong></p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Correlation with Outcome</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Glucose</strong></td>
<td><strong>0.47</strong> ✅</td>
</tr>
<tr>
<td><strong>BMI</strong></td>
<td><strong>0.31</strong> ✅</td>
</tr>
<tr>
<td><strong>Age</strong></td>
<td><strong>0.23</strong> ✅</td>
</tr>
<tr>
<td><strong>DiabetesPedigreeFunction</strong></td>
<td>0.17 ✅</td>
</tr>
<tr>
<td>Pregnancies</td>
<td>0.22</td>
</tr>
<tr>
<td>SkinThickness</td>
<td>0.07</td>
</tr>
<tr>
<td>BloodPressure</td>
<td>0.06</td>
</tr>
<tr>
<td>Insulin</td>
<td>0.13</td>
</tr>
<tr>
<td><strong>Outcome</strong></td>
<td>1.00 (self)</td>
</tr>
</tbody>
</table>
<p><strong>Correlation with Age</strong> </p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Correlation with Age</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Pregnancies</strong></td>
<td><strong>0.54</strong> ✅</td>
</tr>
<tr>
<td><strong>Glucose</strong></td>
<td><strong>0.26</strong> ✅</td>
</tr>
<tr>
<td><strong>BloodPressure</strong></td>
<td><strong>0.24</strong> ✅</td>
</tr>
<tr>
<td><strong>Outcome</strong></td>
<td><strong>0.24</strong> ✅</td>
</tr>
<tr>
<td>BMI</td>
<td>0.036</td>
</tr>
<tr>
<td><strong>Age</strong></td>
<td>1.00 (self)</td>
</tr>
<tr>
<td>DiabetesPedigreeFunction</td>
<td>0.034</td>
</tr>
<tr>
<td>SkinThickness</td>
<td>- 0.11 ✅</td>
</tr>
<tr>
<td>Insulin</td>
<td>- 0.042</td>
</tr>
</tbody>
</table>
<h3 style="color:blue;">📌 Key Insights</h3>

<ul>
<li>
<p><code>Glucose</code> has the <strong>strongest positive correlation</strong> with diabetes. Makes sense biologically.</p>
</li>
<li>
<p><code>BMI</code>, <code>Age</code>, and <code>DiabetesPedigreeFunction</code> also have a <strong>moderate correlation</strong> with the <code>Outcome</code>.</p>
</li>
<li>
<p><code>BloodPressure</code>, <code>SkinThickness</code>, and <code>Insulin</code> have <strong>weak correlation</strong>, but may still be useful in multivariate models.</p>
</li>
</ul>
<h3 style="color:blue;">📌 Telco Customer Churn</h3>

<p><a href="https://www.kaggle.com/datasets/blastchar/telco-customer-churn">Telco Customer Churn</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span>
    <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;WA_Fn-UseC_-Telco-Customer-Churn.csv&quot;</span><span class="p">)</span>

<span class="c1"># Drop customerID</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;customerID&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Convert TotalCharges to numeric</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;TotalCharges&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TotalCharges&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

<span class="c1"># Fill missing values with median</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;TotalCharges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TotalCharges&#39;</span><span class="p">]</span><span class="o">.</span><span class="kp">median</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Encode binary variables</span>
<span class="n">binary_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;Dependents&#39;</span><span class="p">,</span> <span class="s1">&#39;PhoneService&#39;</span><span class="p">,</span> <span class="s1">&#39;PaperlessBilling&#39;</span><span class="p">,</span> <span class="s1">&#39;Churn&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">binary_cols</span><span class="p">:</span>
    <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;Yes&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># One-hot encode categorical features</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Boxplot for numerical features to detect outliers</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">df</span><span class="p">[[</span><span class="s1">&#39;tenure&#39;</span><span class="p">,</span> <span class="s1">&#39;MonthlyCharges&#39;</span><span class="p">,</span> <span class="s1">&#39;TotalCharges&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Boxplot for Numerical Features&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Churn&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Churn&#39;</span><span class="p">]</span>

<span class="c1"># Scale features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Train-Test Split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Logistic Regression with class balancing</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Accuracy Score: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Classification Report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Confusion Matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ROC Curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Find optimal threshold</span>
<span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="kp">argmax</span><span class="p">(</span><span class="n">tpr</span> <span class="o">-</span> <span class="n">fpr</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Optimal Threshold: </span><span class="si">{</span><span class="n">optimal_threshold</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Predict with new threshold</span>
<span class="n">y_pred_new</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_proba</span> <span class="o">&gt;=</span> <span class="n">optimal_threshold</span><span class="p">)</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Adjusted Classification Report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report with Adjusted Threshold:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_new</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Adjusted Confusion Matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_new</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greens&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix (Adjusted Threshold)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p><img alt="alt text" src="../images/SL26.png" /></p>
<p><img alt="alt text" src="../images/SL27.png" /></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="Regression.html" class="btn btn-neutral float-left" title="Regression"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="CrossValidation.html" class="btn btn-neutral float-right" title="Cross Validation">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="Regression.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="CrossValidation.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
